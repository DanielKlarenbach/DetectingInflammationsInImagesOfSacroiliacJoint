{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsage:\\n1. Directory with data sets must be placed in directory named \"input\"\\n2. Input directory must be in the same directory as the .ipynb file with this sript\\n3. Inside each data set directory there must be three directories named: images, labels and masks.\\n4. Filenames of labels and masks files must be the same as image filename.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Usage:\n",
    "1. Directory with data sets must be placed in directory named \"input\"\n",
    "2. Input directory must be in the same directory as the .ipynb file with this sript\n",
    "3. Inside each data set directory there must be three directories named: images, labels and masks.\n",
    "4. Filenames of labels and masks files must be the same as image filename.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.future.graph as skigraph\n",
    "import shutil\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "\n",
    "from kgcnn.literature.GCN import make_model\n",
    "from kgcnn.utils.data import ragged_tensor_from_nested_numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from kgcnn.utils.learning import LinearLearningRateScheduler\n",
    "from PIL import Image, ImageOps\n",
    "import radiomics\n",
    "import numpy.ma as ma\n",
    "import nrrd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, UpSampling2D, Input, concatenate\n",
    "from keras import backend as K\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.compat.v1 import ConfigProto\n",
    "#from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=10,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def showOpencvImage(image, isGray=False):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "def get_augmented(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    X_val=None,\n",
    "    Y_val=None,\n",
    "    batch_size=32, \n",
    "    seed=0, \n",
    "    data_gen_args = dict(\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.02,\n",
    "        height_shift_range=0.02,\n",
    "        zca_whitening = False,\n",
    "        zca_epsilon = 1e-6,\n",
    "        shear_range=5,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )):\n",
    "\n",
    "\n",
    "    # Train data, provide the same seed and keyword arguments to the fit and flow methods\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen_1 = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen_2 = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    Y_train_1 = Y_train[:,:,:,0:1]\n",
    "    Y_train_2 = Y_train[:,:,:,1:2]\n",
    "    Y_datagen_1.fit(Y_train_1, augment=True, seed=seed)\n",
    "    Y_datagen_2.fit(Y_train_2, augment=True, seed=seed)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_train_augmented_1 = Y_datagen_1.flow(Y_train_1, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_train_augmented_2 = Y_datagen_2.flow(Y_train_2, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    \n",
    "    train_generator = zip(X_train_augmented, Y_train_augmented_1, Y_train_augmented_2)#, Y_train_augmented_3)\n",
    "    return train_generator\n",
    "\n",
    "def my_generator(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    train_gen,\n",
    "    X_val=None,\n",
    "    Y_val=None,\n",
    "    batch_size=2, \n",
    "    seed=0, \n",
    "    data_gen_args = dict(\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.02,\n",
    "        height_shift_range=0.02,\n",
    "        zca_whitening = False,\n",
    "        zca_epsilon = 1e-6,\n",
    "        shear_range=5,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )):\n",
    "    while 1:\n",
    "        sample_batch = next(train_gen)\n",
    "        xx, yy1,yy2 = sample_batch\n",
    "        yy = np.zeros((xx.shape[0],xx.shape[1],xx.shape[2],2),dtype=np.float32)\n",
    "        yy[:,:,:,0:1] = yy1\n",
    "        yy[:,:,:,1:2] = yy2\n",
    "#        yy[:,:,:,6:7] = yy3\n",
    "        yield (xx, yy)\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return UpSampling2D(strides)\n",
    "\n",
    "def conv2d_block(\n",
    "    inputs, \n",
    "    filters=16, \n",
    "    kernel_size=(3,3), \n",
    "    activation='tanh', \n",
    "#    kernel_initializer='he_normal', \n",
    "    kernel_initializer= 'glorot_uniform',\n",
    "    padding='same'):\n",
    "    \n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (inputs)\n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (c)\n",
    "    return c\n",
    "\n",
    "def my_custom_unet(\n",
    "    input_shape,\n",
    "    num_classes=1,\n",
    "    upsample_mode='deconv', # 'deconv' or 'simple' \n",
    "    filters=16,\n",
    "    num_layers=4,\n",
    "    output_activation='softmax'): # 'sigmoid' or 'softmax'\n",
    "    \n",
    "    if upsample_mode=='deconv':\n",
    "        upsample=upsample_conv\n",
    "    else:\n",
    "        upsample=upsample_simple\n",
    "\n",
    "    # Build U-Net model\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs   \n",
    "\n",
    "    down_layers = []\n",
    "    for l in range(num_layers):\n",
    "        x = conv2d_block(inputs=x, filters=filters)\n",
    "        down_layers.append(x)\n",
    "        x = MaxPooling2D((2, 2)) (x)\n",
    "        filters = filters*2 # double the number of filters with each layer\n",
    "\n",
    "    x = conv2d_block(inputs=x, filters=196)\n",
    "\n",
    "\n",
    "    for conv in reversed(down_layers):        \n",
    "        filters //= 2 # decreasing number of filters with each layer \n",
    "        x = upsample(filters, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "        x = concatenate([x, conv])\n",
    "        x = conv2d_block(inputs=x, filters=filters)\n",
    "    \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=output_activation) (x)    \n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def iou(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "\n",
    "def train_UNET(graphs_train, graphs_test):\n",
    "\n",
    "    imgs_train = []\n",
    "    for graph in graphs_train:\n",
    "        imgs_train.append(f\"/home/daniel/Praca inżynierska/DetectingInflammationsInImagesOfSacroiliacJoint/input/300_pixel_40_com/images/{graph.file_id}.bmp\")\n",
    "\n",
    "    masks = glob.glob(\"/home/daniel/Praca inżynierska/DetectingInflammationsInImagesOfSacroiliacJoint/input/300_pixel_40_com/masks/*.bmp\")\n",
    "    orgs = glob.glob(\"/home/daniel/Praca inżynierska/DetectingInflammationsInImagesOfSacroiliacJoint/input/300_pixel_40_com/images/*.bmp\")\n",
    "\n",
    "    masks.sort()\n",
    "    orgs.sort()\n",
    "\n",
    "\n",
    "    list_train = []\n",
    "    list_test =  []\n",
    "\n",
    "    for (i,image) in enumerate(orgs):\n",
    "        for (j,value) in enumerate(imgs_train):\n",
    "            if image == value:\n",
    "                list_train.append(i)\n",
    "                break\n",
    "            elif j==len(imgs_train)-1:\n",
    "                list_test.append(i)\n",
    "                \n",
    "    print(\"FFFFFFFFFF\")\n",
    "    print(len(list_train))\n",
    "    print(len(list_test))\n",
    "    print(len(masks))\n",
    "    print(len(orgs))\n",
    "\n",
    "    imgs_list = []\n",
    "    masks_list = []\n",
    "\n",
    "    size = (128,128)\n",
    "\n",
    "    for image, mask in zip(orgs, masks):\n",
    "        im = cv2.imread(image)\n",
    "        im = im[:,:,0]\n",
    "        imgs_list.append(im)\n",
    "\n",
    "        im = cv2.imread(mask)\n",
    "        im = im[:,:,0]\n",
    "\n",
    "        imMask = np.zeros((im.shape[0],im.shape[1],2),dtype=np.float32)\n",
    "        imMask[im == 0,0] = 1               #background\n",
    "        imMask[im!=0,1] = 1                 #spine\n",
    "\n",
    "        masks_list.append(imMask)\n",
    "\n",
    "\n",
    "\n",
    "    imgs_np = np.asarray(imgs_list)\n",
    "    masks_np = np.asarray(masks_list)\n",
    "    print(imgs_np.shape, masks_np.shape)\n",
    "\n",
    "    weights = np.ones((2),dtype=np.float32)\n",
    "    for i in range(0,2):\n",
    "        weights[i] = 1/(np.sum(masks_np[:,:,:,i])/(masks_np.shape[0]*masks_np.shape[1]*masks_np.shape[2]))\n",
    "\n",
    "    w = sum(weights)\n",
    "    weights = weights/w\n",
    "\n",
    "    print(weights)\n",
    "\n",
    "    print(imgs_np.max(), masks_np.max())\n",
    "    x = np.asarray(imgs_np, dtype=np.float32)\n",
    "    y = np.asarray(masks_np, dtype=np.float32)\n",
    "    print(x.max(), y.max())\n",
    "    print(x.shape, y.shape)\n",
    "    y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 2)\n",
    "    print(x.shape, y.shape)\n",
    "    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    list_val = list_train[:int(0.2*len(list_train))]\n",
    "    list_train = list_train[int(0.2*len(list_train)):]\n",
    "\n",
    "    print(list_train)\n",
    "    print(list_val)\n",
    "    print(list_test)\n",
    "\n",
    "    x_train = x[list_train]\n",
    "    x_val = x[list_val]\n",
    "    x_test = x[list_test]\n",
    "\n",
    "    y_train = y[list_train]\n",
    "    y_val = y[list_val]\n",
    "    y_test = y[list_test]\n",
    "\n",
    "    print(\"x_train: \", x_train.shape)\n",
    "    print(\"y_train: \", y_train.shape)\n",
    "    print(\"x_val: \", x_val.shape)\n",
    "    print(\"y_val: \", y_val.shape)\n",
    "    print(\"x_test: \", x_test.shape)\n",
    "    print(\"y_test: \", y_test.shape)\n",
    "\n",
    "    input_shape = x_train[0].shape\n",
    "\n",
    "    model = my_custom_unet(\n",
    "        input_shape,\n",
    "        num_classes=2,\n",
    "        filters=64,\n",
    "        output_activation='softmax',\n",
    "        num_layers=4  \n",
    "    )\n",
    "\n",
    "    model_filename = 'segm_ALL_' + '.h5'\n",
    "\n",
    "    callback_checkpoint = ModelCheckpoint(\n",
    "        model_filename, \n",
    "        verbose=1, \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.0001), \n",
    "        loss = weighted_categorical_crossentropy(weights),\n",
    "        metrics=[iou]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    train_gen = get_augmented(x_train, y_train, batch_size=2,data_gen_args=data_gen_args)\n",
    "    generator = my_generator(x_train, y_train,train_gen, batch_size=2,data_gen_args=data_gen_args)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        generator,\n",
    "        steps_per_epoch=30,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[callback_checkpoint]\n",
    "    )\n",
    "\n",
    "\n",
    "    model.load_weights(model_filename)\n",
    "    os.makedirs(f\"{OUTPUT_DIR_PATH}/generated_unet\", exist_ok=True)\n",
    "    for N in range(x_test.shape[0]):\n",
    "        y_pred = model.predict(x_test[N:N+1])\n",
    "        predictions = np.round(y_pred)\n",
    "        for k in range(1,2):\n",
    "            dum = predictions[0,:,:,k]*255\n",
    "            cv2.imwrite(f'{OUTPUT_DIR_PATH}/generated_unet/{graphs_test[N].file_id}.png',dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script parameterss\n",
    "DATA_SET_DIR_NAMES = [\"300_pixel_5_com\", \"300_pixel_10_com\", \"300_pixel_15_com\", \"300_pixel_20_com\", \"300_pixel_25_com\", \"300_pixel_30_com\", \"300_pixel_35_com\", \"300_pixel_40_com\"]\n",
    "PYRADIOMICS_FEATURES = [\n",
    "    \"original_firstorder_Mean\",\n",
    "    \"original_firstorder_Variance\",\n",
    "    \"original_glcm_ClusterTendency\",\n",
    "    \"original_glcm_Correlation\",\n",
    "    \"original_ngtdm_Contrast\",\n",
    "    \"original_glrlm_RunEntropy\",\n",
    "    \"original_gldm_DependenceEntropy\",\n",
    "    \"original_gldm_SmallDependenceEmphasis\",\n",
    "    \"original_glrlm_GrayLevelNonUniformity\",\n",
    "    \"original_ngtdm_Busyness\",\n",
    "    \"original_glszm_ZoneEntropy\",\n",
    "    \"original_glszm_SizeZoneNonUniformity\"\n",
    "]\n",
    "WHITE_SUPERPIXEL_LABEL_TRESHOLD = 0.65\n",
    "\n",
    "# globals\n",
    "\n",
    "\n",
    "#configuration\n",
    "logger = logging.getLogger(\"radiomics\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def save_object(filename, obj):\n",
    "    obj_file = open(filename, \"wb\")\n",
    "    pickle.dump(obj, obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "def load_object(filename):\n",
    "    obj_file = open(filename, \"rb\")\n",
    "    obj = pickle.load(obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, file_id, rag, image, superpixels_labels, mask):\n",
    "        self.file_id = file_id\n",
    "        self.rag = rag\n",
    "        self.image = image\n",
    "        self.superpixels_labels = superpixels_labels\n",
    "        self.mask = mask\n",
    "\n",
    "class Subgraph:\n",
    "    def __init__(self, rag, graph, middle_superpixel_label, label):\n",
    "        self.rag = rag\n",
    "        self.graph = graph\n",
    "        self.middle_superpixel_label = middle_superpixel_label\n",
    "        self.label = label\n",
    "        self.unnormalized_edge_indices = None\n",
    "        self.normalized_edge_indices = None\n",
    "        self.edges = None\n",
    "        self.nodes = None\n",
    "        \n",
    "def assign_labels(graph):\n",
    "    white_pixels_count = defaultdict(int)\n",
    "    total_pixels_count = defaultdict(int)\n",
    "    \n",
    "    for (i, row) in enumerate(graph.superpixels_labels):\n",
    "        for (j, superpixel_label) in enumerate(row):\n",
    "            total_pixels_count[superpixel_label] += 1\n",
    "            if graph.mask[i][j] == 1:\n",
    "                white_pixels_count[superpixel_label] += 1\n",
    "      \n",
    "    for node in graph.rag:\n",
    "        graph.rag.nodes[node]['label'] = 1.0 if white_pixels_count[node] / total_pixels_count[node] >= WHITE_SUPERPIXEL_LABEL_TRESHOLD else 0.0\n",
    "            \n",
    "            \n",
    "def assign_features(graph):\n",
    "    unique_superpixels_labels = np.unique(graph.superpixels_labels)\n",
    "    \n",
    "    for superpixel_label in unique_superpixels_labels:\n",
    "        superpixel_label_mask = (graph.superpixels_labels == superpixel_label).astype(int)\n",
    "        NRRD_DIRECTORY_PATH = f\"{OUTPUT_DIR_PATH}/nrrd\"\n",
    "        NRRD_ITEM_DIRECTORY_PATH = f\"{NRRD_DIRECTORY_PATH}/{graph.file_id}\"\n",
    "        os.makedirs(NRRD_ITEM_DIRECTORY_PATH, exist_ok=True)\n",
    "        \n",
    "        os.makedirs(f\"{NRRD_ITEM_DIRECTORY_PATH}\", exist_ok=True)\n",
    "        nrrd.write(f\"{NRRD_ITEM_DIRECTORY_PATH}/{superpixel_label}_image.nrrd\", graph.image)\n",
    "        nrrd.write(f\"{NRRD_ITEM_DIRECTORY_PATH}/{superpixel_label}_superpixel_label_mask.nrrd\", superpixel_label_mask)\n",
    "        nrrd_image_path = os.path.join(f\"{NRRD_ITEM_DIRECTORY_PATH}\", str(superpixel_label) + \"_image.nrrd\")\n",
    "        nrrd_superpixel_label_mask_path = os.path.join(f\"{NRRD_ITEM_DIRECTORY_PATH}\", str(superpixel_label) + \"_superpixel_label_mask.nrrd\")\n",
    "        \n",
    "        extractor = radiomics.featureextractor.RadiomicsFeatureExtractor(minimumROIDimensions=1)\n",
    "        result = extractor.execute(nrrd_image_path, nrrd_superpixel_label_mask_path)  \n",
    "\n",
    "            \n",
    "        for feature in PYRADIOMICS_FEATURES:\n",
    "            graph.rag.nodes[superpixel_label][feature] = result[feature]\n",
    "    \n",
    "def process_images():\n",
    "    filenames = os.listdir(IMAGES_DIR_PATH)\n",
    "    os.makedirs(f\"{OUTPUT_DIR_PATH}/expected\", exist_ok=True)\n",
    "    graphs = list()\n",
    "        \n",
    "    for (file_count, filename) in enumerate(filenames, start=1):\n",
    "        print(f\"Processing files: {file_count}/{len(filenames)}\")\n",
    "        \n",
    "        file_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        try:\n",
    "            image = np.array(ImageOps.grayscale(Image.open(f\"{IMAGES_DIR_PATH}/{filename}\")))\n",
    "            mask = np.array(ImageOps.grayscale(Image.open(f\"{MASKS_DIR_PATH}/{file_id}.bmp\")))\n",
    "            superpixels_labels = np.fromfile(f\"{SUPERPIXELS_LABELS_DIR_PATH}/{file_id}.dat\", dtype=np.dtype((np.int32, image.shape)))[0]\n",
    "        except FileNotFoundError as error: \n",
    "            print(error)\n",
    "            \n",
    "        rag = skigraph.rag_mean_color(image, superpixels_labels)\n",
    "        graphs.append(Graph(file_id, rag, image, superpixels_labels, mask))\n",
    "        assign_labels(graphs[-1])\n",
    "        assign_features(graphs[-1])\n",
    "        \n",
    "        expected = Image.fromarray((mask*255).astype(np.uint8))\n",
    "        expected.save(f\"{OUTPUT_DIR_PATH}/expected/{file_id}.png\")\n",
    "        \n",
    "    print(\"All files have been processed\")\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "def split_into_subgraphs(graphs):\n",
    "    subgraphs = []\n",
    "    for graph in graphs:\n",
    "        for node in graph.rag.nodes:\n",
    "            nodes = [neighbor for neighbor in graph.rag.neighbors(node)] + [node]\n",
    "            rag = graph.rag.subgraph(nodes)\n",
    "            label = graph.rag.nodes[node]['label']\n",
    "            subgraphs.append(Subgraph(rag, graph, node, label))\n",
    "            \n",
    "    return subgraphs\n",
    "\n",
    "def normalize_edge_indices(edge_indices):\n",
    "    flat_list = [node for edge_index in edge_indices for node in edge_index]            \n",
    "    flat_list.sort()\n",
    "    flat_list = list(dict.fromkeys(flat_list))\n",
    "    change = {key:value for (value, key) in enumerate(flat_list)}\n",
    "    result = [[change[edge_index[0]], change[edge_index[1]]] for edge_index in edge_indices] \n",
    "    \n",
    "    return result\n",
    "\n",
    "def prepare_data(subgraphs):\n",
    "    nodes = []\n",
    "    edge_indices = []\n",
    "    edges = []\n",
    "    labels = []\n",
    "    \n",
    "    for subgraph in subgraphs:\n",
    "        node_features = []\n",
    "        \n",
    "        for node in subgraph.rag.nodes:\n",
    "            node_features.append([subgraph.rag.nodes[node][feature] for feature in PYRADIOMICS_FEATURES])\n",
    "            \n",
    "        nodes.append(node_features)\n",
    "        edges.append([[1.0] for edge in subgraph.rag.edges.data()])\n",
    "        unnormalized_edge_indices = [list(index) for index in subgraph.rag.edges]\n",
    "        edge_indices.append(normalize_edge_indices(unnormalized_edge_indices))\n",
    "        labels.append(subgraph.label)\n",
    "        \n",
    "        subgraph.nodes = nodes[-1]\n",
    "        subgraph.unnormalized_edge_indices = unnormalized_edge_indices\n",
    "        subgraph.normalized_edge_indices = edge_indices[-1]\n",
    "        subgraph.edges = edges[-1]\n",
    "\n",
    "    return nodes, edge_indices, edges, np.array(labels)\n",
    "\n",
    "def generate_segmented_images_from_predictions(subgraphs, predictions):\n",
    "    predicted_images = {}\n",
    "    os.makedirs(f\"{OUTPUT_DIR_PATH}/generated\", exist_ok=True)\n",
    "\n",
    "    for (prediction_count, subgraph) in enumerate(subgraphs):\n",
    "        if subgraph.graph.file_id not in predicted_images:\n",
    "            predicted_images[subgraph.graph.file_id] = np.copy(subgraph.graph.superpixels_labels)\n",
    "        predicted_images[subgraph.graph.file_id][predicted_images[subgraph.graph.file_id] == subgraph.middle_superpixel_label] = predictions[prediction_count] - 2\n",
    "\n",
    "    for file_id in predicted_images.keys():\n",
    "        predicted_images[file_id][predicted_images[file_id] == -1] = 255\n",
    "        predicted_images[file_id][predicted_images[file_id] == -2] = 0\n",
    "        generated = Image.fromarray(predicted_images[file_id].astype(np.uint8))\n",
    "        generated.save(f\"{OUTPUT_DIR_PATH}/generated/{file_id}.png\")\n",
    "\n",
    "def compute_dice_coefficient(expected, generated):      \n",
    "    expected[expected!=0] = 1\n",
    "    generated[generated!=0] = 1\n",
    "    intersection = expected*generated\n",
    "    size = len(expected)*len(expected[0])\n",
    "\n",
    "    return np.sum(intersection)/size\n",
    "\n",
    "def compute_dice_coefficients_for_test_set(graphs_test, output_info_file):\n",
    "    output_info_file.write(f\"\\t\\tGCN\\t\\tUNET\\n\")\n",
    "    for graph in graphs_test:\n",
    "        expected = np.array(ImageOps.grayscale(Image.open(f\"{OUTPUT_DIR_PATH}/expected/{graph.file_id}.png\")))\n",
    "        generated_unet = np.array(ImageOps.grayscale(Image.open(f\"{OUTPUT_DIR_PATH}/generated_unet/{graph.file_id}.png\")))\n",
    "        generated = np.array(ImageOps.grayscale(Image.open(f\"{OUTPUT_DIR_PATH}/generated/{graph.file_id}.png\")))\n",
    "        dice_coefficient = compute_dice_coefficient(expected, generated)\n",
    "        dice_coefficient_unet = compute_dice_coefficient(expected, generated_unet)\n",
    "        output_info_file.write(f\"{graph.file_id}\\t{str(dice_coefficient)}\\t{str(dice_coefficient_unet)}\\n\")\n",
    "\n",
    "        \n",
    "def train_GCN(graphs, output_info_file, graphs_train, graphs_test):\n",
    "    subgraphs_train = split_into_subgraphs(graphs_train)\n",
    "    subgraphs_test = split_into_subgraphs(graphs_test)\n",
    "\n",
    "    nodes_train, edge_indices_train, edges_train, labels_train =  prepare_data(subgraphs_train)\n",
    "    nodes_test, edge_indices_test, edges_test, labels_test =  prepare_data(subgraphs_test)\n",
    "\n",
    "    nodes_train = ragged_tensor_from_nested_numpy(nodes_train)\n",
    "    edges_train = ragged_tensor_from_nested_numpy(edges_train)\n",
    "    edge_indices_train = ragged_tensor_from_nested_numpy(edge_indices_train)\n",
    "\n",
    "    nodes_test = ragged_tensor_from_nested_numpy(nodes_test)\n",
    "    edges_test = ragged_tensor_from_nested_numpy(edges_test)\n",
    "    edge_indices_test = ragged_tensor_from_nested_numpy(edge_indices_test)\n",
    "\n",
    "    xtrain = nodes_train, edges_train, edge_indices_train\n",
    "    xtest = nodes_test, edges_test, edge_indices_test\n",
    "    ytrain = labels_train\n",
    "    ytest = labels_test\n",
    "    print([x.shape for x in xtrain])\n",
    "    print([x.shape for x in xtest])\n",
    "    print(ytrain.shape, ytest.shape)\n",
    "    output_info_file.write(f\"nodes_train: {xtrain[0].shape}\\n\")\n",
    "    output_info_file.write(f\"edges_train: {xtrain[1].shape}\\n\")\n",
    "    output_info_file.write(f\"edge_indices_train: {xtrain[2].shape}\\n\")\n",
    "    output_info_file.write(f\"labels_train: {ytrain.shape}\\n\")\n",
    "    output_info_file.write(f\"nodes_test: {xtest[0].shape}\\n\")\n",
    "    output_info_file.write(f\"edges_test: {xtest[1].shape}\\n\")\n",
    "    output_info_file.write(f\"edge_indices_test: {xtest[2].shape}\\n\")\n",
    "    output_info_file.write(f\"labels_test: {ytest.shape}\\n\")\n",
    "    \n",
    "    if os.path.exists(f\"{SAVED_OBJECTS_DIR_PATH}/model\"):\n",
    "        model = keras.models.load_model(f\"{SAVED_OBJECTS_DIR_PATH}/model\")\n",
    "    else:\n",
    "        model = make_model(\n",
    "        name = \"GCN\",\n",
    "        inputs = [{'shape': (None, 12), 'name': \"node_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "                {'shape': (None, 1), 'name': \"edge_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "                {'shape': (None, 2), 'name': \"edge_indices\", 'dtype': 'int64', 'ragged': True}],\n",
    "        input_embedding = {\"node\": {\"input_dim\": 55, \"output_dim\": 64},\n",
    "                           \"edge\": {\"input_dim\": 10, \"output_dim\": 64}},\n",
    "        output_embedding =  'graph',\n",
    "        output_mlp = {\"use_bias\": [True, True, False], \"units\": [140, 70, 1],\n",
    "                    \"activation\": ['relu', 'relu', 'sigmoid']},\n",
    "        gcn_args = {\"units\": 64, \"use_bias\": True, \"activation\": 'relu', \"pooling_method\": 'mean', \n",
    "                    \"normalize_by_weights\": False},\n",
    "        depth = 1\n",
    "        )\n",
    "\n",
    "        learning_rate_start = 1e-3\n",
    "        learning_rate_stop = 1e-4\n",
    "        epo = 150\n",
    "        epomin = 100\n",
    "        epostep = 10\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=learning_rate_start)\n",
    "        cbks = LinearLearningRateScheduler(learning_rate_start, learning_rate_stop, epomin, epo)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      weighted_metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "\n",
    "        start = time.process_time()\n",
    "        hist = model.fit(xtrain, ytrain,\n",
    "                         epochs=epo,\n",
    "                         batch_size=32,\n",
    "                         callbacks=[cbks],\n",
    "                         validation_freq=epostep,\n",
    "                         validation_data=(xtest, ytest),\n",
    "                         verbose=2\n",
    "                         )\n",
    "        stop = time.process_time()\n",
    "        print(\"Print Time for taining: \", stop - start)\n",
    "\n",
    "        trainlossall = np.array(hist.history['accuracy'])\n",
    "        testlossall = np.array(hist.history['val_accuracy'])\n",
    "        acc_valid = testlossall[-1]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(trainlossall.shape[0]), trainlossall, label='Training ACC', c='blue')\n",
    "        plt.plot(np.arange(epostep, epo + epostep, epostep), testlossall, label='Test ACC', c='red')\n",
    "        plt.scatter([trainlossall.shape[0]], [acc_valid], label=\"{0:0.4f} \".format(acc_valid), c='red')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Interaction Network Loss')\n",
    "        plt.legend(loc='upper right', fontsize='x-large')\n",
    "        plt.savefig(f\"{OUTPUT_DIR_PATH}/training_plot.png\")\n",
    "        plt.show()\n",
    "\n",
    "        model.save(f\"{SAVED_OBJECTS_DIR_PATH}/model\")\n",
    "    \n",
    "\n",
    "    \n",
    "    probability = model.predict(xtest)\n",
    "    predictions = np.round(probability)\n",
    "    print(confusion_matrix(ytest, predictions))\n",
    "    output_info_file.write(np.array2string(confusion_matrix(ytest, predictions))+\"\\n\")\n",
    "    generate_segmented_images_from_predictions(subgraphs_test, predictions)\n",
    "    compute_dice_coefficients_for_test_set(graphs_test,output_info_file)\n",
    "    \n",
    "def process_data_set(data_set_dir_name):\n",
    "    \n",
    "    # globals\n",
    "    global DATA_DIR_PATH \n",
    "    global IMAGES_DIR_PATH\n",
    "    global SUPERPIXELS_LABELS_DIR_PATH\n",
    "    global MASKS_DIR_PATH\n",
    "    global OUTPUT_DIR_PATH\n",
    "    global SAVED_OBJECTS_DIR_PATH\n",
    "    DATA_DIR_PATH = f\"./input/{data_set_dir_name}\"\n",
    "    IMAGES_DIR_PATH = f\"{DATA_DIR_PATH}/images\"\n",
    "    SUPERPIXELS_LABELS_DIR_PATH = f\"{DATA_DIR_PATH}/superpixels_labels\"\n",
    "    MASKS_DIR_PATH = f\"{DATA_DIR_PATH}/masks\"\n",
    "    OUTPUT_DIR_PATH = f\"./output/{data_set_dir_name}\"\n",
    "    SAVED_OBJECTS_DIR_PATH = f\"./saved_objects/{data_set_dir_name}\"\n",
    "    \n",
    "    if os.path.exists(f\"{OUTPUT_DIR_PATH}/info.txt\"):\n",
    "        os.remove(f\"{OUTPUT_DIR_PATH}/info.txt\")\n",
    "    if os.path.exists(f\"{OUTPUT_DIR_PATH}/training_plot.png\"):\n",
    "        os.remove(f\"{OUTPUT_DIR_PATH}/training_plot.png\")\n",
    "    if os.path.exists(f\"{OUTPUT_DIR_PATH}/generated\"):\n",
    "        shutil.rmtree(f\"{OUTPUT_DIR_PATH}/generated\")\n",
    "    if os.path.exists(f\"{OUTPUT_DIR_PATH}/generated_unet\"):\n",
    "        shutil.rmtree(f\"{OUTPUT_DIR_PATH}/generated_unet\")\n",
    "\n",
    "    os.makedirs(f\"{OUTPUT_DIR_PATH}\", exist_ok=True)\n",
    "    os.makedirs(f\"{SAVED_OBJECTS_DIR_PATH}\", exist_ok=True)\n",
    "    os.makedirs(f\"{OUTPUT_DIR_PATH}/generated\")\n",
    "\n",
    "    \n",
    "    output_info_file = open(f\"{OUTPUT_DIR_PATH}/info.txt\",\"w+\")\n",
    "    output_info_file.write(f\"data set: {data_set_dir_name}\\n\")\n",
    "    \n",
    "    if os.path.exists(f\"{SAVED_OBJECTS_DIR_PATH}/graphs\"):\n",
    "        graphs = load_object(f\"{SAVED_OBJECTS_DIR_PATH}/graphs\")\n",
    "    else:\n",
    "        graphs = process_images()\n",
    "        save_object(f\"{SAVED_OBJECTS_DIR_PATH}/graphs\", graphs)\n",
    "        \n",
    "    graphs_train, graphs_test = train_test_split(graphs, train_size=0.8, random_state=1)\n",
    "    train_UNET(graphs_train, graphs_test)\n",
    "    train_GCN(graphs, output_info_file, graphs_train, graphs_test)\n",
    "    \n",
    "    output_info_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 196)    903364      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 196)    345940      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  401920      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 2)  130         conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 35s 1s/step - loss: 0.2133 - iou: 0.4051 - val_loss: 0.1772 - val_iou: 0.4627\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17718, saving model to segm_ALL_.h5\n",
      "[TensorShape([27903, None, 12]), TensorShape([27903, None, 1]), TensorShape([27903, None, 2])]\n",
      "[TensorShape([7526, None, 12]), TensorShape([7526, None, 1]), TensorShape([7526, None, 2])]\n",
      "(27903,) (7526,)\n",
      "[[5593  329]\n",
      " [ 274 1330]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n",
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 64) 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 196)    903364      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 196)    345940      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 512)  401920      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 256)  524544      conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 128)  131200      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 64) 32832       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 2)  130         conv2d_36[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 30s 977ms/step - loss: 0.2458 - iou: 0.3364 - val_loss: 0.2219 - val_iou: 0.3591\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22191, saving model to segm_ALL_.h5\n",
      "[TensorShape([28055, None, 12]), TensorShape([28055, None, 1]), TensorShape([28055, None, 2])]\n",
      "[TensorShape([7583, None, 12]), TensorShape([7583, None, 1]), TensorShape([7583, None, 2])]\n",
      "(28055,) (7583,)\n",
      "WARNING:kgcnn: Unknown model kwarg normalize_by_weights with value False\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn (GCN)                       (None, None, 64)     4160        dense_6[0][0]                    \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes (PoolingNodes)    (None, 64)           0           gcn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "mlp (MLP)                       (None, 1)            19040       pooling_nodes[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_2/gcn/pooling_weighted_local_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_2/gcn/pooling_weighted_local_edges_1/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_2/gcn/pooling_weighted_local_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_2/gcn/gather_nodes_outgoing_1/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_2/gcn/gather_nodes_outgoing_1/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_2/gcn/gather_nodes_outgoing_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 - 2s - loss: 0.5016 - accuracy: 0.8207\n",
      "Epoch 2/150\n",
      "877/877 - 2s - loss: 0.3180 - accuracy: 0.8618\n",
      "Epoch 3/150\n",
      "877/877 - 2s - loss: 0.2786 - accuracy: 0.8749\n",
      "Epoch 4/150\n",
      "877/877 - 2s - loss: 0.2673 - accuracy: 0.8771\n",
      "Epoch 5/150\n",
      "877/877 - 2s - loss: 0.2611 - accuracy: 0.8811\n",
      "Epoch 6/150\n",
      "877/877 - 2s - loss: 0.2567 - accuracy: 0.8834\n",
      "Epoch 7/150\n",
      "877/877 - 2s - loss: 0.2572 - accuracy: 0.8840\n",
      "Epoch 8/150\n",
      "877/877 - 2s - loss: 0.2508 - accuracy: 0.8857\n",
      "Epoch 9/150\n",
      "877/877 - 2s - loss: 0.2478 - accuracy: 0.8885\n",
      "Epoch 10/150\n",
      "877/877 - 2s - loss: 0.2501 - accuracy: 0.8891 - val_loss: 0.2385 - val_accuracy: 0.8944\n",
      "Epoch 11/150\n",
      "877/877 - 2s - loss: 0.2458 - accuracy: 0.8891\n",
      "Epoch 12/150\n",
      "877/877 - 2s - loss: 0.2407 - accuracy: 0.8907\n",
      "Epoch 13/150\n",
      "877/877 - 2s - loss: 0.2453 - accuracy: 0.8903\n",
      "Epoch 14/150\n",
      "877/877 - 2s - loss: 0.2428 - accuracy: 0.8900\n",
      "Epoch 15/150\n",
      "877/877 - 2s - loss: 0.2406 - accuracy: 0.8931\n",
      "Epoch 16/150\n",
      "877/877 - 2s - loss: 0.2404 - accuracy: 0.8915\n",
      "Epoch 17/150\n",
      "877/877 - 2s - loss: 0.2407 - accuracy: 0.8915\n",
      "Epoch 18/150\n",
      "877/877 - 2s - loss: 0.2388 - accuracy: 0.8927\n",
      "Epoch 19/150\n",
      "877/877 - 2s - loss: 0.2359 - accuracy: 0.8940\n",
      "Epoch 20/150\n",
      "877/877 - 2s - loss: 0.2393 - accuracy: 0.8922 - val_loss: 0.2168 - val_accuracy: 0.9049\n",
      "Epoch 21/150\n",
      "877/877 - 2s - loss: 0.2374 - accuracy: 0.8916\n",
      "Epoch 22/150\n",
      "877/877 - 2s - loss: 0.2360 - accuracy: 0.8932\n",
      "Epoch 23/150\n",
      "877/877 - 2s - loss: 0.2360 - accuracy: 0.8932\n",
      "Epoch 24/150\n",
      "877/877 - 2s - loss: 0.2337 - accuracy: 0.8950\n",
      "Epoch 25/150\n",
      "877/877 - 2s - loss: 0.2349 - accuracy: 0.8944\n",
      "Epoch 26/150\n",
      "877/877 - 2s - loss: 0.2351 - accuracy: 0.8930\n",
      "Epoch 27/150\n",
      "877/877 - 2s - loss: 0.2331 - accuracy: 0.8960\n",
      "Epoch 28/150\n",
      "877/877 - 2s - loss: 0.2338 - accuracy: 0.8960\n",
      "Epoch 29/150\n",
      "877/877 - 2s - loss: 0.2331 - accuracy: 0.8947\n",
      "Epoch 30/150\n",
      "877/877 - 2s - loss: 0.2318 - accuracy: 0.8946 - val_loss: 0.2063 - val_accuracy: 0.9044\n",
      "Epoch 31/150\n",
      "877/877 - 2s - loss: 0.2302 - accuracy: 0.8957\n",
      "Epoch 32/150\n",
      "877/877 - 2s - loss: 0.2346 - accuracy: 0.8940\n",
      "Epoch 33/150\n",
      "877/877 - 2s - loss: 0.2318 - accuracy: 0.8959\n",
      "Epoch 34/150\n",
      "877/877 - 2s - loss: 0.2329 - accuracy: 0.8955\n",
      "Epoch 35/150\n",
      "877/877 - 2s - loss: 0.2313 - accuracy: 0.8959\n",
      "Epoch 36/150\n",
      "877/877 - 2s - loss: 0.2292 - accuracy: 0.8969\n",
      "Epoch 37/150\n",
      "877/877 - 2s - loss: 0.2298 - accuracy: 0.8954\n",
      "Epoch 38/150\n",
      "877/877 - 2s - loss: 0.2316 - accuracy: 0.8965\n",
      "Epoch 39/150\n",
      "877/877 - 2s - loss: 0.2299 - accuracy: 0.8965\n",
      "Epoch 40/150\n",
      "877/877 - 2s - loss: 0.2297 - accuracy: 0.8971 - val_loss: 0.1981 - val_accuracy: 0.9097\n",
      "Epoch 41/150\n",
      "877/877 - 2s - loss: 0.2284 - accuracy: 0.8971\n",
      "Epoch 42/150\n",
      "877/877 - 2s - loss: 0.2294 - accuracy: 0.8958\n",
      "Epoch 43/150\n",
      "877/877 - 2s - loss: 0.2284 - accuracy: 0.8973\n",
      "Epoch 44/150\n",
      "877/877 - 2s - loss: 0.2289 - accuracy: 0.8966\n",
      "Epoch 45/150\n",
      "877/877 - 2s - loss: 0.2301 - accuracy: 0.8967\n",
      "Epoch 46/150\n",
      "877/877 - 2s - loss: 0.2309 - accuracy: 0.8970\n",
      "Epoch 47/150\n",
      "877/877 - 2s - loss: 0.2282 - accuracy: 0.8985\n",
      "Epoch 48/150\n",
      "877/877 - 2s - loss: 0.2288 - accuracy: 0.8984\n",
      "Epoch 49/150\n",
      "877/877 - 2s - loss: 0.2274 - accuracy: 0.8979\n",
      "Epoch 50/150\n",
      "877/877 - 2s - loss: 0.2273 - accuracy: 0.8977 - val_loss: 0.2069 - val_accuracy: 0.9064\n",
      "Epoch 51/150\n",
      "877/877 - 2s - loss: 0.2280 - accuracy: 0.8986\n",
      "Epoch 52/150\n",
      "877/877 - 2s - loss: 0.2268 - accuracy: 0.8990\n",
      "Epoch 53/150\n",
      "877/877 - 2s - loss: 0.2280 - accuracy: 0.8987\n",
      "Epoch 54/150\n",
      "877/877 - 2s - loss: 0.2269 - accuracy: 0.8977\n",
      "Epoch 55/150\n",
      "877/877 - 2s - loss: 0.2275 - accuracy: 0.8970\n",
      "Epoch 56/150\n",
      "877/877 - 2s - loss: 0.2270 - accuracy: 0.8965\n",
      "Epoch 57/150\n",
      "877/877 - 2s - loss: 0.2265 - accuracy: 0.8991\n",
      "Epoch 58/150\n",
      "877/877 - 2s - loss: 0.2272 - accuracy: 0.8973\n",
      "Epoch 59/150\n",
      "877/877 - 2s - loss: 0.2284 - accuracy: 0.8959\n",
      "Epoch 60/150\n",
      "877/877 - 2s - loss: 0.2239 - accuracy: 0.9000 - val_loss: 0.1999 - val_accuracy: 0.9081\n",
      "Epoch 61/150\n",
      "877/877 - 2s - loss: 0.2254 - accuracy: 0.8999\n",
      "Epoch 62/150\n",
      "877/877 - 2s - loss: 0.2263 - accuracy: 0.8977\n",
      "Epoch 63/150\n",
      "877/877 - 2s - loss: 0.2261 - accuracy: 0.8984\n",
      "Epoch 64/150\n",
      "877/877 - 2s - loss: 0.2265 - accuracy: 0.8976\n",
      "Epoch 65/150\n",
      "877/877 - 2s - loss: 0.2250 - accuracy: 0.8993\n",
      "Epoch 66/150\n",
      "877/877 - 2s - loss: 0.2270 - accuracy: 0.8987\n",
      "Epoch 67/150\n",
      "877/877 - 2s - loss: 0.2248 - accuracy: 0.8990\n",
      "Epoch 68/150\n",
      "877/877 - 2s - loss: 0.2238 - accuracy: 0.8994\n",
      "Epoch 69/150\n",
      "877/877 - 2s - loss: 0.2243 - accuracy: 0.8980\n",
      "Epoch 70/150\n",
      "877/877 - 2s - loss: 0.2251 - accuracy: 0.8989 - val_loss: 0.2010 - val_accuracy: 0.9118\n",
      "Epoch 71/150\n",
      "877/877 - 2s - loss: 0.2246 - accuracy: 0.8987\n",
      "Epoch 72/150\n",
      "877/877 - 2s - loss: 0.2241 - accuracy: 0.8996\n",
      "Epoch 73/150\n",
      "877/877 - 2s - loss: 0.2234 - accuracy: 0.9013\n",
      "Epoch 74/150\n",
      "877/877 - 2s - loss: 0.2255 - accuracy: 0.8988\n",
      "Epoch 75/150\n",
      "877/877 - 2s - loss: 0.2222 - accuracy: 0.9004\n",
      "Epoch 76/150\n",
      "877/877 - 2s - loss: 0.2244 - accuracy: 0.8985\n",
      "Epoch 77/150\n",
      "877/877 - 2s - loss: 0.2232 - accuracy: 0.8998\n",
      "Epoch 78/150\n",
      "877/877 - 2s - loss: 0.2239 - accuracy: 0.8996\n",
      "Epoch 79/150\n",
      "877/877 - 2s - loss: 0.2240 - accuracy: 0.8988\n",
      "Epoch 80/150\n",
      "877/877 - 2s - loss: 0.2243 - accuracy: 0.8983 - val_loss: 0.1964 - val_accuracy: 0.9083\n",
      "Epoch 81/150\n",
      "877/877 - 2s - loss: 0.2232 - accuracy: 0.8980\n",
      "Epoch 82/150\n",
      "877/877 - 2s - loss: 0.2231 - accuracy: 0.8997\n",
      "Epoch 83/150\n",
      "877/877 - 2s - loss: 0.2236 - accuracy: 0.8989\n",
      "Epoch 84/150\n",
      "877/877 - 2s - loss: 0.2226 - accuracy: 0.8994\n",
      "Epoch 85/150\n",
      "877/877 - 2s - loss: 0.2228 - accuracy: 0.8994\n",
      "Epoch 86/150\n",
      "877/877 - 2s - loss: 0.2258 - accuracy: 0.8975\n",
      "Epoch 87/150\n",
      "877/877 - 2s - loss: 0.2226 - accuracy: 0.8997\n",
      "Epoch 88/150\n",
      "877/877 - 2s - loss: 0.2230 - accuracy: 0.8991\n",
      "Epoch 89/150\n",
      "877/877 - 2s - loss: 0.2240 - accuracy: 0.8988\n",
      "Epoch 90/150\n",
      "877/877 - 2s - loss: 0.2241 - accuracy: 0.8995 - val_loss: 0.2005 - val_accuracy: 0.9119\n",
      "Epoch 91/150\n",
      "877/877 - 2s - loss: 0.2244 - accuracy: 0.8983\n",
      "Epoch 92/150\n",
      "877/877 - 2s - loss: 0.2251 - accuracy: 0.8984\n",
      "Epoch 93/150\n",
      "877/877 - 2s - loss: 0.2240 - accuracy: 0.8994\n",
      "Epoch 94/150\n",
      "877/877 - 2s - loss: 0.2239 - accuracy: 0.8993\n",
      "Epoch 95/150\n",
      "877/877 - 2s - loss: 0.2255 - accuracy: 0.8980\n",
      "Epoch 96/150\n",
      "877/877 - 2s - loss: 0.2231 - accuracy: 0.9004\n",
      "Epoch 97/150\n",
      "877/877 - 2s - loss: 0.2203 - accuracy: 0.9007\n",
      "Epoch 98/150\n",
      "877/877 - 2s - loss: 0.2224 - accuracy: 0.9013\n",
      "Epoch 99/150\n",
      "877/877 - 2s - loss: 0.2208 - accuracy: 0.9007\n",
      "Epoch 100/150\n",
      "877/877 - 2s - loss: 0.2236 - accuracy: 0.9006 - val_loss: 0.1964 - val_accuracy: 0.9105\n",
      "Epoch 101/150\n",
      "877/877 - 2s - loss: 0.2220 - accuracy: 0.9010\n",
      "Epoch 102/150\n",
      "877/877 - 2s - loss: 0.2249 - accuracy: 0.8994\n",
      "Epoch 103/150\n",
      "877/877 - 2s - loss: 0.2214 - accuracy: 0.9015\n",
      "Epoch 104/150\n",
      "877/877 - 2s - loss: 0.2220 - accuracy: 0.9007\n",
      "Epoch 105/150\n",
      "877/877 - 2s - loss: 0.2217 - accuracy: 0.9004\n",
      "Epoch 106/150\n",
      "877/877 - 2s - loss: 0.2228 - accuracy: 0.9008\n",
      "Epoch 107/150\n",
      "877/877 - 2s - loss: 0.2205 - accuracy: 0.9012\n",
      "Epoch 108/150\n",
      "877/877 - 2s - loss: 0.2219 - accuracy: 0.8996\n",
      "Epoch 109/150\n",
      "877/877 - 2s - loss: 0.2215 - accuracy: 0.9015\n",
      "Epoch 110/150\n",
      "877/877 - 2s - loss: 0.2212 - accuracy: 0.9005 - val_loss: 0.1950 - val_accuracy: 0.9126\n",
      "Epoch 111/150\n",
      "877/877 - 2s - loss: 0.2198 - accuracy: 0.9003\n",
      "Epoch 112/150\n",
      "877/877 - 2s - loss: 0.2205 - accuracy: 0.9003\n",
      "Epoch 113/150\n",
      "877/877 - 2s - loss: 0.2183 - accuracy: 0.9028\n",
      "Epoch 114/150\n",
      "877/877 - 2s - loss: 0.2212 - accuracy: 0.9005\n",
      "Epoch 115/150\n",
      "877/877 - 2s - loss: 0.2172 - accuracy: 0.9025\n",
      "Epoch 116/150\n",
      "877/877 - 2s - loss: 0.2175 - accuracy: 0.9012\n",
      "Epoch 117/150\n",
      "877/877 - 2s - loss: 0.2187 - accuracy: 0.9002\n",
      "Epoch 118/150\n",
      "877/877 - 2s - loss: 0.2174 - accuracy: 0.9024\n",
      "Epoch 119/150\n",
      "877/877 - 2s - loss: 0.2160 - accuracy: 0.9027\n",
      "Epoch 120/150\n",
      "877/877 - 2s - loss: 0.2156 - accuracy: 0.9030 - val_loss: 0.1945 - val_accuracy: 0.9128\n",
      "Epoch 121/150\n",
      "877/877 - 2s - loss: 0.2147 - accuracy: 0.9035\n",
      "Epoch 122/150\n",
      "877/877 - 2s - loss: 0.2149 - accuracy: 0.9024\n",
      "Epoch 123/150\n",
      "877/877 - 2s - loss: 0.2135 - accuracy: 0.9030\n",
      "Epoch 124/150\n",
      "877/877 - 2s - loss: 0.2143 - accuracy: 0.9032\n",
      "Epoch 125/150\n",
      "877/877 - 2s - loss: 0.2146 - accuracy: 0.9017\n",
      "Epoch 126/150\n",
      "877/877 - 2s - loss: 0.2122 - accuracy: 0.9036\n",
      "Epoch 127/150\n",
      "877/877 - 2s - loss: 0.2137 - accuracy: 0.9036\n",
      "Epoch 128/150\n",
      "877/877 - 2s - loss: 0.2118 - accuracy: 0.9050\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 - 2s - loss: 0.2122 - accuracy: 0.9060\n",
      "Epoch 130/150\n",
      "877/877 - 2s - loss: 0.2127 - accuracy: 0.9047 - val_loss: 0.1955 - val_accuracy: 0.9145\n",
      "Epoch 131/150\n",
      "877/877 - 2s - loss: 0.2118 - accuracy: 0.9054\n",
      "Epoch 132/150\n",
      "877/877 - 2s - loss: 0.2114 - accuracy: 0.9048\n",
      "Epoch 133/150\n",
      "877/877 - 2s - loss: 0.2107 - accuracy: 0.9050\n",
      "Epoch 134/150\n",
      "877/877 - 2s - loss: 0.2098 - accuracy: 0.9064\n",
      "Epoch 135/150\n",
      "877/877 - 2s - loss: 0.2097 - accuracy: 0.9056\n",
      "Epoch 136/150\n",
      "877/877 - 2s - loss: 0.2102 - accuracy: 0.9056\n",
      "Epoch 137/150\n",
      "877/877 - 2s - loss: 0.2101 - accuracy: 0.9048\n",
      "Epoch 138/150\n",
      "877/877 - 2s - loss: 0.2082 - accuracy: 0.9062\n",
      "Epoch 139/150\n",
      "877/877 - 2s - loss: 0.2084 - accuracy: 0.9055\n",
      "Epoch 140/150\n",
      "877/877 - 2s - loss: 0.2075 - accuracy: 0.9069 - val_loss: 0.1912 - val_accuracy: 0.9151\n",
      "Epoch 141/150\n",
      "877/877 - 2s - loss: 0.2071 - accuracy: 0.9069\n",
      "Epoch 142/150\n",
      "877/877 - 2s - loss: 0.2069 - accuracy: 0.9067\n",
      "Epoch 143/150\n",
      "877/877 - 2s - loss: 0.2063 - accuracy: 0.9067\n",
      "Epoch 144/150\n",
      "877/877 - 2s - loss: 0.2066 - accuracy: 0.9065\n",
      "Epoch 145/150\n",
      "877/877 - 2s - loss: 0.2051 - accuracy: 0.9066\n",
      "Epoch 146/150\n",
      "877/877 - 2s - loss: 0.2053 - accuracy: 0.9078\n",
      "Epoch 147/150\n",
      "877/877 - 2s - loss: 0.2045 - accuracy: 0.9076\n",
      "Epoch 148/150\n",
      "877/877 - 2s - loss: 0.2048 - accuracy: 0.9074\n",
      "Epoch 149/150\n",
      "877/877 - 2s - loss: 0.2040 - accuracy: 0.9078\n",
      "Epoch 150/150\n",
      "877/877 - 2s - loss: 0.2038 - accuracy: 0.9076 - val_loss: 0.1929 - val_accuracy: 0.9144\n",
      "Print Time for taining:  594.847605334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_7_layer_call_fn, dense_7_layer_call_and_return_conditional_losses, gather_nodes_outgoing_1_layer_call_fn, gather_nodes_outgoing_1_layer_call_and_return_conditional_losses, dense_8_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_10_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_10_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5559  349]\n",
      " [ 300 1375]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n",
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:654: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MCC = numpy.sqrt(Q_eigenValue[:, :, -2])  # 2nd highest eigenvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 64) 640         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 196)    903364      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 196)    345940      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 16, 16, 512)  401920      conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 32, 32, 256)  524544      conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 2)  130         conv2d_55[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 33s 1s/step - loss: 0.2261 - iou: 0.3707 - val_loss: 0.2777 - val_iou: 0.6168\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27773, saving model to segm_ALL_.h5\n",
      "[TensorShape([28131, None, 12]), TensorShape([28131, None, 1]), TensorShape([28131, None, 2])]\n",
      "[TensorShape([7586, None, 12]), TensorShape([7586, None, 1]), TensorShape([7586, None, 2])]\n",
      "(28131,) (7586,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_1 (GCN)                     (None, None, 64)     4160        dense_13[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_1 (PoolingNodes)  (None, 64)           0           gcn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_1 (MLP)                     (None, 1)            19040       pooling_nodes_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/gcn_1/pooling_weighted_local_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_4/gcn_1/pooling_weighted_local_edges_2/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/gcn_1/pooling_weighted_local_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/gcn_1/gather_nodes_outgoing_2/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_4/gcn_1/gather_nodes_outgoing_2/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/gcn_1/gather_nodes_outgoing_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 - 3s - loss: 0.5053 - accuracy: 0.8191\n",
      "Epoch 2/150\n",
      "880/880 - 2s - loss: 0.3046 - accuracy: 0.8620\n",
      "Epoch 3/150\n",
      "880/880 - 2s - loss: 0.2729 - accuracy: 0.8734\n",
      "Epoch 4/150\n",
      "880/880 - 2s - loss: 0.2593 - accuracy: 0.8812\n",
      "Epoch 5/150\n",
      "880/880 - 2s - loss: 0.2593 - accuracy: 0.8818\n",
      "Epoch 6/150\n",
      "880/880 - 2s - loss: 0.2525 - accuracy: 0.8834\n",
      "Epoch 7/150\n",
      "880/880 - 2s - loss: 0.2505 - accuracy: 0.8862\n",
      "Epoch 8/150\n",
      "880/880 - 2s - loss: 0.2550 - accuracy: 0.8840\n",
      "Epoch 9/150\n",
      "880/880 - 2s - loss: 0.2467 - accuracy: 0.8878\n",
      "Epoch 10/150\n",
      "880/880 - 3s - loss: 0.2482 - accuracy: 0.8855 - val_loss: 0.2170 - val_accuracy: 0.9043\n",
      "Epoch 11/150\n",
      "880/880 - 2s - loss: 0.2454 - accuracy: 0.8876\n",
      "Epoch 12/150\n",
      "880/880 - 2s - loss: 0.2431 - accuracy: 0.8891\n",
      "Epoch 13/150\n",
      "880/880 - 2s - loss: 0.2420 - accuracy: 0.8893\n",
      "Epoch 14/150\n",
      "880/880 - 2s - loss: 0.2430 - accuracy: 0.8893\n",
      "Epoch 15/150\n",
      "880/880 - 2s - loss: 0.2398 - accuracy: 0.8901\n",
      "Epoch 16/150\n",
      "880/880 - 2s - loss: 0.2412 - accuracy: 0.8887\n",
      "Epoch 17/150\n",
      "880/880 - 2s - loss: 0.2410 - accuracy: 0.8909\n",
      "Epoch 18/150\n",
      "880/880 - 2s - loss: 0.2388 - accuracy: 0.8904\n",
      "Epoch 19/150\n",
      "880/880 - 2s - loss: 0.2379 - accuracy: 0.8909\n",
      "Epoch 20/150\n",
      "880/880 - 2s - loss: 0.2351 - accuracy: 0.8930 - val_loss: 0.2356 - val_accuracy: 0.8961\n",
      "Epoch 21/150\n",
      "880/880 - 2s - loss: 0.2374 - accuracy: 0.8918\n",
      "Epoch 22/150\n",
      "880/880 - 2s - loss: 0.2348 - accuracy: 0.8931\n",
      "Epoch 23/150\n",
      "880/880 - 2s - loss: 0.2364 - accuracy: 0.8926\n",
      "Epoch 24/150\n",
      "880/880 - 2s - loss: 0.2360 - accuracy: 0.8929\n",
      "Epoch 25/150\n",
      "880/880 - 2s - loss: 0.2342 - accuracy: 0.8923\n",
      "Epoch 26/150\n",
      "880/880 - 2s - loss: 0.2336 - accuracy: 0.8929\n",
      "Epoch 27/150\n",
      "880/880 - 2s - loss: 0.2336 - accuracy: 0.8924\n",
      "Epoch 28/150\n",
      "880/880 - 2s - loss: 0.2324 - accuracy: 0.8947\n",
      "Epoch 29/150\n",
      "880/880 - 2s - loss: 0.2332 - accuracy: 0.8927\n",
      "Epoch 30/150\n",
      "880/880 - 2s - loss: 0.2329 - accuracy: 0.8924 - val_loss: 0.2027 - val_accuracy: 0.9098\n",
      "Epoch 31/150\n",
      "880/880 - 2s - loss: 0.2301 - accuracy: 0.8950\n",
      "Epoch 32/150\n",
      "880/880 - 2s - loss: 0.2299 - accuracy: 0.8949\n",
      "Epoch 33/150\n",
      "880/880 - 2s - loss: 0.2338 - accuracy: 0.8931\n",
      "Epoch 34/150\n",
      "880/880 - 2s - loss: 0.2318 - accuracy: 0.8937\n",
      "Epoch 35/150\n",
      "880/880 - 2s - loss: 0.2299 - accuracy: 0.8951\n",
      "Epoch 36/150\n",
      "880/880 - 2s - loss: 0.2311 - accuracy: 0.8914\n",
      "Epoch 37/150\n",
      "880/880 - 2s - loss: 0.2295 - accuracy: 0.8948\n",
      "Epoch 38/150\n",
      "880/880 - 2s - loss: 0.2306 - accuracy: 0.8948\n",
      "Epoch 39/150\n",
      "880/880 - 2s - loss: 0.2300 - accuracy: 0.8943\n",
      "Epoch 40/150\n",
      "880/880 - 2s - loss: 0.2309 - accuracy: 0.8932 - val_loss: 0.2043 - val_accuracy: 0.9113\n",
      "Epoch 41/150\n",
      "880/880 - 2s - loss: 0.2289 - accuracy: 0.8942\n",
      "Epoch 42/150\n",
      "880/880 - 2s - loss: 0.2290 - accuracy: 0.8952\n",
      "Epoch 43/150\n",
      "880/880 - 2s - loss: 0.2282 - accuracy: 0.8957\n",
      "Epoch 44/150\n",
      "880/880 - 2s - loss: 0.2288 - accuracy: 0.8947\n",
      "Epoch 45/150\n",
      "880/880 - 2s - loss: 0.2298 - accuracy: 0.8944\n",
      "Epoch 46/150\n",
      "880/880 - 2s - loss: 0.2296 - accuracy: 0.8946\n",
      "Epoch 47/150\n",
      "880/880 - 2s - loss: 0.2293 - accuracy: 0.8953\n",
      "Epoch 48/150\n",
      "880/880 - 2s - loss: 0.2263 - accuracy: 0.8972\n",
      "Epoch 49/150\n",
      "880/880 - 2s - loss: 0.2261 - accuracy: 0.8966\n",
      "Epoch 50/150\n",
      "880/880 - 2s - loss: 0.2273 - accuracy: 0.8953 - val_loss: 0.2221 - val_accuracy: 0.9110\n",
      "Epoch 51/150\n",
      "880/880 - 2s - loss: 0.2284 - accuracy: 0.8964\n",
      "Epoch 52/150\n",
      "880/880 - 2s - loss: 0.2273 - accuracy: 0.8956\n",
      "Epoch 53/150\n",
      "880/880 - 2s - loss: 0.2270 - accuracy: 0.8972\n",
      "Epoch 54/150\n",
      "880/880 - 2s - loss: 0.2285 - accuracy: 0.8971\n",
      "Epoch 55/150\n",
      "880/880 - 2s - loss: 0.2306 - accuracy: 0.8951\n",
      "Epoch 56/150\n",
      "880/880 - 2s - loss: 0.2249 - accuracy: 0.8979\n",
      "Epoch 57/150\n",
      "880/880 - 2s - loss: 0.2263 - accuracy: 0.8968\n",
      "Epoch 58/150\n",
      "880/880 - 2s - loss: 0.2265 - accuracy: 0.8974\n",
      "Epoch 59/150\n",
      "880/880 - 2s - loss: 0.2265 - accuracy: 0.8965\n",
      "Epoch 60/150\n",
      "880/880 - 2s - loss: 0.2265 - accuracy: 0.8975 - val_loss: 0.2043 - val_accuracy: 0.9110\n",
      "Epoch 61/150\n",
      "880/880 - 2s - loss: 0.2251 - accuracy: 0.8968\n",
      "Epoch 62/150\n",
      "880/880 - 2s - loss: 0.2254 - accuracy: 0.8974\n",
      "Epoch 63/150\n",
      "880/880 - 2s - loss: 0.2256 - accuracy: 0.8960\n",
      "Epoch 64/150\n",
      "880/880 - 2s - loss: 0.2261 - accuracy: 0.8979\n",
      "Epoch 65/150\n",
      "880/880 - 2s - loss: 0.2278 - accuracy: 0.8967\n",
      "Epoch 66/150\n",
      "880/880 - 2s - loss: 0.2276 - accuracy: 0.8962\n",
      "Epoch 67/150\n",
      "880/880 - 2s - loss: 0.2252 - accuracy: 0.8977\n",
      "Epoch 68/150\n",
      "880/880 - 2s - loss: 0.2247 - accuracy: 0.8973\n",
      "Epoch 69/150\n",
      "880/880 - 2s - loss: 0.2245 - accuracy: 0.8966\n",
      "Epoch 70/150\n",
      "880/880 - 2s - loss: 0.2248 - accuracy: 0.8985 - val_loss: 0.2026 - val_accuracy: 0.9109\n",
      "Epoch 71/150\n",
      "880/880 - 2s - loss: 0.2239 - accuracy: 0.8987\n",
      "Epoch 72/150\n",
      "880/880 - 2s - loss: 0.2265 - accuracy: 0.8968\n",
      "Epoch 73/150\n",
      "880/880 - 2s - loss: 0.2247 - accuracy: 0.8969\n",
      "Epoch 74/150\n",
      "880/880 - 2s - loss: 0.2242 - accuracy: 0.8974\n",
      "Epoch 75/150\n",
      "880/880 - 2s - loss: 0.2252 - accuracy: 0.8984\n",
      "Epoch 76/150\n",
      "880/880 - 2s - loss: 0.2234 - accuracy: 0.8989\n",
      "Epoch 77/150\n",
      "880/880 - 2s - loss: 0.2234 - accuracy: 0.8985\n",
      "Epoch 78/150\n",
      "880/880 - 2s - loss: 0.2240 - accuracy: 0.8984\n",
      "Epoch 79/150\n",
      "880/880 - 2s - loss: 0.2247 - accuracy: 0.8977\n",
      "Epoch 80/150\n",
      "880/880 - 2s - loss: 0.2252 - accuracy: 0.8971 - val_loss: 0.1965 - val_accuracy: 0.9138\n",
      "Epoch 81/150\n",
      "880/880 - 2s - loss: 0.2225 - accuracy: 0.8982\n",
      "Epoch 82/150\n",
      "880/880 - 2s - loss: 0.2239 - accuracy: 0.8971\n",
      "Epoch 83/150\n",
      "880/880 - 2s - loss: 0.2213 - accuracy: 0.8999\n",
      "Epoch 84/150\n",
      "880/880 - 2s - loss: 0.2235 - accuracy: 0.8979\n",
      "Epoch 85/150\n",
      "880/880 - 2s - loss: 0.2246 - accuracy: 0.8977\n",
      "Epoch 86/150\n",
      "880/880 - 2s - loss: 0.2245 - accuracy: 0.8979\n",
      "Epoch 87/150\n",
      "880/880 - 2s - loss: 0.2236 - accuracy: 0.8984\n",
      "Epoch 88/150\n",
      "880/880 - 2s - loss: 0.2253 - accuracy: 0.8971\n",
      "Epoch 89/150\n",
      "880/880 - 2s - loss: 0.2217 - accuracy: 0.8994\n",
      "Epoch 90/150\n",
      "880/880 - 3s - loss: 0.2230 - accuracy: 0.8992 - val_loss: 0.1956 - val_accuracy: 0.9138\n",
      "Epoch 91/150\n",
      "880/880 - 2s - loss: 0.2236 - accuracy: 0.8984\n",
      "Epoch 92/150\n",
      "880/880 - 2s - loss: 0.2212 - accuracy: 0.8979\n",
      "Epoch 93/150\n",
      "880/880 - 2s - loss: 0.2210 - accuracy: 0.8998\n",
      "Epoch 94/150\n",
      "880/880 - 2s - loss: 0.2217 - accuracy: 0.8983\n",
      "Epoch 95/150\n",
      "880/880 - 2s - loss: 0.2260 - accuracy: 0.8973\n",
      "Epoch 96/150\n",
      "880/880 - 2s - loss: 0.2242 - accuracy: 0.8987\n",
      "Epoch 97/150\n",
      "880/880 - 2s - loss: 0.2214 - accuracy: 0.8983\n",
      "Epoch 98/150\n",
      "880/880 - 2s - loss: 0.2213 - accuracy: 0.9004\n",
      "Epoch 99/150\n",
      "880/880 - 2s - loss: 0.2231 - accuracy: 0.8978\n",
      "Epoch 100/150\n",
      "880/880 - 2s - loss: 0.2241 - accuracy: 0.8993 - val_loss: 0.2154 - val_accuracy: 0.9079\n",
      "Epoch 101/150\n",
      "880/880 - 2s - loss: 0.2225 - accuracy: 0.8990\n",
      "Epoch 102/150\n",
      "880/880 - 2s - loss: 0.2211 - accuracy: 0.8997\n",
      "Epoch 103/150\n",
      "880/880 - 2s - loss: 0.2218 - accuracy: 0.8983\n",
      "Epoch 104/150\n",
      "880/880 - 2s - loss: 0.2202 - accuracy: 0.8977\n",
      "Epoch 105/150\n",
      "880/880 - 2s - loss: 0.2208 - accuracy: 0.8995\n",
      "Epoch 106/150\n",
      "880/880 - 2s - loss: 0.2200 - accuracy: 0.9000\n",
      "Epoch 107/150\n",
      "880/880 - 2s - loss: 0.2204 - accuracy: 0.8993\n",
      "Epoch 108/150\n",
      "880/880 - 2s - loss: 0.2189 - accuracy: 0.8997\n",
      "Epoch 109/150\n",
      "880/880 - 2s - loss: 0.2193 - accuracy: 0.8989\n",
      "Epoch 110/150\n",
      "880/880 - 2s - loss: 0.2193 - accuracy: 0.9009 - val_loss: 0.1982 - val_accuracy: 0.9150\n",
      "Epoch 111/150\n",
      "880/880 - 2s - loss: 0.2203 - accuracy: 0.8984\n",
      "Epoch 112/150\n",
      "880/880 - 2s - loss: 0.2206 - accuracy: 0.8984\n",
      "Epoch 113/150\n",
      "880/880 - 2s - loss: 0.2170 - accuracy: 0.9009\n",
      "Epoch 114/150\n",
      "880/880 - 2s - loss: 0.2228 - accuracy: 0.8998\n",
      "Epoch 115/150\n",
      "880/880 - 2s - loss: 0.2181 - accuracy: 0.9015\n",
      "Epoch 116/150\n",
      "880/880 - 2s - loss: 0.2168 - accuracy: 0.9016\n",
      "Epoch 117/150\n",
      "880/880 - 2s - loss: 0.2159 - accuracy: 0.9015\n",
      "Epoch 118/150\n",
      "880/880 - 2s - loss: 0.2156 - accuracy: 0.9014\n",
      "Epoch 119/150\n",
      "880/880 - 2s - loss: 0.2159 - accuracy: 0.8999\n",
      "Epoch 120/150\n",
      "880/880 - 2s - loss: 0.2152 - accuracy: 0.9011 - val_loss: 0.1998 - val_accuracy: 0.9088\n",
      "Epoch 121/150\n",
      "880/880 - 2s - loss: 0.2154 - accuracy: 0.9007\n",
      "Epoch 122/150\n",
      "880/880 - 2s - loss: 0.2147 - accuracy: 0.9016\n",
      "Epoch 123/150\n",
      "880/880 - 2s - loss: 0.2149 - accuracy: 0.9013\n",
      "Epoch 124/150\n",
      "880/880 - 2s - loss: 0.2144 - accuracy: 0.9011\n",
      "Epoch 125/150\n",
      "880/880 - 2s - loss: 0.2134 - accuracy: 0.9037\n",
      "Epoch 126/150\n",
      "880/880 - 2s - loss: 0.2135 - accuracy: 0.9026\n",
      "Epoch 127/150\n",
      "880/880 - 2s - loss: 0.2128 - accuracy: 0.9027\n",
      "Epoch 128/150\n",
      "880/880 - 2s - loss: 0.2126 - accuracy: 0.9018\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 - 2s - loss: 0.2123 - accuracy: 0.9022\n",
      "Epoch 130/150\n",
      "880/880 - 2s - loss: 0.2109 - accuracy: 0.9026 - val_loss: 0.1966 - val_accuracy: 0.9122\n",
      "Epoch 131/150\n",
      "880/880 - 2s - loss: 0.2112 - accuracy: 0.9028\n",
      "Epoch 132/150\n",
      "880/880 - 2s - loss: 0.2103 - accuracy: 0.9026\n",
      "Epoch 133/150\n",
      "880/880 - 2s - loss: 0.2103 - accuracy: 0.9041\n",
      "Epoch 134/150\n",
      "880/880 - 2s - loss: 0.2092 - accuracy: 0.9046\n",
      "Epoch 135/150\n",
      "880/880 - 2s - loss: 0.2094 - accuracy: 0.9044\n",
      "Epoch 136/150\n",
      "880/880 - 2s - loss: 0.2091 - accuracy: 0.9053\n",
      "Epoch 137/150\n",
      "880/880 - 2s - loss: 0.2083 - accuracy: 0.9047\n",
      "Epoch 138/150\n",
      "880/880 - 2s - loss: 0.2090 - accuracy: 0.9038\n",
      "Epoch 139/150\n",
      "880/880 - 2s - loss: 0.2079 - accuracy: 0.9044\n",
      "Epoch 140/150\n",
      "880/880 - 2s - loss: 0.2065 - accuracy: 0.9067 - val_loss: 0.2005 - val_accuracy: 0.9135\n",
      "Epoch 141/150\n",
      "880/880 - 2s - loss: 0.2075 - accuracy: 0.9052\n",
      "Epoch 142/150\n",
      "880/880 - 2s - loss: 0.2066 - accuracy: 0.9052\n",
      "Epoch 143/150\n",
      "880/880 - 2s - loss: 0.2058 - accuracy: 0.9044\n",
      "Epoch 144/150\n",
      "880/880 - 2s - loss: 0.2055 - accuracy: 0.9060\n",
      "Epoch 145/150\n",
      "880/880 - 2s - loss: 0.2051 - accuracy: 0.9059\n",
      "Epoch 146/150\n",
      "880/880 - 2s - loss: 0.2041 - accuracy: 0.9063\n",
      "Epoch 147/150\n",
      "880/880 - 2s - loss: 0.2040 - accuracy: 0.9057\n",
      "Epoch 148/150\n",
      "880/880 - 2s - loss: 0.2038 - accuracy: 0.9065\n",
      "Epoch 149/150\n",
      "880/880 - 2s - loss: 0.2032 - accuracy: 0.9072\n",
      "Epoch 150/150\n",
      "880/880 - 2s - loss: 0.2029 - accuracy: 0.9063 - val_loss: 0.2061 - val_accuracy: 0.9158\n",
      "Print Time for taining:  630.2840122990001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_14_layer_call_fn, dense_14_layer_call_and_return_conditional_losses, gather_nodes_outgoing_2_layer_call_fn, gather_nodes_outgoing_2_layer_call_and_return_conditional_losses, dense_15_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_15_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_15_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5476  392]\n",
      " [ 247 1471]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n",
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 64) 640         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 196)    903364      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 196)    345940      conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 16, 16, 512)  401920      conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 32, 32, 256)  524544      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 512)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 2)  130         conv2d_74[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 33s 1s/step - loss: 0.2375 - iou: 0.3451 - val_loss: 0.1880 - val_iou: 0.4191\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18801, saving model to segm_ALL_.h5\n",
      "[TensorShape([8833, None, 12]), TensorShape([8833, None, 1]), TensorShape([8833, None, 2])]\n",
      "[TensorShape([2182, None, 12]), TensorShape([2182, None, 1]), TensorShape([2182, None, 2])]\n",
      "(8833,) (2182,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_2 (GCN)                     (None, None, 64)     4160        dense_20[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_2 (PoolingNodes)  (None, 64)           0           gcn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_2 (MLP)                     (None, 1)            19040       pooling_nodes_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/gcn_2/pooling_weighted_local_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/gcn_2/pooling_weighted_local_edges_3/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/gcn_2/pooling_weighted_local_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/gcn_2/gather_nodes_outgoing_3/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_6/gcn_2/gather_nodes_outgoing_3/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/gcn_2/gather_nodes_outgoing_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 - 1s - loss: 0.6277 - accuracy: 0.7683\n",
      "Epoch 2/150\n",
      "277/277 - 1s - loss: 0.4618 - accuracy: 0.7848\n",
      "Epoch 3/150\n",
      "277/277 - 1s - loss: 0.4147 - accuracy: 0.8027\n",
      "Epoch 4/150\n",
      "277/277 - 1s - loss: 0.3935 - accuracy: 0.8071\n",
      "Epoch 5/150\n",
      "277/277 - 1s - loss: 0.3733 - accuracy: 0.8159\n",
      "Epoch 6/150\n",
      "277/277 - 1s - loss: 0.3712 - accuracy: 0.8132\n",
      "Epoch 7/150\n",
      "277/277 - 1s - loss: 0.3630 - accuracy: 0.8224\n",
      "Epoch 8/150\n",
      "277/277 - 1s - loss: 0.3537 - accuracy: 0.8217\n",
      "Epoch 9/150\n",
      "277/277 - 1s - loss: 0.3384 - accuracy: 0.8288\n",
      "Epoch 10/150\n",
      "277/277 - 1s - loss: 0.3382 - accuracy: 0.8302 - val_loss: 0.3736 - val_accuracy: 0.8158\n",
      "Epoch 11/150\n",
      "277/277 - 1s - loss: 0.3407 - accuracy: 0.8244\n",
      "Epoch 12/150\n",
      "277/277 - 1s - loss: 0.3370 - accuracy: 0.8344\n",
      "Epoch 13/150\n",
      "277/277 - 1s - loss: 0.3355 - accuracy: 0.8310\n",
      "Epoch 14/150\n",
      "277/277 - 1s - loss: 0.3439 - accuracy: 0.8219\n",
      "Epoch 15/150\n",
      "277/277 - 1s - loss: 0.3397 - accuracy: 0.8275\n",
      "Epoch 16/150\n",
      "277/277 - 1s - loss: 0.3337 - accuracy: 0.8335\n",
      "Epoch 17/150\n",
      "277/277 - 1s - loss: 0.3272 - accuracy: 0.8392\n",
      "Epoch 18/150\n",
      "277/277 - 1s - loss: 0.3300 - accuracy: 0.8356\n",
      "Epoch 19/150\n",
      "277/277 - 1s - loss: 0.3643 - accuracy: 0.8193\n",
      "Epoch 20/150\n",
      "277/277 - 1s - loss: 0.3268 - accuracy: 0.8395 - val_loss: 0.3077 - val_accuracy: 0.8520\n",
      "Epoch 21/150\n",
      "277/277 - 1s - loss: 0.3182 - accuracy: 0.8431\n",
      "Epoch 22/150\n",
      "277/277 - 1s - loss: 0.3175 - accuracy: 0.8450\n",
      "Epoch 23/150\n",
      "277/277 - 1s - loss: 0.3117 - accuracy: 0.8454\n",
      "Epoch 24/150\n",
      "277/277 - 1s - loss: 0.3135 - accuracy: 0.8463\n",
      "Epoch 25/150\n",
      "277/277 - 1s - loss: 0.3141 - accuracy: 0.8446\n",
      "Epoch 26/150\n",
      "277/277 - 1s - loss: 0.3183 - accuracy: 0.8451\n",
      "Epoch 27/150\n",
      "277/277 - 1s - loss: 0.3176 - accuracy: 0.8457\n",
      "Epoch 28/150\n",
      "277/277 - 1s - loss: 0.3079 - accuracy: 0.8497\n",
      "Epoch 29/150\n",
      "277/277 - 1s - loss: 0.3090 - accuracy: 0.8490\n",
      "Epoch 30/150\n",
      "277/277 - 1s - loss: 0.3130 - accuracy: 0.8481 - val_loss: 0.3007 - val_accuracy: 0.8584\n",
      "Epoch 31/150\n",
      "277/277 - 1s - loss: 0.3157 - accuracy: 0.8506\n",
      "Epoch 32/150\n",
      "277/277 - 1s - loss: 0.3108 - accuracy: 0.8481\n",
      "Epoch 33/150\n",
      "277/277 - 1s - loss: 0.3067 - accuracy: 0.8557\n",
      "Epoch 34/150\n",
      "277/277 - 1s - loss: 0.3063 - accuracy: 0.8520\n",
      "Epoch 35/150\n",
      "277/277 - 1s - loss: 0.3097 - accuracy: 0.8469\n",
      "Epoch 36/150\n",
      "277/277 - 1s - loss: 0.3056 - accuracy: 0.8503\n",
      "Epoch 37/150\n",
      "277/277 - 1s - loss: 0.3046 - accuracy: 0.8481\n",
      "Epoch 38/150\n",
      "277/277 - 1s - loss: 0.3028 - accuracy: 0.8524\n",
      "Epoch 39/150\n",
      "277/277 - 1s - loss: 0.3019 - accuracy: 0.8518\n",
      "Epoch 40/150\n",
      "277/277 - 1s - loss: 0.3032 - accuracy: 0.8493 - val_loss: 0.3201 - val_accuracy: 0.8378\n",
      "Epoch 41/150\n",
      "277/277 - 1s - loss: 0.3067 - accuracy: 0.8517\n",
      "Epoch 42/150\n",
      "277/277 - 1s - loss: 0.3011 - accuracy: 0.8523\n",
      "Epoch 43/150\n",
      "277/277 - 1s - loss: 0.3009 - accuracy: 0.8540\n",
      "Epoch 44/150\n",
      "277/277 - 1s - loss: 0.3011 - accuracy: 0.8541\n",
      "Epoch 45/150\n",
      "277/277 - 1s - loss: 0.3077 - accuracy: 0.8486\n",
      "Epoch 46/150\n",
      "277/277 - 1s - loss: 0.3011 - accuracy: 0.8544\n",
      "Epoch 47/150\n",
      "277/277 - 1s - loss: 0.3031 - accuracy: 0.8552\n",
      "Epoch 48/150\n",
      "277/277 - 1s - loss: 0.3030 - accuracy: 0.8504\n",
      "Epoch 49/150\n",
      "277/277 - 1s - loss: 0.2991 - accuracy: 0.8544\n",
      "Epoch 50/150\n",
      "277/277 - 1s - loss: 0.3032 - accuracy: 0.8525 - val_loss: 0.2927 - val_accuracy: 0.8630\n",
      "Epoch 51/150\n",
      "277/277 - 1s - loss: 0.2976 - accuracy: 0.8558\n",
      "Epoch 52/150\n",
      "277/277 - 1s - loss: 0.2961 - accuracy: 0.8579\n",
      "Epoch 53/150\n",
      "277/277 - 1s - loss: 0.3072 - accuracy: 0.8519\n",
      "Epoch 54/150\n",
      "277/277 - 1s - loss: 0.2983 - accuracy: 0.8587\n",
      "Epoch 55/150\n",
      "277/277 - 1s - loss: 0.2969 - accuracy: 0.8562\n",
      "Epoch 56/150\n",
      "277/277 - 1s - loss: 0.2975 - accuracy: 0.8533\n",
      "Epoch 57/150\n",
      "277/277 - 1s - loss: 0.3065 - accuracy: 0.8515\n",
      "Epoch 58/150\n",
      "277/277 - 1s - loss: 0.3108 - accuracy: 0.8442\n",
      "Epoch 59/150\n",
      "277/277 - 1s - loss: 0.3012 - accuracy: 0.8547\n",
      "Epoch 60/150\n",
      "277/277 - 1s - loss: 0.2942 - accuracy: 0.8540 - val_loss: 0.2876 - val_accuracy: 0.8588\n",
      "Epoch 61/150\n",
      "277/277 - 1s - loss: 0.2908 - accuracy: 0.8559\n",
      "Epoch 62/150\n",
      "277/277 - 1s - loss: 0.2905 - accuracy: 0.8584\n",
      "Epoch 63/150\n",
      "277/277 - 1s - loss: 0.2931 - accuracy: 0.8566\n",
      "Epoch 64/150\n",
      "277/277 - 1s - loss: 0.2956 - accuracy: 0.8570\n",
      "Epoch 65/150\n",
      "277/277 - 1s - loss: 0.2925 - accuracy: 0.8571\n",
      "Epoch 66/150\n",
      "277/277 - 1s - loss: 0.2926 - accuracy: 0.8580\n",
      "Epoch 67/150\n",
      "277/277 - 1s - loss: 0.2914 - accuracy: 0.8589\n",
      "Epoch 68/150\n",
      "277/277 - 1s - loss: 0.2912 - accuracy: 0.8594\n",
      "Epoch 69/150\n",
      "277/277 - 1s - loss: 0.2926 - accuracy: 0.8601\n",
      "Epoch 70/150\n",
      "277/277 - 1s - loss: 0.2917 - accuracy: 0.8581 - val_loss: 0.3132 - val_accuracy: 0.8428\n",
      "Epoch 71/150\n",
      "277/277 - 1s - loss: 0.2914 - accuracy: 0.8586\n",
      "Epoch 72/150\n",
      "277/277 - 1s - loss: 0.2884 - accuracy: 0.8600\n",
      "Epoch 73/150\n",
      "277/277 - 1s - loss: 0.2894 - accuracy: 0.8596\n",
      "Epoch 74/150\n",
      "277/277 - 1s - loss: 0.2875 - accuracy: 0.8622\n",
      "Epoch 75/150\n",
      "277/277 - 1s - loss: 0.2888 - accuracy: 0.8613\n",
      "Epoch 76/150\n",
      "277/277 - 1s - loss: 0.2913 - accuracy: 0.8584\n",
      "Epoch 77/150\n",
      "277/277 - 1s - loss: 0.2887 - accuracy: 0.8570\n",
      "Epoch 78/150\n",
      "277/277 - 1s - loss: 0.2908 - accuracy: 0.8586\n",
      "Epoch 79/150\n",
      "277/277 - 1s - loss: 0.2866 - accuracy: 0.8605\n",
      "Epoch 80/150\n",
      "277/277 - 1s - loss: 0.2905 - accuracy: 0.8606 - val_loss: 0.2805 - val_accuracy: 0.8611\n",
      "Epoch 81/150\n",
      "277/277 - 1s - loss: 0.2983 - accuracy: 0.8507\n",
      "Epoch 82/150\n",
      "277/277 - 1s - loss: 0.2857 - accuracy: 0.8615\n",
      "Epoch 83/150\n",
      "277/277 - 1s - loss: 0.2863 - accuracy: 0.8606\n",
      "Epoch 84/150\n",
      "277/277 - 1s - loss: 0.2853 - accuracy: 0.8614\n",
      "Epoch 85/150\n",
      "277/277 - 1s - loss: 0.2865 - accuracy: 0.8587\n",
      "Epoch 86/150\n",
      "277/277 - 1s - loss: 0.2862 - accuracy: 0.8607\n",
      "Epoch 87/150\n",
      "277/277 - 1s - loss: 0.2803 - accuracy: 0.8644\n",
      "Epoch 88/150\n",
      "277/277 - 1s - loss: 0.2813 - accuracy: 0.8638\n",
      "Epoch 89/150\n",
      "277/277 - 1s - loss: 0.2817 - accuracy: 0.8622\n",
      "Epoch 90/150\n",
      "277/277 - 1s - loss: 0.2844 - accuracy: 0.8596 - val_loss: 0.2851 - val_accuracy: 0.8607\n",
      "Epoch 91/150\n",
      "277/277 - 1s - loss: 0.2809 - accuracy: 0.8621\n",
      "Epoch 92/150\n",
      "277/277 - 1s - loss: 0.2792 - accuracy: 0.8602\n",
      "Epoch 93/150\n",
      "277/277 - 1s - loss: 0.2819 - accuracy: 0.8585\n",
      "Epoch 94/150\n",
      "277/277 - 1s - loss: 0.2832 - accuracy: 0.8637\n",
      "Epoch 95/150\n",
      "277/277 - 1s - loss: 0.2797 - accuracy: 0.8628\n",
      "Epoch 96/150\n",
      "277/277 - 1s - loss: 0.2946 - accuracy: 0.8581\n",
      "Epoch 97/150\n",
      "277/277 - 1s - loss: 0.2850 - accuracy: 0.8572\n",
      "Epoch 98/150\n",
      "277/277 - 1s - loss: 0.2857 - accuracy: 0.8594\n",
      "Epoch 99/150\n",
      "277/277 - 1s - loss: 0.2814 - accuracy: 0.8607\n",
      "Epoch 100/150\n",
      "277/277 - 1s - loss: 0.2946 - accuracy: 0.8576 - val_loss: 0.2860 - val_accuracy: 0.8616\n",
      "Epoch 101/150\n",
      "277/277 - 1s - loss: 0.2815 - accuracy: 0.8627\n",
      "Epoch 102/150\n",
      "277/277 - 1s - loss: 0.2749 - accuracy: 0.8627\n",
      "Epoch 103/150\n",
      "277/277 - 1s - loss: 0.2763 - accuracy: 0.8639\n",
      "Epoch 104/150\n",
      "277/277 - 1s - loss: 0.2763 - accuracy: 0.8628\n",
      "Epoch 105/150\n",
      "277/277 - 1s - loss: 0.2771 - accuracy: 0.8643\n",
      "Epoch 106/150\n",
      "277/277 - 1s - loss: 0.2785 - accuracy: 0.8623\n",
      "Epoch 107/150\n",
      "277/277 - 1s - loss: 0.2896 - accuracy: 0.8518\n",
      "Epoch 108/150\n",
      "277/277 - 1s - loss: 0.2731 - accuracy: 0.8644\n",
      "Epoch 109/150\n",
      "277/277 - 1s - loss: 0.2747 - accuracy: 0.8647\n",
      "Epoch 110/150\n",
      "277/277 - 1s - loss: 0.2695 - accuracy: 0.8664 - val_loss: 0.2794 - val_accuracy: 0.8616\n",
      "Epoch 111/150\n",
      "277/277 - 1s - loss: 0.2689 - accuracy: 0.8663\n",
      "Epoch 112/150\n",
      "277/277 - 1s - loss: 0.2760 - accuracy: 0.8636\n",
      "Epoch 113/150\n",
      "277/277 - 1s - loss: 0.2707 - accuracy: 0.8640\n",
      "Epoch 114/150\n",
      "277/277 - 1s - loss: 0.2693 - accuracy: 0.8657\n",
      "Epoch 115/150\n",
      "277/277 - 1s - loss: 0.2685 - accuracy: 0.8657\n",
      "Epoch 116/150\n",
      "277/277 - 1s - loss: 0.2666 - accuracy: 0.8688\n",
      "Epoch 117/150\n",
      "277/277 - 1s - loss: 0.2657 - accuracy: 0.8643\n",
      "Epoch 118/150\n",
      "277/277 - 1s - loss: 0.2675 - accuracy: 0.8672\n",
      "Epoch 119/150\n",
      "277/277 - 1s - loss: 0.2652 - accuracy: 0.8690\n",
      "Epoch 120/150\n",
      "277/277 - 1s - loss: 0.2663 - accuracy: 0.8678 - val_loss: 0.2954 - val_accuracy: 0.8616\n",
      "Epoch 121/150\n",
      "277/277 - 1s - loss: 0.2635 - accuracy: 0.8684\n",
      "Epoch 122/150\n",
      "277/277 - 1s - loss: 0.2604 - accuracy: 0.8694\n",
      "Epoch 123/150\n",
      "277/277 - 1s - loss: 0.2615 - accuracy: 0.8709\n",
      "Epoch 124/150\n",
      "277/277 - 1s - loss: 0.2670 - accuracy: 0.8680\n",
      "Epoch 125/150\n",
      "277/277 - 1s - loss: 0.2588 - accuracy: 0.8727\n",
      "Epoch 126/150\n",
      "277/277 - 1s - loss: 0.2569 - accuracy: 0.8723\n",
      "Epoch 127/150\n",
      "277/277 - 1s - loss: 0.2569 - accuracy: 0.8744\n",
      "Epoch 128/150\n",
      "277/277 - 1s - loss: 0.2549 - accuracy: 0.8721\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 - 1s - loss: 0.2541 - accuracy: 0.8747\n",
      "Epoch 130/150\n",
      "277/277 - 1s - loss: 0.2560 - accuracy: 0.8733 - val_loss: 0.2822 - val_accuracy: 0.8671\n",
      "Epoch 131/150\n",
      "277/277 - 1s - loss: 0.2539 - accuracy: 0.8774\n",
      "Epoch 132/150\n",
      "277/277 - 1s - loss: 0.2526 - accuracy: 0.8738\n",
      "Epoch 133/150\n",
      "277/277 - 1s - loss: 0.2509 - accuracy: 0.8739\n",
      "Epoch 134/150\n",
      "277/277 - 1s - loss: 0.2486 - accuracy: 0.8757\n",
      "Epoch 135/150\n",
      "277/277 - 1s - loss: 0.2501 - accuracy: 0.8765\n",
      "Epoch 136/150\n",
      "277/277 - 1s - loss: 0.2475 - accuracy: 0.8765\n",
      "Epoch 137/150\n",
      "277/277 - 1s - loss: 0.2467 - accuracy: 0.8777\n",
      "Epoch 138/150\n",
      "277/277 - 1s - loss: 0.2469 - accuracy: 0.8755\n",
      "Epoch 139/150\n",
      "277/277 - 1s - loss: 0.2450 - accuracy: 0.8767\n",
      "Epoch 140/150\n",
      "277/277 - 1s - loss: 0.2452 - accuracy: 0.8789 - val_loss: 0.2903 - val_accuracy: 0.8611\n",
      "Epoch 141/150\n",
      "277/277 - 1s - loss: 0.2422 - accuracy: 0.8790\n",
      "Epoch 142/150\n",
      "277/277 - 1s - loss: 0.2415 - accuracy: 0.8801\n",
      "Epoch 143/150\n",
      "277/277 - 1s - loss: 0.2442 - accuracy: 0.8784\n",
      "Epoch 144/150\n",
      "277/277 - 1s - loss: 0.2392 - accuracy: 0.8799\n",
      "Epoch 145/150\n",
      "277/277 - 1s - loss: 0.2399 - accuracy: 0.8780\n",
      "Epoch 146/150\n",
      "277/277 - 1s - loss: 0.2364 - accuracy: 0.8799\n",
      "Epoch 147/150\n",
      "277/277 - 1s - loss: 0.2361 - accuracy: 0.8803\n",
      "Epoch 148/150\n",
      "277/277 - 1s - loss: 0.2375 - accuracy: 0.8814\n",
      "Epoch 149/150\n",
      "277/277 - 1s - loss: 0.2348 - accuracy: 0.8816\n",
      "Epoch 150/150\n",
      "277/277 - 1s - loss: 0.2335 - accuracy: 0.8819 - val_loss: 0.2986 - val_accuracy: 0.8662\n",
      "Print Time for taining:  194.87391408799976\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_21_layer_call_fn, dense_21_layer_call_and_return_conditional_losses, gather_nodes_outgoing_3_layer_call_fn, gather_nodes_outgoing_3_layer_call_and_return_conditional_losses, dense_22_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_20_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_20_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1509  148]\n",
      " [ 144  381]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n",
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:654: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MCC = numpy.sqrt(Q_eigenValue[:, :, -2])  # 2nd highest eigenvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 64) 640         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 196)    903364      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 196)    345940      conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 16, 16, 512)  401920      conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 32, 32, 256)  524544      conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 512)  0           conv2d_transpose_17[0][0]        \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_18[0][0]        \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_19[0][0]        \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 128, 128, 2)  130         conv2d_93[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 33s 1s/step - loss: 0.2308 - iou: 0.3592 - val_loss: 0.1595 - val_iou: 0.5167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15951, saving model to segm_ALL_.h5\n",
      "[TensorShape([28417, None, 12]), TensorShape([28417, None, 1]), TensorShape([28417, None, 2])]\n",
      "[TensorShape([7711, None, 12]), TensorShape([7711, None, 1]), TensorShape([7711, None, 2])]\n",
      "(28417,) (7711,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_3 (GCN)                     (None, None, 64)     4160        dense_27[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_3 (PoolingNodes)  (None, 64)           0           gcn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_3 (MLP)                     (None, 1)            19040       pooling_nodes_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_8/gcn_3/pooling_weighted_local_edges_4/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_8/gcn_3/pooling_weighted_local_edges_4/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_8/gcn_3/pooling_weighted_local_edges_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_8/gcn_3/gather_nodes_outgoing_4/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_8/gcn_3/gather_nodes_outgoing_4/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_8/gcn_3/gather_nodes_outgoing_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/889 - 3s - loss: 0.4553 - accuracy: 0.8256\n",
      "Epoch 2/150\n",
      "889/889 - 2s - loss: 0.3029 - accuracy: 0.8647\n",
      "Epoch 3/150\n",
      "889/889 - 2s - loss: 0.2757 - accuracy: 0.8769\n",
      "Epoch 4/150\n",
      "889/889 - 2s - loss: 0.2572 - accuracy: 0.8849\n",
      "Epoch 5/150\n",
      "889/889 - 2s - loss: 0.2534 - accuracy: 0.8868\n",
      "Epoch 6/150\n",
      "889/889 - 2s - loss: 0.2487 - accuracy: 0.8873\n",
      "Epoch 7/150\n",
      "889/889 - 2s - loss: 0.2470 - accuracy: 0.8897\n",
      "Epoch 8/150\n",
      "889/889 - 2s - loss: 0.2463 - accuracy: 0.8866\n",
      "Epoch 9/150\n",
      "889/889 - 2s - loss: 0.2403 - accuracy: 0.8909\n",
      "Epoch 10/150\n",
      "889/889 - 3s - loss: 0.2391 - accuracy: 0.8928 - val_loss: 0.1993 - val_accuracy: 0.9097\n",
      "Epoch 11/150\n",
      "889/889 - 2s - loss: 0.2350 - accuracy: 0.8949\n",
      "Epoch 12/150\n",
      "889/889 - 2s - loss: 0.2391 - accuracy: 0.8915\n",
      "Epoch 13/150\n",
      "889/889 - 2s - loss: 0.2384 - accuracy: 0.8936\n",
      "Epoch 14/150\n",
      "889/889 - 2s - loss: 0.2348 - accuracy: 0.8935\n",
      "Epoch 15/150\n",
      "889/889 - 2s - loss: 0.2302 - accuracy: 0.8957\n",
      "Epoch 16/150\n",
      "889/889 - 2s - loss: 0.2322 - accuracy: 0.8949\n",
      "Epoch 17/150\n",
      "889/889 - 2s - loss: 0.2306 - accuracy: 0.8965\n",
      "Epoch 18/150\n",
      "889/889 - 2s - loss: 0.2312 - accuracy: 0.8954\n",
      "Epoch 19/150\n",
      "889/889 - 2s - loss: 0.2295 - accuracy: 0.8968\n",
      "Epoch 20/150\n",
      "889/889 - 2s - loss: 0.2258 - accuracy: 0.8977 - val_loss: 0.2420 - val_accuracy: 0.8867\n",
      "Epoch 21/150\n",
      "889/889 - 2s - loss: 0.2264 - accuracy: 0.8980\n",
      "Epoch 22/150\n",
      "889/889 - 2s - loss: 0.2290 - accuracy: 0.8962\n",
      "Epoch 23/150\n",
      "889/889 - 2s - loss: 0.2258 - accuracy: 0.8981\n",
      "Epoch 24/150\n",
      "889/889 - 2s - loss: 0.2245 - accuracy: 0.8984\n",
      "Epoch 25/150\n",
      "889/889 - 2s - loss: 0.2231 - accuracy: 0.8998\n",
      "Epoch 26/150\n",
      "889/889 - 2s - loss: 0.2229 - accuracy: 0.8988\n",
      "Epoch 27/150\n",
      "889/889 - 2s - loss: 0.2221 - accuracy: 0.9000\n",
      "Epoch 28/150\n",
      "889/889 - 2s - loss: 0.2192 - accuracy: 0.9000\n",
      "Epoch 29/150\n",
      "889/889 - 2s - loss: 0.2231 - accuracy: 0.8989\n",
      "Epoch 30/150\n",
      "889/889 - 2s - loss: 0.2214 - accuracy: 0.9001 - val_loss: 0.1978 - val_accuracy: 0.9156\n",
      "Epoch 31/150\n",
      "889/889 - 2s - loss: 0.2215 - accuracy: 0.9000\n",
      "Epoch 32/150\n",
      "889/889 - 2s - loss: 0.2193 - accuracy: 0.9009\n",
      "Epoch 33/150\n",
      "889/889 - 2s - loss: 0.2195 - accuracy: 0.9000\n",
      "Epoch 34/150\n",
      "889/889 - 2s - loss: 0.2212 - accuracy: 0.9003\n",
      "Epoch 35/150\n",
      "889/889 - 2s - loss: 0.2205 - accuracy: 0.9009\n",
      "Epoch 36/150\n",
      "889/889 - 2s - loss: 0.2192 - accuracy: 0.9000\n",
      "Epoch 37/150\n",
      "889/889 - 2s - loss: 0.2195 - accuracy: 0.9002\n",
      "Epoch 38/150\n",
      "889/889 - 2s - loss: 0.2189 - accuracy: 0.8991\n",
      "Epoch 39/150\n",
      "889/889 - 2s - loss: 0.2189 - accuracy: 0.9006\n",
      "Epoch 40/150\n",
      "889/889 - 2s - loss: 0.2174 - accuracy: 0.9027 - val_loss: 0.1981 - val_accuracy: 0.9121\n",
      "Epoch 41/150\n",
      "889/889 - 2s - loss: 0.2180 - accuracy: 0.9020\n",
      "Epoch 42/150\n",
      "889/889 - 2s - loss: 0.2169 - accuracy: 0.9035\n",
      "Epoch 43/150\n",
      "889/889 - 2s - loss: 0.2214 - accuracy: 0.9016\n",
      "Epoch 44/150\n",
      "889/889 - 2s - loss: 0.2185 - accuracy: 0.9008\n",
      "Epoch 45/150\n",
      "889/889 - 2s - loss: 0.2172 - accuracy: 0.9023\n",
      "Epoch 46/150\n",
      "889/889 - 2s - loss: 0.2153 - accuracy: 0.9026\n",
      "Epoch 47/150\n",
      "889/889 - 2s - loss: 0.2153 - accuracy: 0.9019\n",
      "Epoch 48/150\n",
      "889/889 - 2s - loss: 0.2182 - accuracy: 0.9007\n",
      "Epoch 49/150\n",
      "889/889 - 2s - loss: 0.2167 - accuracy: 0.9026\n",
      "Epoch 50/150\n",
      "889/889 - 2s - loss: 0.2192 - accuracy: 0.9009 - val_loss: 0.2274 - val_accuracy: 0.8955\n",
      "Epoch 51/150\n",
      "889/889 - 2s - loss: 0.2172 - accuracy: 0.9017\n",
      "Epoch 52/150\n",
      "889/889 - 2s - loss: 0.2161 - accuracy: 0.9021\n",
      "Epoch 53/150\n",
      "889/889 - 2s - loss: 0.2134 - accuracy: 0.9026\n",
      "Epoch 54/150\n",
      "889/889 - 2s - loss: 0.2147 - accuracy: 0.9038\n",
      "Epoch 55/150\n",
      "889/889 - 2s - loss: 0.2135 - accuracy: 0.9031\n",
      "Epoch 56/150\n",
      "889/889 - 2s - loss: 0.2152 - accuracy: 0.9018\n",
      "Epoch 57/150\n",
      "889/889 - 2s - loss: 0.2147 - accuracy: 0.9032\n",
      "Epoch 58/150\n",
      "889/889 - 2s - loss: 0.2152 - accuracy: 0.9037\n",
      "Epoch 59/150\n",
      "889/889 - 2s - loss: 0.2140 - accuracy: 0.9033\n",
      "Epoch 60/150\n",
      "889/889 - 2s - loss: 0.2140 - accuracy: 0.9039 - val_loss: 0.1889 - val_accuracy: 0.9132\n",
      "Epoch 61/150\n",
      "889/889 - 2s - loss: 0.2125 - accuracy: 0.9026\n",
      "Epoch 62/150\n",
      "889/889 - 2s - loss: 0.2262 - accuracy: 0.9025\n",
      "Epoch 63/150\n",
      "889/889 - 2s - loss: 0.2141 - accuracy: 0.9036\n",
      "Epoch 64/150\n",
      "889/889 - 2s - loss: 0.2145 - accuracy: 0.9017\n",
      "Epoch 65/150\n",
      "889/889 - 2s - loss: 0.2158 - accuracy: 0.9017\n",
      "Epoch 66/150\n",
      "889/889 - 2s - loss: 0.2131 - accuracy: 0.9034\n",
      "Epoch 67/150\n",
      "889/889 - 2s - loss: 0.2127 - accuracy: 0.9036\n",
      "Epoch 68/150\n",
      "889/889 - 2s - loss: 0.2133 - accuracy: 0.9038\n",
      "Epoch 69/150\n",
      "889/889 - 2s - loss: 0.2125 - accuracy: 0.9043\n",
      "Epoch 70/150\n",
      "889/889 - 2s - loss: 0.2122 - accuracy: 0.9038 - val_loss: 0.1899 - val_accuracy: 0.9152\n",
      "Epoch 71/150\n",
      "889/889 - 2s - loss: 0.2107 - accuracy: 0.9046\n",
      "Epoch 72/150\n",
      "889/889 - 2s - loss: 0.2114 - accuracy: 0.9041\n",
      "Epoch 73/150\n",
      "889/889 - 2s - loss: 0.2127 - accuracy: 0.9040\n",
      "Epoch 74/150\n",
      "889/889 - 2s - loss: 0.2129 - accuracy: 0.9035\n",
      "Epoch 75/150\n",
      "889/889 - 2s - loss: 0.2115 - accuracy: 0.9044\n",
      "Epoch 76/150\n",
      "889/889 - 2s - loss: 0.2113 - accuracy: 0.9037\n",
      "Epoch 77/150\n",
      "889/889 - 2s - loss: 0.2115 - accuracy: 0.9037\n",
      "Epoch 78/150\n",
      "889/889 - 2s - loss: 0.2115 - accuracy: 0.9053\n",
      "Epoch 79/150\n",
      "889/889 - 2s - loss: 0.2163 - accuracy: 0.9023\n",
      "Epoch 80/150\n",
      "889/889 - 2s - loss: 0.2112 - accuracy: 0.9039 - val_loss: 0.1908 - val_accuracy: 0.9154\n",
      "Epoch 81/150\n",
      "889/889 - 2s - loss: 0.2101 - accuracy: 0.9048\n",
      "Epoch 82/150\n",
      "889/889 - 2s - loss: 0.2108 - accuracy: 0.9044\n",
      "Epoch 83/150\n",
      "889/889 - 2s - loss: 0.2099 - accuracy: 0.9057\n",
      "Epoch 84/150\n",
      "889/889 - 2s - loss: 0.2086 - accuracy: 0.9047\n",
      "Epoch 85/150\n",
      "889/889 - 2s - loss: 0.2099 - accuracy: 0.9038\n",
      "Epoch 86/150\n",
      "889/889 - 2s - loss: 0.2092 - accuracy: 0.9053\n",
      "Epoch 87/150\n",
      "889/889 - 2s - loss: 0.2091 - accuracy: 0.9056\n",
      "Epoch 88/150\n",
      "889/889 - 2s - loss: 0.2084 - accuracy: 0.9042\n",
      "Epoch 89/150\n",
      "889/889 - 2s - loss: 0.2098 - accuracy: 0.9067\n",
      "Epoch 90/150\n",
      "889/889 - 2s - loss: 0.2078 - accuracy: 0.9058 - val_loss: 0.1917 - val_accuracy: 0.9125\n",
      "Epoch 91/150\n",
      "889/889 - 2s - loss: 0.2104 - accuracy: 0.9031\n",
      "Epoch 92/150\n",
      "889/889 - 2s - loss: 0.2081 - accuracy: 0.9061\n",
      "Epoch 93/150\n",
      "889/889 - 2s - loss: 0.2085 - accuracy: 0.9061\n",
      "Epoch 94/150\n",
      "889/889 - 2s - loss: 0.2092 - accuracy: 0.9064\n",
      "Epoch 95/150\n",
      "889/889 - 2s - loss: 0.2068 - accuracy: 0.9065\n",
      "Epoch 96/150\n",
      "889/889 - 2s - loss: 0.2080 - accuracy: 0.9060\n",
      "Epoch 97/150\n",
      "889/889 - 2s - loss: 0.2084 - accuracy: 0.9056\n",
      "Epoch 98/150\n",
      "889/889 - 2s - loss: 0.2066 - accuracy: 0.9069\n",
      "Epoch 99/150\n",
      "889/889 - 2s - loss: 0.2100 - accuracy: 0.9054\n",
      "Epoch 100/150\n",
      "889/889 - 2s - loss: 0.2081 - accuracy: 0.9052 - val_loss: 0.1852 - val_accuracy: 0.9156\n",
      "Epoch 101/150\n",
      "889/889 - 2s - loss: 0.2072 - accuracy: 0.9066\n",
      "Epoch 102/150\n",
      "889/889 - 2s - loss: 0.2074 - accuracy: 0.9075\n",
      "Epoch 103/150\n",
      "889/889 - 2s - loss: 0.2071 - accuracy: 0.9068\n",
      "Epoch 104/150\n",
      "889/889 - 2s - loss: 0.2071 - accuracy: 0.9054\n",
      "Epoch 105/150\n",
      "889/889 - 2s - loss: 0.2088 - accuracy: 0.9060\n",
      "Epoch 106/150\n",
      "889/889 - 2s - loss: 0.2047 - accuracy: 0.9071\n",
      "Epoch 107/150\n",
      "889/889 - 2s - loss: 0.2046 - accuracy: 0.9067\n",
      "Epoch 108/150\n",
      "889/889 - 2s - loss: 0.2044 - accuracy: 0.9075\n",
      "Epoch 109/150\n",
      "889/889 - 2s - loss: 0.2038 - accuracy: 0.9073\n",
      "Epoch 110/150\n",
      "889/889 - 2s - loss: 0.2026 - accuracy: 0.9087 - val_loss: 0.1908 - val_accuracy: 0.9123\n",
      "Epoch 111/150\n",
      "889/889 - 2s - loss: 0.2021 - accuracy: 0.9084\n",
      "Epoch 112/150\n",
      "889/889 - 2s - loss: 0.2038 - accuracy: 0.9080\n",
      "Epoch 113/150\n",
      "889/889 - 2s - loss: 0.2033 - accuracy: 0.9079\n",
      "Epoch 114/150\n",
      "889/889 - 2s - loss: 0.2019 - accuracy: 0.9084\n",
      "Epoch 115/150\n",
      "889/889 - 2s - loss: 0.2013 - accuracy: 0.9079\n",
      "Epoch 116/150\n",
      "889/889 - 2s - loss: 0.2024 - accuracy: 0.9078\n",
      "Epoch 117/150\n",
      "889/889 - 2s - loss: 0.2006 - accuracy: 0.9083\n",
      "Epoch 118/150\n",
      "889/889 - 2s - loss: 0.2043 - accuracy: 0.9082\n",
      "Epoch 119/150\n",
      "889/889 - 2s - loss: 0.2005 - accuracy: 0.9091\n",
      "Epoch 120/150\n",
      "889/889 - 2s - loss: 0.1993 - accuracy: 0.9093 - val_loss: 0.1947 - val_accuracy: 0.9103\n",
      "Epoch 121/150\n",
      "889/889 - 2s - loss: 0.2001 - accuracy: 0.9092\n",
      "Epoch 122/150\n",
      "889/889 - 2s - loss: 0.1996 - accuracy: 0.9090\n",
      "Epoch 123/150\n",
      "889/889 - 2s - loss: 0.1974 - accuracy: 0.9107\n",
      "Epoch 124/150\n",
      "889/889 - 2s - loss: 0.1971 - accuracy: 0.9107\n",
      "Epoch 125/150\n",
      "889/889 - 2s - loss: 0.1976 - accuracy: 0.9107\n",
      "Epoch 126/150\n",
      "889/889 - 2s - loss: 0.1981 - accuracy: 0.9098\n",
      "Epoch 127/150\n",
      "889/889 - 2s - loss: 0.1958 - accuracy: 0.9105\n",
      "Epoch 128/150\n",
      "889/889 - 2s - loss: 0.1964 - accuracy: 0.9110\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/889 - 2s - loss: 0.1953 - accuracy: 0.9107\n",
      "Epoch 130/150\n",
      "889/889 - 2s - loss: 0.1951 - accuracy: 0.9113 - val_loss: 0.1932 - val_accuracy: 0.9136\n",
      "Epoch 131/150\n",
      "889/889 - 2s - loss: 0.1946 - accuracy: 0.9127\n",
      "Epoch 132/150\n",
      "889/889 - 2s - loss: 0.1948 - accuracy: 0.9124\n",
      "Epoch 133/150\n",
      "889/889 - 2s - loss: 0.1924 - accuracy: 0.9129\n",
      "Epoch 134/150\n",
      "889/889 - 2s - loss: 0.1922 - accuracy: 0.9120\n",
      "Epoch 135/150\n",
      "889/889 - 2s - loss: 0.1924 - accuracy: 0.9113\n",
      "Epoch 136/150\n",
      "889/889 - 2s - loss: 0.1917 - accuracy: 0.9125\n",
      "Epoch 137/150\n",
      "889/889 - 2s - loss: 0.1914 - accuracy: 0.9121\n",
      "Epoch 138/150\n",
      "889/889 - 2s - loss: 0.1912 - accuracy: 0.9126\n",
      "Epoch 139/150\n",
      "889/889 - 2s - loss: 0.1907 - accuracy: 0.9135\n",
      "Epoch 140/150\n",
      "889/889 - 2s - loss: 0.1900 - accuracy: 0.9132 - val_loss: 0.1987 - val_accuracy: 0.9139\n",
      "Epoch 141/150\n",
      "889/889 - 2s - loss: 0.1888 - accuracy: 0.9133\n",
      "Epoch 142/150\n",
      "889/889 - 2s - loss: 0.1887 - accuracy: 0.9128\n",
      "Epoch 143/150\n",
      "889/889 - 2s - loss: 0.1882 - accuracy: 0.9137\n",
      "Epoch 144/150\n",
      "889/889 - 2s - loss: 0.1872 - accuracy: 0.9143\n",
      "Epoch 145/150\n",
      "889/889 - 2s - loss: 0.1865 - accuracy: 0.9140\n",
      "Epoch 146/150\n",
      "889/889 - 2s - loss: 0.1859 - accuracy: 0.9141\n",
      "Epoch 147/150\n",
      "889/889 - 2s - loss: 0.1860 - accuracy: 0.9143\n",
      "Epoch 148/150\n",
      "889/889 - 2s - loss: 0.1848 - accuracy: 0.9151\n",
      "Epoch 149/150\n",
      "889/889 - 2s - loss: 0.1848 - accuracy: 0.9146\n",
      "Epoch 150/150\n",
      "889/889 - 2s - loss: 0.1842 - accuracy: 0.9152 - val_loss: 0.2075 - val_accuracy: 0.9140\n",
      "Print Time for taining:  626.9406887069999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_28_layer_call_fn, dense_28_layer_call_and_return_conditional_losses, gather_nodes_outgoing_4_layer_call_fn, gather_nodes_outgoing_4_layer_call_and_return_conditional_losses, dense_29_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_25_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_25_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5594  376]\n",
      " [ 287 1454]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n",
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:654: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MCC = numpy.sqrt(Q_eigenValue[:, :, -2])  # 2nd highest eigenvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 128, 128, 64) 640         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 512)  1180160     max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 196)    903364      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 196)    345940      conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 16, 16, 512)  401920      conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_transpose_20[0][0]        \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 512)  4719104     concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 32, 32, 256)  524544      conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 32, 32, 512)  0           conv2d_transpose_21[0][0]        \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 32, 32, 256)  1179904     concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_22[0][0]        \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 128)  295040      concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_23[0][0]        \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 128, 128, 64) 73792       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 128, 128, 2)  130         conv2d_112[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 30s 967ms/step - loss: 0.2372 - iou: 0.3493 - val_loss: 0.1971 - val_iou: 0.3826\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19709, saving model to segm_ALL_.h5\n",
      "[TensorShape([28560, None, 12]), TensorShape([28560, None, 1]), TensorShape([28560, None, 2])]\n",
      "[TensorShape([7773, None, 12]), TensorShape([7773, None, 1]), TensorShape([7773, None, 2])]\n",
      "(28560,) (7773,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_4 (GCN)                     (None, None, 64)     4160        dense_34[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_4 (PoolingNodes)  (None, 64)           0           gcn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_4 (MLP)                     (None, 1)            19040       pooling_nodes_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_10/gcn_4/pooling_weighted_local_edges_5/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_10/gcn_4/pooling_weighted_local_edges_5/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_10/gcn_4/pooling_weighted_local_edges_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_10/gcn_4/gather_nodes_outgoing_5/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_10/gcn_4/gather_nodes_outgoing_5/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_10/gcn_4/gather_nodes_outgoing_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 - 2s - loss: 0.4233 - accuracy: 0.8315\n",
      "Epoch 2/150\n",
      "893/893 - 2s - loss: 0.2949 - accuracy: 0.8664\n",
      "Epoch 3/150\n",
      "893/893 - 2s - loss: 0.2646 - accuracy: 0.8793\n",
      "Epoch 4/150\n",
      "893/893 - 2s - loss: 0.2570 - accuracy: 0.8831\n",
      "Epoch 5/150\n",
      "893/893 - 2s - loss: 0.2540 - accuracy: 0.8853\n",
      "Epoch 6/150\n",
      "893/893 - 2s - loss: 0.2484 - accuracy: 0.8879\n",
      "Epoch 7/150\n",
      "893/893 - 2s - loss: 0.2483 - accuracy: 0.8884\n",
      "Epoch 8/150\n",
      "893/893 - 2s - loss: 0.2433 - accuracy: 0.8904\n",
      "Epoch 9/150\n",
      "893/893 - 2s - loss: 0.2416 - accuracy: 0.8918\n",
      "Epoch 10/150\n",
      "893/893 - 2s - loss: 0.2407 - accuracy: 0.8904 - val_loss: 0.2225 - val_accuracy: 0.9039\n",
      "Epoch 11/150\n",
      "893/893 - 2s - loss: 0.2383 - accuracy: 0.8936\n",
      "Epoch 12/150\n",
      "893/893 - 2s - loss: 0.2372 - accuracy: 0.8940\n",
      "Epoch 13/150\n",
      "893/893 - 2s - loss: 0.2356 - accuracy: 0.8925\n",
      "Epoch 14/150\n",
      "893/893 - 2s - loss: 0.2339 - accuracy: 0.8937\n",
      "Epoch 15/150\n",
      "893/893 - 2s - loss: 0.2344 - accuracy: 0.8952\n",
      "Epoch 16/150\n",
      "893/893 - 2s - loss: 0.2320 - accuracy: 0.8967\n",
      "Epoch 17/150\n",
      "893/893 - 2s - loss: 0.2325 - accuracy: 0.8940\n",
      "Epoch 18/150\n",
      "893/893 - 2s - loss: 0.2310 - accuracy: 0.8954\n",
      "Epoch 19/150\n",
      "893/893 - 2s - loss: 0.2295 - accuracy: 0.8943\n",
      "Epoch 20/150\n",
      "893/893 - 2s - loss: 0.2272 - accuracy: 0.8974 - val_loss: 0.2073 - val_accuracy: 0.9072\n",
      "Epoch 21/150\n",
      "893/893 - 2s - loss: 0.2286 - accuracy: 0.8972\n",
      "Epoch 22/150\n",
      "893/893 - 2s - loss: 0.2259 - accuracy: 0.8983\n",
      "Epoch 23/150\n",
      "893/893 - 2s - loss: 0.2270 - accuracy: 0.8986\n",
      "Epoch 24/150\n",
      "893/893 - 2s - loss: 0.2246 - accuracy: 0.8981\n",
      "Epoch 25/150\n",
      "893/893 - 2s - loss: 0.2236 - accuracy: 0.8999\n",
      "Epoch 26/150\n",
      "893/893 - 2s - loss: 0.2239 - accuracy: 0.8974\n",
      "Epoch 27/150\n",
      "893/893 - 2s - loss: 0.2257 - accuracy: 0.8978\n",
      "Epoch 28/150\n",
      "893/893 - 2s - loss: 0.2242 - accuracy: 0.8979\n",
      "Epoch 29/150\n",
      "893/893 - 2s - loss: 0.2214 - accuracy: 0.8992\n",
      "Epoch 30/150\n",
      "893/893 - 2s - loss: 0.2227 - accuracy: 0.8989 - val_loss: 0.2017 - val_accuracy: 0.9034\n",
      "Epoch 31/150\n",
      "893/893 - 2s - loss: 0.2238 - accuracy: 0.8974\n",
      "Epoch 32/150\n",
      "893/893 - 2s - loss: 0.2225 - accuracy: 0.8999\n",
      "Epoch 33/150\n",
      "893/893 - 2s - loss: 0.2198 - accuracy: 0.9007\n",
      "Epoch 34/150\n",
      "893/893 - 2s - loss: 0.2205 - accuracy: 0.8997\n",
      "Epoch 35/150\n",
      "893/893 - 2s - loss: 0.2213 - accuracy: 0.8997\n",
      "Epoch 36/150\n",
      "893/893 - 2s - loss: 0.2203 - accuracy: 0.9014\n",
      "Epoch 37/150\n",
      "893/893 - 2s - loss: 0.2192 - accuracy: 0.9000\n",
      "Epoch 38/150\n",
      "893/893 - 2s - loss: 0.2211 - accuracy: 0.8992\n",
      "Epoch 39/150\n",
      "893/893 - 2s - loss: 0.2207 - accuracy: 0.9012\n",
      "Epoch 40/150\n",
      "893/893 - 2s - loss: 0.2163 - accuracy: 0.9026 - val_loss: 0.2186 - val_accuracy: 0.8963\n",
      "Epoch 41/150\n",
      "893/893 - 2s - loss: 0.2186 - accuracy: 0.9006\n",
      "Epoch 42/150\n",
      "893/893 - 2s - loss: 0.2183 - accuracy: 0.9016\n",
      "Epoch 43/150\n",
      "893/893 - 2s - loss: 0.2186 - accuracy: 0.9016\n",
      "Epoch 44/150\n",
      "893/893 - 2s - loss: 0.2176 - accuracy: 0.9011\n",
      "Epoch 45/150\n",
      "893/893 - 2s - loss: 0.2178 - accuracy: 0.9022\n",
      "Epoch 46/150\n",
      "893/893 - 2s - loss: 0.2164 - accuracy: 0.9015\n",
      "Epoch 47/150\n",
      "893/893 - 2s - loss: 0.2177 - accuracy: 0.9013\n",
      "Epoch 48/150\n",
      "893/893 - 2s - loss: 0.2162 - accuracy: 0.9021\n",
      "Epoch 49/150\n",
      "893/893 - 2s - loss: 0.2186 - accuracy: 0.9000\n",
      "Epoch 50/150\n",
      "893/893 - 2s - loss: 0.2171 - accuracy: 0.9020 - val_loss: 0.1942 - val_accuracy: 0.9121\n",
      "Epoch 51/150\n",
      "893/893 - 2s - loss: 0.2154 - accuracy: 0.9015\n",
      "Epoch 52/150\n",
      "893/893 - 2s - loss: 0.2187 - accuracy: 0.9014\n",
      "Epoch 53/150\n",
      "893/893 - 2s - loss: 0.2156 - accuracy: 0.9023\n",
      "Epoch 54/150\n",
      "893/893 - 2s - loss: 0.2127 - accuracy: 0.9033\n",
      "Epoch 55/150\n",
      "893/893 - 2s - loss: 0.2154 - accuracy: 0.9029\n",
      "Epoch 56/150\n",
      "893/893 - 2s - loss: 0.2134 - accuracy: 0.9031\n",
      "Epoch 57/150\n",
      "893/893 - 2s - loss: 0.2155 - accuracy: 0.9004\n",
      "Epoch 58/150\n",
      "893/893 - 2s - loss: 0.2138 - accuracy: 0.9022\n",
      "Epoch 59/150\n",
      "893/893 - 2s - loss: 0.2155 - accuracy: 0.9038\n",
      "Epoch 60/150\n",
      "893/893 - 2s - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.2104 - val_accuracy: 0.9026\n",
      "Epoch 61/150\n",
      "893/893 - 2s - loss: 0.2153 - accuracy: 0.9021\n",
      "Epoch 62/150\n",
      "893/893 - 2s - loss: 0.2127 - accuracy: 0.9041\n",
      "Epoch 63/150\n",
      "893/893 - 2s - loss: 0.2119 - accuracy: 0.9032\n",
      "Epoch 64/150\n",
      "893/893 - 2s - loss: 0.2147 - accuracy: 0.9028\n",
      "Epoch 65/150\n",
      "893/893 - 2s - loss: 0.2123 - accuracy: 0.9020\n",
      "Epoch 66/150\n",
      "893/893 - 2s - loss: 0.2144 - accuracy: 0.9016\n",
      "Epoch 67/150\n",
      "893/893 - 2s - loss: 0.2137 - accuracy: 0.9031\n",
      "Epoch 68/150\n",
      "893/893 - 2s - loss: 0.2124 - accuracy: 0.9017\n",
      "Epoch 69/150\n",
      "893/893 - 2s - loss: 0.2105 - accuracy: 0.9041\n",
      "Epoch 70/150\n",
      "893/893 - 2s - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.1915 - val_accuracy: 0.9134\n",
      "Epoch 71/150\n",
      "893/893 - 2s - loss: 0.2140 - accuracy: 0.9025\n",
      "Epoch 72/150\n",
      "893/893 - 2s - loss: 0.2113 - accuracy: 0.9033\n",
      "Epoch 73/150\n",
      "893/893 - 2s - loss: 0.2127 - accuracy: 0.9035\n",
      "Epoch 74/150\n",
      "893/893 - 2s - loss: 0.2119 - accuracy: 0.9032\n",
      "Epoch 75/150\n",
      "893/893 - 2s - loss: 0.2118 - accuracy: 0.9025\n",
      "Epoch 76/150\n",
      "893/893 - 2s - loss: 0.2113 - accuracy: 0.9038\n",
      "Epoch 77/150\n",
      "893/893 - 2s - loss: 0.2115 - accuracy: 0.9026\n",
      "Epoch 78/150\n",
      "893/893 - 2s - loss: 0.2128 - accuracy: 0.9038\n",
      "Epoch 79/150\n",
      "893/893 - 2s - loss: 0.2078 - accuracy: 0.9050\n",
      "Epoch 80/150\n",
      "893/893 - 2s - loss: 0.2102 - accuracy: 0.9035 - val_loss: 0.1946 - val_accuracy: 0.9083\n",
      "Epoch 81/150\n",
      "893/893 - 2s - loss: 0.2113 - accuracy: 0.9024\n",
      "Epoch 82/150\n",
      "893/893 - 2s - loss: 0.2103 - accuracy: 0.9049\n",
      "Epoch 83/150\n",
      "893/893 - 2s - loss: 0.2095 - accuracy: 0.9046\n",
      "Epoch 84/150\n",
      "893/893 - 2s - loss: 0.2094 - accuracy: 0.9058\n",
      "Epoch 85/150\n",
      "893/893 - 2s - loss: 0.2094 - accuracy: 0.9056\n",
      "Epoch 86/150\n",
      "893/893 - 2s - loss: 0.2116 - accuracy: 0.9047\n",
      "Epoch 87/150\n",
      "893/893 - 2s - loss: 0.2101 - accuracy: 0.9040\n",
      "Epoch 88/150\n",
      "893/893 - 2s - loss: 0.2099 - accuracy: 0.9040\n",
      "Epoch 89/150\n",
      "893/893 - 2s - loss: 0.2084 - accuracy: 0.9053\n",
      "Epoch 90/150\n",
      "893/893 - 2s - loss: 0.2101 - accuracy: 0.9047 - val_loss: 0.1907 - val_accuracy: 0.9161\n",
      "Epoch 91/150\n",
      "893/893 - 2s - loss: 0.2062 - accuracy: 0.9060\n",
      "Epoch 92/150\n",
      "893/893 - 2s - loss: 0.2094 - accuracy: 0.9042\n",
      "Epoch 93/150\n",
      "893/893 - 2s - loss: 0.2090 - accuracy: 0.9057\n",
      "Epoch 94/150\n",
      "893/893 - 2s - loss: 0.2101 - accuracy: 0.9049\n",
      "Epoch 95/150\n",
      "893/893 - 2s - loss: 0.2092 - accuracy: 0.9035\n",
      "Epoch 96/150\n",
      "893/893 - 2s - loss: 0.2094 - accuracy: 0.9056\n",
      "Epoch 97/150\n",
      "893/893 - 2s - loss: 0.2082 - accuracy: 0.9053\n",
      "Epoch 98/150\n",
      "893/893 - 2s - loss: 0.2076 - accuracy: 0.9054\n",
      "Epoch 99/150\n",
      "893/893 - 2s - loss: 0.2085 - accuracy: 0.9043\n",
      "Epoch 100/150\n",
      "893/893 - 2s - loss: 0.2095 - accuracy: 0.9041 - val_loss: 0.1922 - val_accuracy: 0.9146\n",
      "Epoch 101/150\n",
      "893/893 - 2s - loss: 0.2067 - accuracy: 0.9061\n",
      "Epoch 102/150\n",
      "893/893 - 2s - loss: 0.2099 - accuracy: 0.9059\n",
      "Epoch 103/150\n",
      "893/893 - 2s - loss: 0.2079 - accuracy: 0.9061\n",
      "Epoch 104/150\n",
      "893/893 - 2s - loss: 0.2062 - accuracy: 0.9071\n",
      "Epoch 105/150\n",
      "893/893 - 2s - loss: 0.2056 - accuracy: 0.9058\n",
      "Epoch 106/150\n",
      "893/893 - 2s - loss: 0.2052 - accuracy: 0.9058\n",
      "Epoch 107/150\n",
      "893/893 - 2s - loss: 0.2047 - accuracy: 0.9062\n",
      "Epoch 108/150\n",
      "893/893 - 2s - loss: 0.2059 - accuracy: 0.9069\n",
      "Epoch 109/150\n",
      "893/893 - 2s - loss: 0.2048 - accuracy: 0.9060\n",
      "Epoch 110/150\n",
      "893/893 - 2s - loss: 0.2042 - accuracy: 0.9064 - val_loss: 0.2017 - val_accuracy: 0.9142\n",
      "Epoch 111/150\n",
      "893/893 - 2s - loss: 0.2036 - accuracy: 0.9065\n",
      "Epoch 112/150\n",
      "893/893 - 2s - loss: 0.2033 - accuracy: 0.9075\n",
      "Epoch 113/150\n",
      "893/893 - 2s - loss: 0.2019 - accuracy: 0.9081\n",
      "Epoch 114/150\n",
      "893/893 - 2s - loss: 0.2023 - accuracy: 0.9067\n",
      "Epoch 115/150\n",
      "893/893 - 2s - loss: 0.2015 - accuracy: 0.9071\n",
      "Epoch 116/150\n",
      "893/893 - 2s - loss: 0.2021 - accuracy: 0.9063\n",
      "Epoch 117/150\n",
      "893/893 - 2s - loss: 0.2031 - accuracy: 0.9062\n",
      "Epoch 118/150\n",
      "893/893 - 2s - loss: 0.2013 - accuracy: 0.9078\n",
      "Epoch 119/150\n",
      "893/893 - 2s - loss: 0.2001 - accuracy: 0.9081\n",
      "Epoch 120/150\n",
      "893/893 - 2s - loss: 0.2007 - accuracy: 0.9075 - val_loss: 0.1923 - val_accuracy: 0.9146\n",
      "Epoch 121/150\n",
      "893/893 - 2s - loss: 0.1997 - accuracy: 0.9085\n",
      "Epoch 122/150\n",
      "893/893 - 2s - loss: 0.1993 - accuracy: 0.9084\n",
      "Epoch 123/150\n",
      "893/893 - 2s - loss: 0.1979 - accuracy: 0.9093\n",
      "Epoch 124/150\n",
      "893/893 - 2s - loss: 0.1982 - accuracy: 0.9097\n",
      "Epoch 125/150\n",
      "893/893 - 2s - loss: 0.1987 - accuracy: 0.9084\n",
      "Epoch 126/150\n",
      "893/893 - 2s - loss: 0.1963 - accuracy: 0.9096\n",
      "Epoch 127/150\n",
      "893/893 - 2s - loss: 0.1954 - accuracy: 0.9114\n",
      "Epoch 128/150\n",
      "893/893 - 2s - loss: 0.1963 - accuracy: 0.9100\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 - 2s - loss: 0.1956 - accuracy: 0.9109\n",
      "Epoch 130/150\n",
      "893/893 - 2s - loss: 0.1948 - accuracy: 0.9114 - val_loss: 0.1932 - val_accuracy: 0.9125\n",
      "Epoch 131/150\n",
      "893/893 - 2s - loss: 0.1940 - accuracy: 0.9100\n",
      "Epoch 132/150\n",
      "893/893 - 2s - loss: 0.1938 - accuracy: 0.9101\n",
      "Epoch 133/150\n",
      "893/893 - 2s - loss: 0.1929 - accuracy: 0.9103\n",
      "Epoch 134/150\n",
      "893/893 - 2s - loss: 0.1926 - accuracy: 0.9115\n",
      "Epoch 135/150\n",
      "893/893 - 2s - loss: 0.1917 - accuracy: 0.9117\n",
      "Epoch 136/150\n",
      "893/893 - 2s - loss: 0.1918 - accuracy: 0.9112\n",
      "Epoch 137/150\n",
      "893/893 - 2s - loss: 0.1925 - accuracy: 0.9114\n",
      "Epoch 138/150\n",
      "893/893 - 2s - loss: 0.1904 - accuracy: 0.9119\n",
      "Epoch 139/150\n",
      "893/893 - 2s - loss: 0.1899 - accuracy: 0.9123\n",
      "Epoch 140/150\n",
      "893/893 - 2s - loss: 0.1930 - accuracy: 0.9128 - val_loss: 0.2076 - val_accuracy: 0.9090\n",
      "Epoch 141/150\n",
      "893/893 - 2s - loss: 0.1889 - accuracy: 0.9126\n",
      "Epoch 142/150\n",
      "893/893 - 2s - loss: 0.1887 - accuracy: 0.9133\n",
      "Epoch 143/150\n",
      "893/893 - 2s - loss: 0.1874 - accuracy: 0.9133\n",
      "Epoch 144/150\n",
      "893/893 - 2s - loss: 0.1871 - accuracy: 0.9136\n",
      "Epoch 145/150\n",
      "893/893 - 2s - loss: 0.1867 - accuracy: 0.9135\n",
      "Epoch 146/150\n",
      "893/893 - 2s - loss: 0.1864 - accuracy: 0.9136\n",
      "Epoch 147/150\n",
      "893/893 - 2s - loss: 0.1857 - accuracy: 0.9143\n",
      "Epoch 148/150\n",
      "893/893 - 2s - loss: 0.1852 - accuracy: 0.9146\n",
      "Epoch 149/150\n",
      "893/893 - 2s - loss: 0.1847 - accuracy: 0.9152\n",
      "Epoch 150/150\n",
      "893/893 - 2s - loss: 0.1840 - accuracy: 0.9156 - val_loss: 0.2433 - val_accuracy: 0.9121\n",
      "Print Time for taining:  614.8764774359997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_35_layer_call_fn, dense_35_layer_call_and_return_conditional_losses, gather_nodes_outgoing_5_layer_call_fn, gather_nodes_outgoing_5_layer_call_and_return_conditional_losses, dense_36_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_30_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_30_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601  420]\n",
      " [ 263 1489]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:654: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MCC = numpy.sqrt(Q_eigenValue[:, :, -2])  # 2nd highest eigenvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n",
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 128, 128, 64) 640         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 64, 64, 128)  73856       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 32, 32, 256)  295168      max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 512)  1180160     max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 196)    903364      max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 196)    345940      conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 16, 16, 512)  401920      conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_transpose_24[0][0]        \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 16, 16, 512)  4719104     concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DTran (None, 32, 32, 256)  524544      conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 32, 32, 512)  0           conv2d_transpose_25[0][0]        \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 32, 32, 256)  1179904     concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_26 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_26[0][0]        \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 128)  295040      concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_27[0][0]        \n",
      "                                                                 conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 128, 128, 64) 73792       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 128, 128, 2)  130         conv2d_131[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 30s 960ms/step - loss: 0.2358 - iou: 0.3531 - val_loss: 0.1915 - val_iou: 0.4023\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19151, saving model to segm_ALL_.h5\n",
      "[TensorShape([28626, None, 12]), TensorShape([28626, None, 1]), TensorShape([28626, None, 2])]\n",
      "[TensorShape([7798, None, 12]), TensorShape([7798, None, 1]), TensorShape([7798, None, 2])]\n",
      "(28626,) (7798,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_5 (GCN)                     (None, None, 64)     4160        dense_41[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_5 (PoolingNodes)  (None, 64)           0           gcn_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_5 (MLP)                     (None, 1)            19040       pooling_nodes_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_12/gcn_5/pooling_weighted_local_edges_6/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_12/gcn_5/pooling_weighted_local_edges_6/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_12/gcn_5/pooling_weighted_local_edges_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_12/gcn_5/gather_nodes_outgoing_6/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_12/gcn_5/gather_nodes_outgoing_6/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_12/gcn_5/gather_nodes_outgoing_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895/895 - 3s - loss: 0.4615 - accuracy: 0.8218\n",
      "Epoch 2/150\n",
      "895/895 - 2s - loss: 0.3054 - accuracy: 0.8667\n",
      "Epoch 3/150\n",
      "895/895 - 2s - loss: 0.2695 - accuracy: 0.8788\n",
      "Epoch 4/150\n",
      "895/895 - 2s - loss: 0.2555 - accuracy: 0.8862\n",
      "Epoch 5/150\n",
      "895/895 - 2s - loss: 0.2492 - accuracy: 0.8876\n",
      "Epoch 6/150\n",
      "895/895 - 2s - loss: 0.2484 - accuracy: 0.8885\n",
      "Epoch 7/150\n",
      "895/895 - 2s - loss: 0.2419 - accuracy: 0.8907\n",
      "Epoch 8/150\n",
      "895/895 - 2s - loss: 0.2415 - accuracy: 0.8915\n",
      "Epoch 9/150\n",
      "895/895 - 2s - loss: 0.2409 - accuracy: 0.8906\n",
      "Epoch 10/150\n",
      "895/895 - 2s - loss: 0.2398 - accuracy: 0.8929 - val_loss: 0.2057 - val_accuracy: 0.9115\n",
      "Epoch 11/150\n",
      "895/895 - 2s - loss: 0.2380 - accuracy: 0.8927\n",
      "Epoch 12/150\n",
      "895/895 - 2s - loss: 0.2348 - accuracy: 0.8932\n",
      "Epoch 13/150\n",
      "895/895 - 2s - loss: 0.2336 - accuracy: 0.8939\n",
      "Epoch 14/150\n",
      "895/895 - 2s - loss: 0.2317 - accuracy: 0.8944\n",
      "Epoch 15/150\n",
      "895/895 - 2s - loss: 0.2319 - accuracy: 0.8946\n",
      "Epoch 16/150\n",
      "895/895 - 2s - loss: 0.2308 - accuracy: 0.8956\n",
      "Epoch 17/150\n",
      "895/895 - 2s - loss: 0.2298 - accuracy: 0.8948\n",
      "Epoch 18/150\n",
      "895/895 - 2s - loss: 0.2286 - accuracy: 0.8967\n",
      "Epoch 19/150\n",
      "895/895 - 2s - loss: 0.2281 - accuracy: 0.8955\n",
      "Epoch 20/150\n",
      "895/895 - 2s - loss: 0.2271 - accuracy: 0.8961 - val_loss: 0.2006 - val_accuracy: 0.9055\n",
      "Epoch 21/150\n",
      "895/895 - 2s - loss: 0.2274 - accuracy: 0.8976\n",
      "Epoch 22/150\n",
      "895/895 - 2s - loss: 0.2245 - accuracy: 0.8980\n",
      "Epoch 23/150\n",
      "895/895 - 2s - loss: 0.2241 - accuracy: 0.8987\n",
      "Epoch 24/150\n",
      "895/895 - 2s - loss: 0.2222 - accuracy: 0.8982\n",
      "Epoch 25/150\n",
      "895/895 - 2s - loss: 0.2256 - accuracy: 0.8976\n",
      "Epoch 26/150\n",
      "895/895 - 2s - loss: 0.2241 - accuracy: 0.8974\n",
      "Epoch 27/150\n",
      "895/895 - 2s - loss: 0.2211 - accuracy: 0.9004\n",
      "Epoch 28/150\n",
      "895/895 - 2s - loss: 0.2202 - accuracy: 0.8995\n",
      "Epoch 29/150\n",
      "895/895 - 2s - loss: 0.2193 - accuracy: 0.9009\n",
      "Epoch 30/150\n",
      "895/895 - 2s - loss: 0.2203 - accuracy: 0.9005 - val_loss: 0.1957 - val_accuracy: 0.9129\n",
      "Epoch 31/150\n",
      "895/895 - 2s - loss: 0.2183 - accuracy: 0.9012\n",
      "Epoch 32/150\n",
      "895/895 - 2s - loss: 0.2190 - accuracy: 0.9004\n",
      "Epoch 33/150\n",
      "895/895 - 2s - loss: 0.2209 - accuracy: 0.8986\n",
      "Epoch 34/150\n",
      "895/895 - 2s - loss: 0.2181 - accuracy: 0.9012\n",
      "Epoch 35/150\n",
      "895/895 - 2s - loss: 0.2167 - accuracy: 0.9012\n",
      "Epoch 36/150\n",
      "895/895 - 2s - loss: 0.2158 - accuracy: 0.9017\n",
      "Epoch 37/150\n",
      "895/895 - 2s - loss: 0.2163 - accuracy: 0.9028\n",
      "Epoch 38/150\n",
      "895/895 - 2s - loss: 0.2148 - accuracy: 0.9008\n",
      "Epoch 39/150\n",
      "895/895 - 2s - loss: 0.2135 - accuracy: 0.9023\n",
      "Epoch 40/150\n",
      "895/895 - 2s - loss: 0.2147 - accuracy: 0.9031 - val_loss: 0.1876 - val_accuracy: 0.9145\n",
      "Epoch 41/150\n",
      "895/895 - 2s - loss: 0.2143 - accuracy: 0.9033\n",
      "Epoch 42/150\n",
      "895/895 - 2s - loss: 0.2148 - accuracy: 0.9008\n",
      "Epoch 43/150\n",
      "895/895 - 2s - loss: 0.2134 - accuracy: 0.9022\n",
      "Epoch 44/150\n",
      "895/895 - 2s - loss: 0.2149 - accuracy: 0.9026\n",
      "Epoch 45/150\n",
      "895/895 - 2s - loss: 0.2111 - accuracy: 0.9048\n",
      "Epoch 46/150\n",
      "895/895 - 2s - loss: 0.2129 - accuracy: 0.9017\n",
      "Epoch 47/150\n",
      "895/895 - 2s - loss: 0.2134 - accuracy: 0.9014\n",
      "Epoch 48/150\n",
      "895/895 - 2s - loss: 0.2108 - accuracy: 0.9067\n",
      "Epoch 49/150\n",
      "895/895 - 2s - loss: 0.2111 - accuracy: 0.9031\n",
      "Epoch 50/150\n",
      "895/895 - 2s - loss: 0.2132 - accuracy: 0.9037 - val_loss: 0.2042 - val_accuracy: 0.9113\n",
      "Epoch 51/150\n",
      "895/895 - 2s - loss: 0.2126 - accuracy: 0.9027\n",
      "Epoch 52/150\n",
      "895/895 - 2s - loss: 0.2085 - accuracy: 0.9038\n",
      "Epoch 53/150\n",
      "895/895 - 2s - loss: 0.2102 - accuracy: 0.9038\n",
      "Epoch 54/150\n",
      "895/895 - 2s - loss: 0.2141 - accuracy: 0.9036\n",
      "Epoch 55/150\n",
      "895/895 - 2s - loss: 0.2116 - accuracy: 0.9036\n",
      "Epoch 56/150\n",
      "895/895 - 2s - loss: 0.2109 - accuracy: 0.9033\n",
      "Epoch 57/150\n",
      "895/895 - 2s - loss: 0.2085 - accuracy: 0.9046\n",
      "Epoch 58/150\n",
      "895/895 - 2s - loss: 0.2106 - accuracy: 0.9032\n",
      "Epoch 59/150\n",
      "895/895 - 2s - loss: 0.2093 - accuracy: 0.9033\n",
      "Epoch 60/150\n",
      "895/895 - 2s - loss: 0.2081 - accuracy: 0.9058 - val_loss: 0.1841 - val_accuracy: 0.9183\n",
      "Epoch 61/150\n",
      "895/895 - 2s - loss: 0.2094 - accuracy: 0.9047\n",
      "Epoch 62/150\n",
      "895/895 - 2s - loss: 0.2107 - accuracy: 0.9049\n",
      "Epoch 63/150\n",
      "895/895 - 2s - loss: 0.2083 - accuracy: 0.9035\n",
      "Epoch 64/150\n",
      "895/895 - 2s - loss: 0.2114 - accuracy: 0.9034\n",
      "Epoch 65/150\n",
      "895/895 - 2s - loss: 0.2170 - accuracy: 0.9044\n",
      "Epoch 66/150\n",
      "895/895 - 2s - loss: 0.2083 - accuracy: 0.9040\n",
      "Epoch 67/150\n",
      "895/895 - 2s - loss: 0.2063 - accuracy: 0.9053\n",
      "Epoch 68/150\n",
      "895/895 - 2s - loss: 0.2099 - accuracy: 0.9040\n",
      "Epoch 69/150\n",
      "895/895 - 2s - loss: 0.2075 - accuracy: 0.9062\n",
      "Epoch 70/150\n",
      "895/895 - 2s - loss: 0.2062 - accuracy: 0.9053 - val_loss: 0.2096 - val_accuracy: 0.9036\n",
      "Epoch 71/150\n",
      "895/895 - 2s - loss: 0.2078 - accuracy: 0.9050\n",
      "Epoch 72/150\n",
      "895/895 - 2s - loss: 0.2070 - accuracy: 0.9033\n",
      "Epoch 73/150\n",
      "895/895 - 2s - loss: 0.2072 - accuracy: 0.9057\n",
      "Epoch 74/150\n",
      "895/895 - 2s - loss: 0.2078 - accuracy: 0.9053\n",
      "Epoch 75/150\n",
      "895/895 - 2s - loss: 0.2056 - accuracy: 0.9066\n",
      "Epoch 76/150\n",
      "895/895 - 2s - loss: 0.2095 - accuracy: 0.9048\n",
      "Epoch 77/150\n",
      "895/895 - 2s - loss: 0.2061 - accuracy: 0.9054\n",
      "Epoch 78/150\n",
      "895/895 - 2s - loss: 0.2078 - accuracy: 0.9048\n",
      "Epoch 79/150\n",
      "895/895 - 2s - loss: 0.2054 - accuracy: 0.9058\n",
      "Epoch 80/150\n",
      "895/895 - 2s - loss: 0.2075 - accuracy: 0.9059 - val_loss: 0.1900 - val_accuracy: 0.9179\n",
      "Epoch 81/150\n",
      "895/895 - 2s - loss: 0.2054 - accuracy: 0.9067\n",
      "Epoch 82/150\n",
      "895/895 - 2s - loss: 0.2049 - accuracy: 0.9068\n",
      "Epoch 83/150\n",
      "895/895 - 2s - loss: 0.2054 - accuracy: 0.9069\n",
      "Epoch 84/150\n",
      "895/895 - 2s - loss: 0.2039 - accuracy: 0.9058\n",
      "Epoch 85/150\n",
      "895/895 - 2s - loss: 0.2041 - accuracy: 0.9051\n",
      "Epoch 86/150\n",
      "895/895 - 2s - loss: 0.2064 - accuracy: 0.9061\n",
      "Epoch 87/150\n",
      "895/895 - 2s - loss: 0.2033 - accuracy: 0.9060\n",
      "Epoch 88/150\n",
      "895/895 - 2s - loss: 0.2056 - accuracy: 0.9078\n",
      "Epoch 89/150\n",
      "895/895 - 2s - loss: 0.2024 - accuracy: 0.9065\n",
      "Epoch 90/150\n",
      "895/895 - 2s - loss: 0.2037 - accuracy: 0.9076 - val_loss: 0.1895 - val_accuracy: 0.9169\n",
      "Epoch 91/150\n",
      "895/895 - 2s - loss: 0.2047 - accuracy: 0.9062\n",
      "Epoch 92/150\n",
      "895/895 - 2s - loss: 0.2074 - accuracy: 0.9060\n",
      "Epoch 93/150\n",
      "895/895 - 2s - loss: 0.2039 - accuracy: 0.9051\n",
      "Epoch 94/150\n",
      "895/895 - 2s - loss: 0.2040 - accuracy: 0.9066\n",
      "Epoch 95/150\n",
      "895/895 - 2s - loss: 0.2030 - accuracy: 0.9071\n",
      "Epoch 96/150\n",
      "895/895 - 2s - loss: 0.2029 - accuracy: 0.9066\n",
      "Epoch 97/150\n",
      "895/895 - 2s - loss: 0.2060 - accuracy: 0.9063\n",
      "Epoch 98/150\n",
      "895/895 - 2s - loss: 0.2078 - accuracy: 0.9053\n",
      "Epoch 99/150\n",
      "895/895 - 2s - loss: 0.2011 - accuracy: 0.9061\n",
      "Epoch 100/150\n",
      "895/895 - 2s - loss: 0.2019 - accuracy: 0.9074 - val_loss: 0.1864 - val_accuracy: 0.9202\n",
      "Epoch 101/150\n",
      "895/895 - 2s - loss: 0.2051 - accuracy: 0.9059\n",
      "Epoch 102/150\n",
      "895/895 - 2s - loss: 0.2058 - accuracy: 0.9053\n",
      "Epoch 103/150\n",
      "895/895 - 2s - loss: 0.2013 - accuracy: 0.9063\n",
      "Epoch 104/150\n",
      "895/895 - 2s - loss: 0.2013 - accuracy: 0.9082\n",
      "Epoch 105/150\n",
      "895/895 - 2s - loss: 0.2050 - accuracy: 0.9066\n",
      "Epoch 106/150\n",
      "895/895 - 2s - loss: 0.1996 - accuracy: 0.9077\n",
      "Epoch 107/150\n",
      "895/895 - 2s - loss: 0.1988 - accuracy: 0.9085\n",
      "Epoch 108/150\n",
      "895/895 - 2s - loss: 0.2002 - accuracy: 0.9070\n",
      "Epoch 109/150\n",
      "895/895 - 2s - loss: 0.1972 - accuracy: 0.9095\n",
      "Epoch 110/150\n",
      "895/895 - 2s - loss: 0.1987 - accuracy: 0.9087 - val_loss: 0.1883 - val_accuracy: 0.9173\n",
      "Epoch 111/150\n",
      "895/895 - 2s - loss: 0.1982 - accuracy: 0.9098\n",
      "Epoch 112/150\n",
      "895/895 - 2s - loss: 0.1970 - accuracy: 0.9094\n",
      "Epoch 113/150\n",
      "895/895 - 2s - loss: 0.1964 - accuracy: 0.9095\n",
      "Epoch 114/150\n",
      "895/895 - 2s - loss: 0.1970 - accuracy: 0.9087\n",
      "Epoch 115/150\n",
      "895/895 - 2s - loss: 0.1988 - accuracy: 0.9100\n",
      "Epoch 116/150\n",
      "895/895 - 2s - loss: 0.1955 - accuracy: 0.9102\n",
      "Epoch 117/150\n",
      "895/895 - 2s - loss: 0.1945 - accuracy: 0.9098\n",
      "Epoch 118/150\n",
      "895/895 - 2s - loss: 0.1953 - accuracy: 0.9090\n",
      "Epoch 119/150\n",
      "895/895 - 2s - loss: 0.1930 - accuracy: 0.9102\n",
      "Epoch 120/150\n",
      "895/895 - 2s - loss: 0.1926 - accuracy: 0.9109 - val_loss: 0.1913 - val_accuracy: 0.9131\n",
      "Epoch 121/150\n",
      "895/895 - 2s - loss: 0.1930 - accuracy: 0.9105\n",
      "Epoch 122/150\n",
      "895/895 - 2s - loss: 0.1933 - accuracy: 0.9093\n",
      "Epoch 123/150\n",
      "895/895 - 2s - loss: 0.1925 - accuracy: 0.9118\n",
      "Epoch 124/150\n",
      "895/895 - 2s - loss: 0.1898 - accuracy: 0.9119\n",
      "Epoch 125/150\n",
      "895/895 - 2s - loss: 0.1896 - accuracy: 0.9134\n",
      "Epoch 126/150\n",
      "895/895 - 2s - loss: 0.1898 - accuracy: 0.9133\n",
      "Epoch 127/150\n",
      "895/895 - 2s - loss: 0.1885 - accuracy: 0.9133\n",
      "Epoch 128/150\n",
      "895/895 - 2s - loss: 0.1893 - accuracy: 0.9134\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895/895 - 2s - loss: 0.1894 - accuracy: 0.9115\n",
      "Epoch 130/150\n",
      "895/895 - 2s - loss: 0.1884 - accuracy: 0.9117 - val_loss: 0.1847 - val_accuracy: 0.9193\n",
      "Epoch 131/150\n",
      "895/895 - 2s - loss: 0.1863 - accuracy: 0.9129\n",
      "Epoch 132/150\n",
      "895/895 - 2s - loss: 0.1866 - accuracy: 0.9142\n",
      "Epoch 133/150\n",
      "895/895 - 2s - loss: 0.1857 - accuracy: 0.9144\n",
      "Epoch 134/150\n",
      "895/895 - 2s - loss: 0.1851 - accuracy: 0.9132\n",
      "Epoch 135/150\n",
      "895/895 - 2s - loss: 0.1845 - accuracy: 0.9150\n",
      "Epoch 136/150\n",
      "895/895 - 2s - loss: 0.1839 - accuracy: 0.9149\n",
      "Epoch 137/150\n",
      "895/895 - 2s - loss: 0.1835 - accuracy: 0.9153\n",
      "Epoch 138/150\n",
      "895/895 - 2s - loss: 0.1828 - accuracy: 0.9159\n",
      "Epoch 139/150\n",
      "895/895 - 2s - loss: 0.1810 - accuracy: 0.9151\n",
      "Epoch 140/150\n",
      "895/895 - 2s - loss: 0.1810 - accuracy: 0.9154 - val_loss: 0.1832 - val_accuracy: 0.9190\n",
      "Epoch 141/150\n",
      "895/895 - 2s - loss: 0.1812 - accuracy: 0.9164\n",
      "Epoch 142/150\n",
      "895/895 - 2s - loss: 0.1806 - accuracy: 0.9151\n",
      "Epoch 143/150\n",
      "895/895 - 2s - loss: 0.1791 - accuracy: 0.9163\n",
      "Epoch 144/150\n",
      "895/895 - 2s - loss: 0.1786 - accuracy: 0.9163\n",
      "Epoch 145/150\n",
      "895/895 - 2s - loss: 0.1777 - accuracy: 0.9168\n",
      "Epoch 146/150\n",
      "895/895 - 2s - loss: 0.1774 - accuracy: 0.9176\n",
      "Epoch 147/150\n",
      "895/895 - 2s - loss: 0.1767 - accuracy: 0.9187\n",
      "Epoch 148/150\n",
      "895/895 - 2s - loss: 0.1759 - accuracy: 0.9183\n",
      "Epoch 149/150\n",
      "895/895 - 2s - loss: 0.1751 - accuracy: 0.9183\n",
      "Epoch 150/150\n",
      "895/895 - 2s - loss: 0.1747 - accuracy: 0.9192 - val_loss: 0.1916 - val_accuracy: 0.9209\n",
      "Print Time for taining:  615.2675895240009\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_42_layer_call_fn, dense_42_layer_call_and_return_conditional_losses, gather_nodes_outgoing_6_layer_call_fn, gather_nodes_outgoing_6_layer_call_and_return_conditional_losses, dense_43_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_35_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_35_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5690  346]\n",
      " [ 271 1491]]\n",
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "Processing files: 3/140\n",
      "Processing files: 4/140\n",
      "Processing files: 5/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:654: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MCC = numpy.sqrt(Q_eigenValue[:, :, -2])  # 2nd highest eigenvalue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 6/140\n",
      "Processing files: 7/140\n",
      "Processing files: 8/140\n",
      "Processing files: 9/140\n",
      "Processing files: 10/140\n",
      "Processing files: 11/140\n",
      "Processing files: 12/140\n",
      "Processing files: 13/140\n",
      "Processing files: 14/140\n",
      "Processing files: 15/140\n",
      "Processing files: 16/140\n",
      "Processing files: 17/140\n",
      "Processing files: 18/140\n",
      "Processing files: 19/140\n",
      "Processing files: 20/140\n",
      "Processing files: 21/140\n",
      "Processing files: 22/140\n",
      "Processing files: 23/140\n",
      "Processing files: 24/140\n",
      "Processing files: 25/140\n",
      "Processing files: 26/140\n",
      "Processing files: 27/140\n",
      "Processing files: 28/140\n",
      "Processing files: 29/140\n",
      "Processing files: 30/140\n",
      "Processing files: 31/140\n",
      "Processing files: 32/140\n",
      "Processing files: 33/140\n",
      "Processing files: 34/140\n",
      "Processing files: 35/140\n",
      "Processing files: 36/140\n",
      "Processing files: 37/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/radiomics/glcm.py:599: RuntimeWarning: invalid value encountered in sqrt\n",
      "  imc2 = (1 - numpy.e ** (-2 * (HXY2 - HXY))) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 38/140\n",
      "Processing files: 39/140\n",
      "Processing files: 40/140\n",
      "Processing files: 41/140\n",
      "Processing files: 42/140\n",
      "Processing files: 43/140\n",
      "Processing files: 44/140\n",
      "Processing files: 45/140\n",
      "Processing files: 46/140\n",
      "Processing files: 47/140\n",
      "Processing files: 48/140\n",
      "Processing files: 49/140\n",
      "Processing files: 50/140\n",
      "Processing files: 51/140\n",
      "Processing files: 52/140\n",
      "Processing files: 53/140\n",
      "Processing files: 54/140\n",
      "Processing files: 55/140\n",
      "Processing files: 56/140\n",
      "Processing files: 57/140\n",
      "Processing files: 58/140\n",
      "Processing files: 59/140\n",
      "Processing files: 60/140\n",
      "Processing files: 61/140\n",
      "Processing files: 62/140\n",
      "Processing files: 63/140\n",
      "Processing files: 64/140\n",
      "Processing files: 65/140\n",
      "Processing files: 66/140\n",
      "Processing files: 67/140\n",
      "Processing files: 68/140\n",
      "Processing files: 69/140\n",
      "Processing files: 70/140\n",
      "Processing files: 71/140\n",
      "Processing files: 72/140\n",
      "Processing files: 73/140\n",
      "Processing files: 74/140\n",
      "Processing files: 75/140\n",
      "Processing files: 76/140\n",
      "Processing files: 77/140\n",
      "Processing files: 78/140\n",
      "Processing files: 79/140\n",
      "Processing files: 80/140\n",
      "Processing files: 81/140\n",
      "Processing files: 82/140\n",
      "Processing files: 83/140\n",
      "Processing files: 84/140\n",
      "Processing files: 85/140\n",
      "Processing files: 86/140\n",
      "Processing files: 87/140\n",
      "Processing files: 88/140\n",
      "Processing files: 89/140\n",
      "Processing files: 90/140\n",
      "Processing files: 91/140\n",
      "Processing files: 92/140\n",
      "Processing files: 93/140\n",
      "Processing files: 94/140\n",
      "Processing files: 95/140\n",
      "Processing files: 96/140\n",
      "Processing files: 97/140\n",
      "Processing files: 98/140\n",
      "Processing files: 99/140\n",
      "Processing files: 100/140\n",
      "Processing files: 101/140\n",
      "Processing files: 102/140\n",
      "Processing files: 103/140\n",
      "Processing files: 104/140\n",
      "Processing files: 105/140\n",
      "Processing files: 106/140\n",
      "Processing files: 107/140\n",
      "Processing files: 108/140\n",
      "Processing files: 109/140\n",
      "Processing files: 110/140\n",
      "Processing files: 111/140\n",
      "Processing files: 112/140\n",
      "Processing files: 113/140\n",
      "Processing files: 114/140\n",
      "Processing files: 115/140\n",
      "Processing files: 116/140\n",
      "Processing files: 117/140\n",
      "Processing files: 118/140\n",
      "Processing files: 119/140\n",
      "Processing files: 120/140\n",
      "Processing files: 121/140\n",
      "Processing files: 122/140\n",
      "Processing files: 123/140\n",
      "Processing files: 124/140\n",
      "Processing files: 125/140\n",
      "Processing files: 126/140\n",
      "Processing files: 127/140\n",
      "Processing files: 128/140\n",
      "Processing files: 129/140\n",
      "Processing files: 130/140\n",
      "Processing files: 131/140\n",
      "Processing files: 132/140\n",
      "Processing files: 133/140\n",
      "Processing files: 134/140\n",
      "Processing files: 135/140\n",
      "Processing files: 136/140\n",
      "Processing files: 137/140\n",
      "Processing files: 138/140\n",
      "Processing files: 139/140\n",
      "Processing files: 140/140\n",
      "All files have been processed\n",
      "FFFFFFFFFF\n",
      "112\n",
      "28\n",
      "140\n",
      "140\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "[0.22539543 0.77460456]\n",
      "255 1.0\n",
      "255.0 1.0\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128) (140, 128, 128, 2)\n",
      "(140, 128, 128, 1) (140, 128, 128, 2)\n",
      "[28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[0, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[1, 5, 8, 9, 17, 18, 35, 41, 43, 48, 53, 56, 65, 72, 74, 76, 80, 81, 84, 89, 99, 100, 103, 107, 113, 115, 118, 128]\n",
      "x_train:  (90, 128, 128, 1)\n",
      "y_train:  (90, 128, 128, 2)\n",
      "x_val:  (22, 128, 128, 1)\n",
      "y_val:  (22, 128, 128, 2)\n",
      "x_test:  (28, 128, 128, 1)\n",
      "y_test:  (28, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 128, 128, 64) 640         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 64, 64, 128)  73856       max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 32, 32, 256)  295168      max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 512)  1180160     max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 8, 8, 196)    903364      max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 196)    345940      conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DTran (None, 16, 16, 512)  401920      conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_transpose_28[0][0]        \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, 16, 512)  4719104     concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 512)  2359808     conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 32, 32, 256)  524544      conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 512)  0           conv2d_transpose_29[0][0]        \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 32, 32, 256)  1179904     concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 64, 64, 128)  131200      conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_30[0][0]        \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 64, 64, 128)  295040      concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 128, 128, 64) 32832       conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_31[0][0]        \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 128, 128, 64) 73792       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 128, 128, 2)  130         conv2d_150[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,426,394\n",
      "Trainable params: 16,426,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 30s 967ms/step - loss: 0.1839 - iou: 0.4777 - val_loss: 0.1310 - val_iou: 0.5647\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13105, saving model to segm_ALL_.h5\n",
      "[TensorShape([28685, None, 12]), TensorShape([28685, None, 1]), TensorShape([28685, None, 2])]\n",
      "[TensorShape([7807, None, 12]), TensorShape([7807, None, 1]), TensorShape([7807, None, 2])]\n",
      "(28685,) (7807,)\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 1,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 12)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'GCN',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, None, 64)     832         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_6 (GCN)                     (None, None, 64)     4160        dense_48[0][0]                   \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes_6 (PoolingNodes)  (None, 64)           0           gcn_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_6 (MLP)                     (None, 1)            19040       pooling_nodes_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 24,032\n",
      "Trainable params: 24,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_14/gcn_6/pooling_weighted_local_edges_7/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_14/gcn_6/pooling_weighted_local_edges_7/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_14/gcn_6/pooling_weighted_local_edges_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_14/gcn_6/gather_nodes_outgoing_7/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_14/gcn_6/gather_nodes_outgoing_7/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_14/gcn_6/gather_nodes_outgoing_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 - 3s - loss: 0.4267 - accuracy: 0.8350\n",
      "Epoch 2/150\n",
      "897/897 - 2s - loss: 0.2822 - accuracy: 0.8740\n",
      "Epoch 3/150\n",
      "897/897 - 2s - loss: 0.2608 - accuracy: 0.8818\n",
      "Epoch 4/150\n",
      "897/897 - 2s - loss: 0.2563 - accuracy: 0.8837\n",
      "Epoch 5/150\n",
      "897/897 - 2s - loss: 0.2499 - accuracy: 0.8860\n",
      "Epoch 6/150\n",
      "897/897 - 2s - loss: 0.2489 - accuracy: 0.8866\n",
      "Epoch 7/150\n",
      "897/897 - 2s - loss: 0.2417 - accuracy: 0.8917\n",
      "Epoch 8/150\n",
      "897/897 - 2s - loss: 0.2447 - accuracy: 0.8915\n",
      "Epoch 9/150\n",
      "897/897 - 2s - loss: 0.2415 - accuracy: 0.8912\n",
      "Epoch 10/150\n",
      "897/897 - 2s - loss: 0.2396 - accuracy: 0.8914 - val_loss: 0.2084 - val_accuracy: 0.9071\n",
      "Epoch 11/150\n",
      "897/897 - 2s - loss: 0.2397 - accuracy: 0.8929\n",
      "Epoch 12/150\n",
      "897/897 - 2s - loss: 0.2344 - accuracy: 0.8930\n",
      "Epoch 13/150\n",
      "897/897 - 2s - loss: 0.2354 - accuracy: 0.8948\n",
      "Epoch 14/150\n",
      "897/897 - 2s - loss: 0.2351 - accuracy: 0.8938\n",
      "Epoch 15/150\n",
      "897/897 - 2s - loss: 0.2350 - accuracy: 0.8952\n",
      "Epoch 16/150\n",
      "897/897 - 2s - loss: 0.2340 - accuracy: 0.8968\n",
      "Epoch 17/150\n",
      "897/897 - 2s - loss: 0.2300 - accuracy: 0.8951\n",
      "Epoch 18/150\n",
      "897/897 - 2s - loss: 0.2276 - accuracy: 0.8965\n",
      "Epoch 19/150\n",
      "897/897 - 2s - loss: 0.2300 - accuracy: 0.8968\n",
      "Epoch 20/150\n",
      "897/897 - 2s - loss: 0.2311 - accuracy: 0.8971 - val_loss: 0.2051 - val_accuracy: 0.9133\n",
      "Epoch 21/150\n",
      "897/897 - 2s - loss: 0.2268 - accuracy: 0.8979\n",
      "Epoch 22/150\n",
      "897/897 - 2s - loss: 0.2262 - accuracy: 0.8989\n",
      "Epoch 23/150\n",
      "897/897 - 2s - loss: 0.2253 - accuracy: 0.8985\n",
      "Epoch 24/150\n",
      "897/897 - 2s - loss: 0.2242 - accuracy: 0.8984\n",
      "Epoch 25/150\n",
      "897/897 - 2s - loss: 0.2245 - accuracy: 0.8973\n",
      "Epoch 26/150\n",
      "897/897 - 2s - loss: 0.2217 - accuracy: 0.8993\n",
      "Epoch 27/150\n",
      "897/897 - 2s - loss: 0.2253 - accuracy: 0.8978\n",
      "Epoch 28/150\n",
      "897/897 - 2s - loss: 0.2227 - accuracy: 0.8997\n",
      "Epoch 29/150\n",
      "897/897 - 2s - loss: 0.2229 - accuracy: 0.8974\n",
      "Epoch 30/150\n",
      "897/897 - 2s - loss: 0.2218 - accuracy: 0.8989 - val_loss: 0.2139 - val_accuracy: 0.9056\n",
      "Epoch 31/150\n",
      "897/897 - 2s - loss: 0.2207 - accuracy: 0.8984\n",
      "Epoch 32/150\n",
      "897/897 - 2s - loss: 0.2208 - accuracy: 0.8996\n",
      "Epoch 33/150\n",
      "897/897 - 2s - loss: 0.2185 - accuracy: 0.9006\n",
      "Epoch 34/150\n",
      "897/897 - 2s - loss: 0.2196 - accuracy: 0.9014\n",
      "Epoch 35/150\n",
      "897/897 - 2s - loss: 0.2170 - accuracy: 0.9024\n",
      "Epoch 36/150\n",
      "897/897 - 2s - loss: 0.2179 - accuracy: 0.9021\n",
      "Epoch 37/150\n",
      "897/897 - 2s - loss: 0.2183 - accuracy: 0.9022\n",
      "Epoch 38/150\n",
      "897/897 - 2s - loss: 0.2189 - accuracy: 0.9001\n",
      "Epoch 39/150\n",
      "897/897 - 2s - loss: 0.2162 - accuracy: 0.9021\n",
      "Epoch 40/150\n",
      "897/897 - 2s - loss: 0.2155 - accuracy: 0.9028 - val_loss: 0.1857 - val_accuracy: 0.9202\n",
      "Epoch 41/150\n",
      "897/897 - 2s - loss: 0.2143 - accuracy: 0.9028\n",
      "Epoch 42/150\n",
      "897/897 - 2s - loss: 0.2154 - accuracy: 0.9021\n",
      "Epoch 43/150\n",
      "897/897 - 2s - loss: 0.2164 - accuracy: 0.9013\n",
      "Epoch 44/150\n",
      "897/897 - 2s - loss: 0.2160 - accuracy: 0.9011\n",
      "Epoch 45/150\n",
      "897/897 - 2s - loss: 0.2142 - accuracy: 0.9022\n",
      "Epoch 46/150\n",
      "897/897 - 2s - loss: 0.2144 - accuracy: 0.9029\n",
      "Epoch 47/150\n",
      "897/897 - 2s - loss: 0.2132 - accuracy: 0.9027\n",
      "Epoch 48/150\n",
      "897/897 - 2s - loss: 0.2109 - accuracy: 0.9045\n",
      "Epoch 49/150\n",
      "897/897 - 2s - loss: 0.2114 - accuracy: 0.9036\n",
      "Epoch 50/150\n",
      "897/897 - 2s - loss: 0.2125 - accuracy: 0.9023 - val_loss: 0.1862 - val_accuracy: 0.9216\n",
      "Epoch 51/150\n",
      "897/897 - 2s - loss: 0.2118 - accuracy: 0.9033\n",
      "Epoch 52/150\n",
      "897/897 - 2s - loss: 0.2123 - accuracy: 0.9039\n",
      "Epoch 53/150\n",
      "897/897 - 2s - loss: 0.2101 - accuracy: 0.9043\n",
      "Epoch 54/150\n",
      "897/897 - 2s - loss: 0.2103 - accuracy: 0.9050\n",
      "Epoch 55/150\n",
      "897/897 - 2s - loss: 0.2115 - accuracy: 0.9023\n",
      "Epoch 56/150\n",
      "897/897 - 2s - loss: 0.2134 - accuracy: 0.9020\n",
      "Epoch 57/150\n",
      "897/897 - 2s - loss: 0.2083 - accuracy: 0.9074\n",
      "Epoch 58/150\n",
      "897/897 - 2s - loss: 0.2087 - accuracy: 0.9066\n",
      "Epoch 59/150\n",
      "897/897 - 2s - loss: 0.2091 - accuracy: 0.9050\n",
      "Epoch 60/150\n",
      "897/897 - 2s - loss: 0.2089 - accuracy: 0.9059 - val_loss: 0.1838 - val_accuracy: 0.9184\n",
      "Epoch 61/150\n",
      "897/897 - 2s - loss: 0.2066 - accuracy: 0.9064\n",
      "Epoch 62/150\n",
      "897/897 - 2s - loss: 0.2093 - accuracy: 0.9052\n",
      "Epoch 63/150\n",
      "897/897 - 2s - loss: 0.2079 - accuracy: 0.9043\n",
      "Epoch 64/150\n",
      "897/897 - 2s - loss: 0.2085 - accuracy: 0.9063\n",
      "Epoch 65/150\n",
      "897/897 - 2s - loss: 0.2067 - accuracy: 0.9073\n",
      "Epoch 66/150\n",
      "897/897 - 2s - loss: 0.2068 - accuracy: 0.9056\n",
      "Epoch 67/150\n",
      "897/897 - 2s - loss: 0.2084 - accuracy: 0.9066\n",
      "Epoch 68/150\n",
      "897/897 - 2s - loss: 0.2066 - accuracy: 0.9057\n",
      "Epoch 69/150\n",
      "897/897 - 2s - loss: 0.2060 - accuracy: 0.9062\n",
      "Epoch 70/150\n",
      "897/897 - 2s - loss: 0.2082 - accuracy: 0.9051 - val_loss: 0.1857 - val_accuracy: 0.9220\n",
      "Epoch 71/150\n",
      "897/897 - 2s - loss: 0.2051 - accuracy: 0.9069\n",
      "Epoch 72/150\n",
      "897/897 - 2s - loss: 0.2032 - accuracy: 0.9086\n",
      "Epoch 73/150\n",
      "897/897 - 2s - loss: 0.2057 - accuracy: 0.9074\n",
      "Epoch 74/150\n",
      "897/897 - 2s - loss: 0.2061 - accuracy: 0.9065\n",
      "Epoch 75/150\n",
      "897/897 - 2s - loss: 0.2044 - accuracy: 0.9058\n",
      "Epoch 76/150\n",
      "897/897 - 2s - loss: 0.2032 - accuracy: 0.9078\n",
      "Epoch 77/150\n",
      "897/897 - 2s - loss: 0.2024 - accuracy: 0.9076\n",
      "Epoch 78/150\n",
      "897/897 - 2s - loss: 0.2033 - accuracy: 0.9068\n",
      "Epoch 79/150\n",
      "897/897 - 2s - loss: 0.2029 - accuracy: 0.9074\n",
      "Epoch 80/150\n",
      "897/897 - 2s - loss: 0.2020 - accuracy: 0.9087 - val_loss: 0.1878 - val_accuracy: 0.9174\n",
      "Epoch 81/150\n",
      "897/897 - 2s - loss: 0.2029 - accuracy: 0.9064\n",
      "Epoch 82/150\n",
      "897/897 - 2s - loss: 0.2038 - accuracy: 0.9080\n",
      "Epoch 83/150\n",
      "897/897 - 2s - loss: 0.2045 - accuracy: 0.9062\n",
      "Epoch 84/150\n",
      "897/897 - 2s - loss: 0.2044 - accuracy: 0.9078\n",
      "Epoch 85/150\n",
      "897/897 - 2s - loss: 0.2044 - accuracy: 0.9078\n",
      "Epoch 86/150\n",
      "897/897 - 2s - loss: 0.2034 - accuracy: 0.9060\n",
      "Epoch 87/150\n",
      "897/897 - 2s - loss: 0.2021 - accuracy: 0.9081\n",
      "Epoch 88/150\n",
      "897/897 - 2s - loss: 0.2017 - accuracy: 0.9085\n",
      "Epoch 89/150\n",
      "897/897 - 2s - loss: 0.2020 - accuracy: 0.9097\n",
      "Epoch 90/150\n",
      "897/897 - 2s - loss: 0.2016 - accuracy: 0.9085 - val_loss: 0.1819 - val_accuracy: 0.9196\n",
      "Epoch 91/150\n",
      "897/897 - 2s - loss: 0.2027 - accuracy: 0.9084\n",
      "Epoch 92/150\n",
      "897/897 - 2s - loss: 0.2013 - accuracy: 0.9081\n",
      "Epoch 93/150\n",
      "897/897 - 2s - loss: 0.2020 - accuracy: 0.9072\n",
      "Epoch 94/150\n",
      "897/897 - 2s - loss: 0.1999 - accuracy: 0.9093\n",
      "Epoch 95/150\n",
      "897/897 - 2s - loss: 0.2012 - accuracy: 0.9084\n",
      "Epoch 96/150\n",
      "897/897 - 2s - loss: 0.2017 - accuracy: 0.9091\n",
      "Epoch 97/150\n",
      "897/897 - 2s - loss: 0.2013 - accuracy: 0.9097\n",
      "Epoch 98/150\n",
      "897/897 - 2s - loss: 0.2008 - accuracy: 0.9094\n",
      "Epoch 99/150\n",
      "897/897 - 2s - loss: 0.1999 - accuracy: 0.9091\n",
      "Epoch 100/150\n",
      "897/897 - 2s - loss: 0.2000 - accuracy: 0.9086 - val_loss: 0.1851 - val_accuracy: 0.9208\n",
      "Epoch 101/150\n",
      "897/897 - 2s - loss: 0.2029 - accuracy: 0.9089\n",
      "Epoch 102/150\n",
      "897/897 - 2s - loss: 0.1985 - accuracy: 0.9090\n",
      "Epoch 103/150\n",
      "897/897 - 2s - loss: 0.2008 - accuracy: 0.9097\n",
      "Epoch 104/150\n",
      "897/897 - 2s - loss: 0.2000 - accuracy: 0.9082\n",
      "Epoch 105/150\n",
      "897/897 - 2s - loss: 0.1998 - accuracy: 0.9084\n",
      "Epoch 106/150\n",
      "897/897 - 2s - loss: 0.1964 - accuracy: 0.9101\n",
      "Epoch 107/150\n",
      "897/897 - 2s - loss: 0.1953 - accuracy: 0.9108\n",
      "Epoch 108/150\n",
      "897/897 - 2s - loss: 0.1957 - accuracy: 0.9106\n",
      "Epoch 109/150\n",
      "897/897 - 2s - loss: 0.1974 - accuracy: 0.9101\n",
      "Epoch 110/150\n",
      "897/897 - 2s - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.2037 - val_accuracy: 0.9101\n",
      "Epoch 111/150\n",
      "897/897 - 2s - loss: 0.1954 - accuracy: 0.9118\n",
      "Epoch 112/150\n",
      "897/897 - 2s - loss: 0.1952 - accuracy: 0.9112\n",
      "Epoch 113/150\n",
      "897/897 - 2s - loss: 0.1931 - accuracy: 0.9136\n",
      "Epoch 114/150\n",
      "897/897 - 2s - loss: 0.1942 - accuracy: 0.9130\n",
      "Epoch 115/150\n",
      "897/897 - 2s - loss: 0.1932 - accuracy: 0.9128\n",
      "Epoch 116/150\n",
      "897/897 - 2s - loss: 0.1924 - accuracy: 0.9112\n",
      "Epoch 117/150\n",
      "897/897 - 2s - loss: 0.1921 - accuracy: 0.9126\n",
      "Epoch 118/150\n",
      "897/897 - 2s - loss: 0.1925 - accuracy: 0.9108\n",
      "Epoch 119/150\n",
      "897/897 - 2s - loss: 0.1911 - accuracy: 0.9133\n",
      "Epoch 120/150\n",
      "897/897 - 2s - loss: 0.1916 - accuracy: 0.9132 - val_loss: 0.1801 - val_accuracy: 0.9198\n",
      "Epoch 121/150\n",
      "897/897 - 2s - loss: 0.1902 - accuracy: 0.9125\n",
      "Epoch 122/150\n",
      "897/897 - 2s - loss: 0.2036 - accuracy: 0.9079\n",
      "Epoch 123/150\n",
      "897/897 - 2s - loss: 0.1929 - accuracy: 0.9116\n",
      "Epoch 124/150\n",
      "897/897 - 2s - loss: 0.1884 - accuracy: 0.9147\n",
      "Epoch 125/150\n",
      "897/897 - 2s - loss: 0.1877 - accuracy: 0.9154\n",
      "Epoch 126/150\n",
      "897/897 - 2s - loss: 0.1883 - accuracy: 0.9151\n",
      "Epoch 127/150\n",
      "897/897 - 2s - loss: 0.1882 - accuracy: 0.9146\n",
      "Epoch 128/150\n",
      "897/897 - 2s - loss: 0.1873 - accuracy: 0.9159\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 - 2s - loss: 0.1845 - accuracy: 0.9166\n",
      "Epoch 130/150\n",
      "897/897 - 2s - loss: 0.1869 - accuracy: 0.9141 - val_loss: 0.1838 - val_accuracy: 0.9224\n",
      "Epoch 131/150\n",
      "897/897 - 2s - loss: 0.1862 - accuracy: 0.9168\n",
      "Epoch 132/150\n",
      "897/897 - 2s - loss: 0.1851 - accuracy: 0.9155\n",
      "Epoch 133/150\n",
      "897/897 - 2s - loss: 0.1832 - accuracy: 0.9169\n",
      "Epoch 134/150\n",
      "897/897 - 2s - loss: 0.1829 - accuracy: 0.9145\n",
      "Epoch 135/150\n",
      "897/897 - 2s - loss: 0.1834 - accuracy: 0.9175\n",
      "Epoch 136/150\n",
      "897/897 - 2s - loss: 0.1821 - accuracy: 0.9172\n",
      "Epoch 137/150\n",
      "897/897 - 2s - loss: 0.1815 - accuracy: 0.9164\n",
      "Epoch 138/150\n",
      "897/897 - 2s - loss: 0.1819 - accuracy: 0.9158\n",
      "Epoch 139/150\n",
      "897/897 - 2s - loss: 0.1815 - accuracy: 0.9168\n",
      "Epoch 140/150\n",
      "897/897 - 2s - loss: 0.1801 - accuracy: 0.9181 - val_loss: 0.1856 - val_accuracy: 0.9217\n",
      "Epoch 141/150\n",
      "897/897 - 2s - loss: 0.1799 - accuracy: 0.9183\n",
      "Epoch 142/150\n",
      "897/897 - 2s - loss: 0.1787 - accuracy: 0.9178\n",
      "Epoch 143/150\n",
      "897/897 - 2s - loss: 0.1787 - accuracy: 0.9181\n",
      "Epoch 144/150\n",
      "897/897 - 2s - loss: 0.1783 - accuracy: 0.9176\n",
      "Epoch 145/150\n",
      "897/897 - 2s - loss: 0.1771 - accuracy: 0.9181\n",
      "Epoch 146/150\n",
      "897/897 - 2s - loss: 0.1768 - accuracy: 0.9198\n",
      "Epoch 147/150\n",
      "897/897 - 2s - loss: 0.1765 - accuracy: 0.9186\n",
      "Epoch 148/150\n",
      "897/897 - 2s - loss: 0.1755 - accuracy: 0.9192\n",
      "Epoch 149/150\n",
      "897/897 - 2s - loss: 0.1750 - accuracy: 0.9193\n",
      "Epoch 150/150\n",
      "897/897 - 2s - loss: 0.1745 - accuracy: 0.9199 - val_loss: 0.1968 - val_accuracy: 0.9233\n",
      "Print Time for taining:  618.342036895001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as dense_49_layer_call_fn, dense_49_layer_call_and_return_conditional_losses, gather_nodes_outgoing_7_layer_call_fn, gather_nodes_outgoing_7_layer_call_and_return_conditional_losses, dense_50_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_40_com/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_objects/300_pixel_40_com/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5725  319]\n",
      " [ 280 1483]]\n"
     ]
    }
   ],
   "source": [
    "for data_set in DATA_SET_DIR_NAMES:\n",
    "    process_data_set(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
