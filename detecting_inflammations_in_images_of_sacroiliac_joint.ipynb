{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsage:\\n1. Data directory must be in the same directory as the script\\n2. Images, lables and superpixels directories must be inside data directory\\n3. Script parameters must be specified in script parameters cell\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Usage:\n",
    "1. Data directory must be in the same directory as the script\n",
    "2. Images, lables and superpixels directories must be inside data directory\n",
    "3. Script parameters must be specified in script parameters cell\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.future.graph as skigraph\n",
    "import shutil\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from kgcnn.literature.GCN import make_model\n",
    "from kgcnn.utils.data import ragged_tensor_from_nested_numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from kgcnn.utils.learning import LinearLearningRateScheduler\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# script parameterss\n",
    "MAIN_DIR_PATH = \"/home/daniel/Praca inÅ¼ynierska/DetectingInflammationsInImagesOfSacroiliacJoint\"\n",
    "DATA_DIR_NAME = \"input/data_set_2\"\n",
    "IMAGES_DIR_NAME = \"images\"\n",
    "SUPERPIXELS_LABELS_DIR_NAME = \"labels\"\n",
    "SUPERPIXELS_DIR_NAME = \"superpixels\"\n",
    "MASKS_DIR_NAME = \"masks\"\n",
    "\n",
    "IMAGE_FILE_PREFIX = \"STIR\"\n",
    "SUPERPIXELS_FILE_PREFIX = \"1000SuperPixelMeanValueTPS_\"\n",
    "\n",
    "IMG_CMAP = \"pink\"\n",
    "EDGE_CMAP = \"viridis\"\n",
    "EDGE_WIDTH = 2\n",
    "\n",
    "CREATE_SUPERPIXELS_IMAGES = False\n",
    "\n",
    "# globals\n",
    "DATA_DIR_PATH = f\"{MAIN_DIR_PATH}/{DATA_DIR_NAME}\"\n",
    "IMAGES_DIR_PATH = f\"{DATA_DIR_PATH}/{IMAGES_DIR_NAME}\"\n",
    "SUPERPIXELS_LABELS_DIR_PATH = f\"{DATA_DIR_PATH}/{SUPERPIXELS_LABELS_DIR_NAME}\"\n",
    "SUPERPIXELS_DIR_PATH = f\"{DATA_DIR_PATH}/{SUPERPIXELS_DIR_NAME}\"\n",
    "MASKS_DIR_PATH = f\"{MAIN_DIR_PATH}/{MASKS_DIR_NAME}\"\n",
    "subgraphs_info = []\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def show_2d_image_from_3d_image(image_3d, index_of_2d_image):\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(image_3d[:,:,index_of_2d_image], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def save_object(filename, obj):\n",
    "    obj_file = open(filename, 'wb')\n",
    "    pickle.dump(obj, obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "def load_object(filename):\n",
    "    obj_file = open(filename, 'rb')\n",
    "    obj = pickle.load(obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "# read data\n",
    "def read_binary_data_3D(file_name, image_size, image_count, voxel_bytes, signed='Y', byte_order='BE'):\n",
    "    if voxel_bytes == 2:\n",
    "        if signed == 'N':\n",
    "            d = np.zeros((image_size, image_size, image_count), np.uint16)\n",
    "        else:\n",
    "            d = np.zeros((image_size, image_size, image_count), np.int16)\n",
    "    elif voxel_bytes == 1:\n",
    "        if signed == 'N':\n",
    "            d = np.zeros((image_size, image_size, image_count), np.uint8)\n",
    "        else:\n",
    "            d = np.zeros((image_size, image_size, image_count), np.int8)\n",
    "    else:\n",
    "        print('Wrong number of bytes per voxel')\n",
    "        return\n",
    "\n",
    "    f = open(file_name, \"rb\")\n",
    "    for i in range(0, image_count):\n",
    "        for j in range(0, image_size):\n",
    "            for k in range(0, image_size):\n",
    "                byte = f.read(voxel_bytes)\n",
    "                if voxel_bytes == 2:\n",
    "                    if byte_order == 'BE':\n",
    "                        a = 256 * byte[0] + byte[1]\n",
    "                    else:\n",
    "                        a = byte[0] + 256 * byte[1]\n",
    "                else:\n",
    "                    a = byte[0]\n",
    "                d[j,k,i] = a\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "# rag creation\n",
    "FileInfo = collections.namedtuple('FileInfo', ['name', 'patient_id', 'height', 'width', 'image_count', 'voxel_bytes'])\n",
    "class SubgraphInfo:\n",
    "    def __init__(self, rag, neighbor_graph, label):\n",
    "        self.rag = rag\n",
    "        self.neighbor_graph = neighbor_graph\n",
    "        self.label = label\n",
    "        self.unnormalized_edge_indices = None\n",
    "        self.normalized_edge_indices = None\n",
    "        self.edges = None\n",
    "        self.nodes = None\n",
    "        \n",
    "def create_rag_on_superpixels_image(superpixel_labels, superpixels, rag, file_info, image_number, edge_width, img_cmap, edge_cmap):\n",
    "    PATIENT_ID_DIR_PATH = f\"saved_objects/rags/{file_info.patient_id}\"\n",
    "    RAG_IMAGE_PATH = f\"{PATIENT_ID_DIR_PATH}/rag_{image_number}_{file_info.height}_{file_info.width}_{file_info.image_count}_{file_info.voxel_bytes}_.png\"\n",
    "    if os.path.exists(RAG_IMAGE_PATH):\n",
    "        shutil.rmtree(PATIENT_ID_DIR_PATH)\n",
    "    os.makedirs(PATIENT_ID_DIR_PATH, exist_ok=True)\n",
    "    \n",
    "    rag_file = open(RAG_IMAGE_PATH, \"w\")\n",
    "    rag_file.close()\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "    ax.axis('off')\n",
    "    lc = skigraph.show_rag(\n",
    "        superpixel_labels, rag, superpixels, img_cmap=img_cmap, edge_width=edge_width, edge_cmap=edge_cmap, ax=ax\n",
    "    )\n",
    "    fig.colorbar(lc, fraction=0.04, ax=ax)\n",
    "    fig.savefig(RAG_IMAGE_PATH)\n",
    "    plt.close(fig) \n",
    "    \n",
    "def assign_label(image, superpixels_labels, rag):\n",
    "    white_pixels_count = {}\n",
    "    total_pixels_count = {}\n",
    "    for (i, row) in enumerate(superpixels_labels):\n",
    "        for (j, label) in enumerate(row):\n",
    "            if label in total_pixels_count:\n",
    "                total_pixels_count[label] += 1\n",
    "            else:\n",
    "                total_pixels_count[label] = 1 \n",
    "            if image[i][j] >= 130:\n",
    "                if label in white_pixels_count:\n",
    "                    white_pixels_count[label] += 1\n",
    "                else:\n",
    "                    white_pixels_count[label] = 1\n",
    "                    \n",
    "    for (i, node) in enumerate(rag):\n",
    "        if i in white_pixels_count and white_pixels_count[i] / total_pixels_count[i] >= 0.75:\n",
    "            rag.nodes[node]['label'] = '1'\n",
    "        else:\n",
    "            rag.nodes[node]['label'] = '0'\n",
    "    \n",
    "def process_bmp_images(images_dir_path, superpixels_labels_dir_path, superpixels_dir_path, masks_dir_path):\n",
    "    file_names = os.listdir(images_dir_path)\n",
    "    rags = {i: list() for i in range(1, len(file_names) + 1)}\n",
    "    \n",
    "    for (image_index, file_name) in enumerate(file_names):\n",
    "        print(f\"Processing file: {image_index + 1}/{len(file_names)}\")\n",
    "        img = ImageOps.grayscale((Image.open(f\"{IMAGES_DIR_PATH}/{file_name}\")))\n",
    "        img = np.array(img)\n",
    "        img = img/(img.max()/255.0)  \n",
    "        file_id = file_name.split(\"_\")[-1][0:-4]\n",
    "        try:\n",
    "            superpixels_labels = np.fromfile(f\"{superpixels_labels_dir_path}/org_{file_id}.dat\", dtype=np.dtype((np.int32, (img.shape[0], img.shape[1]))))[0]\n",
    "        except: \n",
    "            continue\n",
    "        rag = skigraph.rag_mean_color(img, superpixels_labels)\n",
    "        rags[image_index] = [rag]\n",
    "        assign_label(img, superpixels_labels, rag)   \n",
    "    print(\"All files have been processed\")\n",
    "    \n",
    "    return rags\n",
    "\n",
    "def process_3D_image(superpixels_labels_file, image_file, superpixels_file, file_info, create_superpixels_images = CREATE_SUPERPIXELS_IMAGES):\n",
    "    rags = []\n",
    "    \n",
    "    for file_index in range(file_info.image_count):\n",
    "        print(f\"Processing sub images: {file_index + 1}/{file_info.image_count}\")\n",
    "        superpixels_labels = superpixels_labels_file[:,:,file_index]\n",
    "        img = image_file[:,:,file_index]\n",
    "        img = img/(img.max()/255.0) \n",
    "        rag = skigraph.rag_mean_color(img, superpixels_labels)\n",
    "        rags.append(rag)\n",
    "        assign_label(img, superpixels_labels, rag)\n",
    "        \n",
    "        if create_superpixels_images:\n",
    "            superpixels = superpixels_file[:,:,file_index]\n",
    "            create_rag_on_superpixels_image(\n",
    "               superpixels_labels, superpixels, rag, file_info, file_index + 1, EDGE_WIDTH, IMG_CMAP, EDGE_CMAP\n",
    "            )\n",
    "        \n",
    "    return rags\n",
    "\n",
    "def process_all_3D_images(images_dir_path, superpixels_labels_dir_path, superpixels_dir_path):\n",
    "    file_names = os.listdir(superpixels_labels_dir_path)\n",
    "    rags = {i: list() for i in range(1, len(file_names) + 1)}\n",
    "\n",
    "    for (file_3d_index, file_name) in enumerate(file_names, start=1):\n",
    "        unprocessed_file_info = file_name.split(\"_\")[:-1]\n",
    "        unprocessed_file_info[1:] = [int(unprocessed_file_info[i]) for i in range(1, len(unprocessed_file_info))]\n",
    "        file_info = FileInfo(*unprocessed_file_info)\n",
    "        file_suffix = f\"{file_info.patient_id}_{file_info.height}_{file_info.width}_{file_info.image_count}_{file_info.voxel_bytes}_.raw\"\n",
    "        print(f\"Directory processing progress: {file_3d_index}/{len(file_names)}, current patient: {file_info.patient_id}\")\n",
    "        \n",
    "        superpixels_labels_file = read_binary_data_3D(\n",
    "            f\"{superpixels_labels_dir_path}/{file_name}\",\n",
    "            file_info.height,\n",
    "            file_info.image_count,\n",
    "            file_info.voxel_bytes,\n",
    "            signed='Y',\n",
    "            byte_order='EB'\n",
    "        )\n",
    "        image_file = read_binary_data_3D(\n",
    "            f\"{images_dir_path}/{IMAGE_FILE_PREFIX}_{file_suffix}\",\n",
    "            file_info.height,\n",
    "            file_info.image_count,\n",
    "            file_info.voxel_bytes,\n",
    "            signed='Y',\n",
    "            byte_order='BE'\n",
    "        )\n",
    "        superpixels_file = read_binary_data_3D(\n",
    "            f\"{superpixels_dir_path}/{SUPERPIXELS_FILE_PREFIX}{file_suffix}\",\n",
    "            file_info.height,\n",
    "            file_info.image_count,\n",
    "            file_info.voxel_bytes,\n",
    "            signed='Y',\n",
    "            byte_order='EB'\n",
    "        )\n",
    "        \n",
    "        rags[file_info.patient_id] = process_3D_image(superpixels_labels_file, image_file, superpixels_file, file_info)\n",
    "    \n",
    "    print(\"All 3D files have been processed\")\n",
    "    return rags\n",
    "\n",
    "# split into subgraphs containing node and node neighbors\n",
    "def split_into_subgraphs(rags, how_many):\n",
    "    neighbor_graphs = []\n",
    "    labels = []\n",
    "    for (i, rag_3d) in enumerate(rags.values()):\n",
    "        if i ==  how_many:\n",
    "            break\n",
    "        print(i)\n",
    "        for rag_2d in rag_3d:\n",
    "            for node in rag_2d.nodes:\n",
    "                nodes = [n for n in rag_2d.neighbors(node)]\n",
    "                nodes.append(node)\n",
    "                neighbor_graphs.append(rag_2d.subgraph(nodes))\n",
    "                labels.append([float(rag_2d.nodes[node]['label'])])\n",
    "                subgraphs_info.append(SubgraphInfo(rag_2d, neighbor_graphs[-1], labels[-1]))\n",
    "    return neighbor_graphs, labels\n",
    "\n",
    "def normalize_edge_indices(edge_indices):\n",
    "    result = []\n",
    "    flat_list = []\n",
    "    for sublist in edge_indices:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "            \n",
    "    flat_list.sort()\n",
    "    flat_list = list(dict.fromkeys(flat_list))\n",
    "    change = {key:value for (value, key) in enumerate(flat_list)}\n",
    "    \n",
    "    for sublist in edge_indices:\n",
    "        temp = []\n",
    "        for item in sublist:\n",
    "            temp.append(change[item])\n",
    "        result.append(temp)    \n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def prepare_data(neighbor_graphs):\n",
    "    nodes = []\n",
    "    edge_indices = []\n",
    "    edges = []\n",
    "    for (subgraph, graph) in enumerate(neighbor_graphs):\n",
    "        mean_intensities = []\n",
    "        edges_prim = []\n",
    "        for node in graph.nodes:\n",
    "            mean_intensities.append(graph.nodes[node]['mean color'][0])  \n",
    "        for data in graph.edges.data():\n",
    "            edges_prim.append(1)\n",
    "        nodes.append(mean_intensities)\n",
    "        edges.append(edges_prim)\n",
    "        edge_indices.append(normalize_edge_indices([list(e) for e in graph.edges]))\n",
    "        subgraphs_info[subgraph].nodes = nodes[-1]\n",
    "        subgraphs_info[subgraph].unnormalized_edge_indices = [list(e) for e in graph.edges]\n",
    "        subgraphs_info[subgraph].normalized_edge_indices = edge_indices[-1]\n",
    "        subgraphs_info[subgraph].edges = edges[-1]\n",
    "\n",
    "    return nodes, edge_indices, edges\n",
    "\n",
    "def process_images(images_dir_path, superpixels_labels_dir_path, superpixels_dir_path, masks_dir_path, file_format):\n",
    "    if file_format == 'raw':\n",
    "        return process_all_3D_images(images_dir_path, superpixels_labels_dir_path, superpixels_dir_path)\n",
    "    elif file_format == 'bmp':\n",
    "        return process_bmp_images(images_dir_path, superpixels_labels_dir_path, superpixels_dir_path, masks_dir_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 1/140\n",
      "Processing file: 2/140\n",
      "Processing file: 3/140\n",
      "Processing file: 4/140\n",
      "Processing file: 5/140\n",
      "Processing file: 6/140\n",
      "Processing file: 7/140\n",
      "Processing file: 8/140\n",
      "Processing file: 9/140\n",
      "Processing file: 10/140\n",
      "Processing file: 11/140\n",
      "Processing file: 12/140\n",
      "Processing file: 13/140\n",
      "Processing file: 14/140\n",
      "Processing file: 15/140\n",
      "Processing file: 16/140\n",
      "Processing file: 17/140\n",
      "Processing file: 18/140\n",
      "Processing file: 19/140\n",
      "Processing file: 20/140\n",
      "Processing file: 21/140\n",
      "Processing file: 22/140\n",
      "Processing file: 23/140\n",
      "Processing file: 24/140\n",
      "Processing file: 25/140\n",
      "Processing file: 26/140\n",
      "Processing file: 27/140\n",
      "Processing file: 28/140\n",
      "Processing file: 29/140\n",
      "Processing file: 30/140\n",
      "Processing file: 31/140\n",
      "Processing file: 32/140\n",
      "Processing file: 33/140\n",
      "Processing file: 34/140\n",
      "Processing file: 35/140\n",
      "Processing file: 36/140\n",
      "Processing file: 37/140\n",
      "Processing file: 38/140\n",
      "Processing file: 39/140\n",
      "Processing file: 40/140\n",
      "Processing file: 41/140\n",
      "Processing file: 42/140\n",
      "Processing file: 43/140\n",
      "Processing file: 44/140\n",
      "Processing file: 45/140\n",
      "Processing file: 46/140\n",
      "Processing file: 47/140\n",
      "Processing file: 48/140\n",
      "Processing file: 49/140\n",
      "Processing file: 50/140\n",
      "Processing file: 51/140\n",
      "Processing file: 52/140\n",
      "Processing file: 53/140\n",
      "Processing file: 54/140\n",
      "Processing file: 55/140\n",
      "Processing file: 56/140\n",
      "Processing file: 57/140\n",
      "Processing file: 58/140\n",
      "Processing file: 59/140\n",
      "Processing file: 60/140\n",
      "Processing file: 61/140\n",
      "Processing file: 62/140\n",
      "Processing file: 63/140\n",
      "Processing file: 64/140\n",
      "Processing file: 65/140\n",
      "Processing file: 66/140\n",
      "Processing file: 67/140\n",
      "Processing file: 68/140\n",
      "Processing file: 69/140\n",
      "Processing file: 70/140\n",
      "Processing file: 71/140\n",
      "Processing file: 72/140\n",
      "Processing file: 73/140\n",
      "Processing file: 74/140\n",
      "Processing file: 75/140\n",
      "Processing file: 76/140\n",
      "Processing file: 77/140\n",
      "Processing file: 78/140\n",
      "Processing file: 79/140\n",
      "Processing file: 80/140\n",
      "Processing file: 81/140\n",
      "Processing file: 82/140\n",
      "Processing file: 83/140\n",
      "Processing file: 84/140\n",
      "Processing file: 85/140\n",
      "Processing file: 86/140\n",
      "Processing file: 87/140\n",
      "Processing file: 88/140\n",
      "Processing file: 89/140\n",
      "Processing file: 90/140\n",
      "Processing file: 91/140\n",
      "Processing file: 92/140\n",
      "Processing file: 93/140\n",
      "Processing file: 94/140\n",
      "Processing file: 95/140\n",
      "Processing file: 96/140\n",
      "Processing file: 97/140\n",
      "Processing file: 98/140\n",
      "Processing file: 99/140\n",
      "Processing file: 100/140\n",
      "Processing file: 101/140\n",
      "Processing file: 102/140\n",
      "Processing file: 103/140\n",
      "Processing file: 104/140\n",
      "Processing file: 105/140\n",
      "Processing file: 106/140\n",
      "Processing file: 107/140\n",
      "Processing file: 108/140\n",
      "Processing file: 109/140\n",
      "Processing file: 110/140\n",
      "Processing file: 111/140\n",
      "Processing file: 112/140\n",
      "Processing file: 113/140\n",
      "Processing file: 114/140\n",
      "Processing file: 115/140\n",
      "Processing file: 116/140\n",
      "Processing file: 117/140\n",
      "Processing file: 118/140\n",
      "Processing file: 119/140\n",
      "Processing file: 120/140\n",
      "Processing file: 121/140\n",
      "Processing file: 122/140\n",
      "Processing file: 123/140\n",
      "Processing file: 124/140\n",
      "Processing file: 125/140\n",
      "Processing file: 126/140\n",
      "Processing file: 127/140\n",
      "Processing file: 128/140\n",
      "Processing file: 129/140\n",
      "Processing file: 130/140\n",
      "Processing file: 131/140\n",
      "Processing file: 132/140\n",
      "Processing file: 133/140\n",
      "Processing file: 134/140\n",
      "Processing file: 135/140\n",
      "Processing file: 136/140\n",
      "Processing file: 137/140\n",
      "Processing file: 138/140\n",
      "Processing file: 139/140\n",
      "Processing file: 140/140\n",
      "All files have been processed\n"
     ]
    }
   ],
   "source": [
    "rags = process_images(IMAGES_DIR_PATH, SUPERPIXELS_LABELS_DIR_PATH, SUPERPIXELS_DIR_PATH, MASKS_DIR_PATH, 'bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "neighbor_graphs, labels = split_into_subgraphs(rags, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edge_indices, edges =  prepare_data(neighbor_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 18], [1, 20], [1, 25], [33, 18], [33, 20], [33, 37], [37, 20], [37, 25], [18, 20], [20, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs_info[20].unnormalized_edge_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 16), (0, 18), (1, 2), (1, 18), (1, 20), (1, 25), (2, 3), (2, 25), (2, 26), (2, 34), (3, 4), (3, 21), (3, 26), (3, 38), (4, 5), (4, 21), (4, 41), (4, 30), (5, 15), (5, 6), (5, 30), (15, 6), (15, 7), (15, 30), (15, 31), (15, 42), (6, 7), (7, 8), (7, 19), (7, 28), (7, 31), (8, 9), (8, 28), (9, 10), (9, 29), (9, 28), (9, 44), (10, 11), (10, 22), (10, 29), (10, 43), (10, 23), (11, 12), (11, 17), (11, 22), (11, 23), (11, 24), (12, 13), (12, 17), (12, 24), (12, 35), (12, 40), (13, 14), (13, 35), (13, 36), (14, 27), (14, 36), (16, 18), (16, 33), (16, 45), (17, 24), (18, 20), (18, 33), (19, 28), (19, 31), (19, 39), (20, 25), (20, 33), (20, 37), (21, 38), (21, 41), (22, 23), (23, 24), (23, 29), (23, 43), (23, 47), (24, 40), (24, 47), (25, 34), (25, 37), (26, 34), (26, 38), (27, 32), (27, 36), (28, 39), (28, 49), (28, 44), (29, 43), (29, 44), (30, 46), (30, 42), (30, 41), (30, 58), (30, 55), (30, 64), (31, 39), (31, 42), (32, 36), (32, 53), (33, 37), (33, 45), (34, 37), (34, 38), (34, 54), (34, 57), (35, 40), (35, 36), (36, 40), (36, 53), (36, 59), (36, 65), (36, 67), (37, 45), (37, 48), (37, 54), (37, 63), (38, 41), (38, 57), (38, 60), (38, 73), (38, 69), (39, 42), (39, 49), (39, 50), (40, 47), (40, 52), (40, 65), (40, 59), (41, 58), (41, 60), (42, 46), (42, 50), (42, 55), (42, 61), (43, 44), (43, 47), (43, 62), (44, 49), (44, 51), (44, 56), (44, 62), (44, 70), (44, 74), (44, 86), (45, 48), (45, 66), (46, 55), (47, 52), (47, 62), (48, 63), (48, 54), (48, 66), (49, 50), (49, 51), (50, 51), (50, 61), (50, 55), (51, 61), (51, 70), (51, 78), (52, 62), (52, 65), (52, 75), (53, 67), (53, 79), (54, 57), (54, 63), (54, 68), (54, 72), (55, 64), (55, 61), (57, 68), (57, 73), (57, 69), (57, 82), (58, 60), (58, 64), (58, 69), (59, 67), (59, 65), (59, 75), (59, 87), (60, 69), (61, 64), (61, 77), (61, 78), (62, 65), (62, 75), (62, 86), (63, 66), (63, 72), (63, 76), (64, 69), (64, 77), (64, 81), (65, 75), (66, 71), (66, 76), (67, 79), (67, 90), (67, 87), (68, 72), (68, 76), (68, 82), (68, 94), (69, 73), (69, 81), (69, 83), (69, 82), (69, 88), (70, 74), (70, 78), (71, 76), (71, 80), (72, 76), (74, 78), (74, 86), (74, 85), (74, 98), (74, 99), (74, 102), (75, 86), (75, 87), (75, 89), (75, 103), (76, 80), (76, 92), (76, 93), (76, 94), (77, 78), (77, 81), (77, 84), (77, 85), (78, 85), (78, 84), (79, 90), (80, 92), (80, 95), (81, 84), (81, 83), (81, 91), (81, 101), (81, 105), (82, 88), (82, 94), (82, 96), (82, 107), (82, 108), (83, 88), (83, 101), (83, 108), (84, 91), (84, 97), (84, 85), (84, 100), (85, 100), (85, 98), (86, 89), (86, 99), (86, 106), (86, 117), (86, 125), (87, 90), (87, 103), (88, 108), (89, 106), (89, 103), (89, 112), (90, 103), (90, 110), (90, 113), (91, 97), (91, 105), (92, 95), (92, 93), (92, 104), (93, 94), (93, 104), (94, 96), (94, 104), (94, 114), (95, 104), (95, 122), (95, 120), (96, 107), (96, 114), (96, 123), (97, 105), (97, 100), (97, 115), (97, 109), (98, 102), (98, 100), (98, 116), (99, 102), (99, 111), (99, 125), (99, 127), (100, 115), (100, 119), (100, 116), (101, 105), (101, 109), (101, 108), (101, 121), (102, 111), (102, 116), (103, 112), (103, 113), (103, 126), (103, 129), (104, 114), (104, 120), (104, 122), (104, 130), (104, 131), (105, 109), (106, 117), (106, 112), (107, 108), (107, 118), (107, 123), (108, 118), (108, 121), (108, 139), (109, 115), (109, 121), (109, 124), (109, 132), (110, 113), (111, 116), (111, 127), (112, 117), (112, 126), (113, 129), (113, 135), (113, 126), (113, 142), (114, 123), (114, 131), (114, 138), (115, 119), (115, 124), (115, 134), (115, 140), (115, 136), (116, 119), (116, 134), (116, 127), (116, 144), (116, 149), (117, 125), (117, 128), (117, 126), (117, 133), (118, 123), (118, 139), (119, 134), (120, 122), (120, 130), (120, 137), (121, 124), (121, 132), (121, 139), (121, 146), (121, 148), (122, 137), (123, 139), (123, 138), (123, 143), (124, 132), (124, 140), (125, 128), (125, 127), (125, 154), (125, 155), (126, 129), (126, 133), (126, 142), (127, 149), (127, 150), (127, 154), (128, 133), (128, 141), (128, 151), (128, 155), (130, 131), (130, 137), (130, 145), (130, 147), (130, 156), (131, 138), (131, 145), (132, 140), (132, 148), (132, 153), (133, 141), (133, 142), (134, 136), (134, 144), (135, 142), (135, 152), (135, 158), (136, 140), (136, 144), (136, 150), (136, 163), (137, 156), (137, 167), (138, 143), (138, 145), (139, 143), (139, 146), (139, 160), (140, 153), (140, 162), (140, 163), (141, 142), (141, 151), (141, 152), (141, 166), (142, 152), (143, 145), (143, 159), (143, 160), (143, 146), (143, 161), (144, 149), (144, 150), (145, 147), (145, 159), (145, 157), (146, 148), (146, 160), (147, 156), (147, 157), (148, 153), (148, 160), (148, 178), (148, 179), (149, 150), (150, 163), (150, 154), (151, 155), (151, 164), (151, 166), (151, 175), (151, 174), (152, 158), (152, 166), (152, 168), (152, 177), (153, 162), (153, 165), (153, 171), (153, 180), (153, 179), (153, 182), (153, 188), (154, 155), (154, 163), (154, 176), (154, 181), (154, 189), (155, 164), (155, 173), (155, 174), (155, 181), (156, 157), (156, 170), (156, 167), (157, 159), (157, 170), (157, 161), (157, 169), (158, 172), (158, 177), (159, 161), (160, 161), (160, 169), (160, 178), (161, 169), (162, 165), (162, 163), (163, 165), (163, 171), (163, 184), (163, 176), (163, 190), (164, 174), (165, 171), (166, 168), (166, 175), (166, 177), (166, 185), (166, 195), (166, 196), (167, 170), (167, 186), (167, 187), (167, 193), (168, 177), (169, 170), (169, 178), (170, 187), (170, 178), (170, 191), (170, 193), (170, 202), (170, 203), (171, 180), (171, 184), (172, 177), (172, 192), (172, 197), (173, 174), (173, 181), (174, 175), (174, 183), (174, 185), (174, 181), (174, 189), (174, 210), (174, 215), (174, 216), (175, 185), (176, 189), (176, 190), (176, 200), (176, 209), (176, 212), (176, 222), (177, 192), (177, 196), (178, 179), (178, 191), (178, 198), (179, 188), (179, 194), (179, 198), (180, 184), (180, 182), (180, 190), (180, 199), (180, 200), (180, 201), (181, 189), (182, 188), (182, 194), (182, 199), (183, 185), (184, 190), (185, 195), (185, 210), (186, 187), (186, 193), (187, 193), (188, 194), (188, 199), (189, 209), (189, 215), (189, 217), (190, 200), (191, 198), (191, 204), (191, 203), (191, 206), (192, 197), (192, 196), (193, 202), (193, 203), (194, 198), (194, 199), (195, 196), (195, 210), (195, 213), (195, 229), (196, 197), (196, 205), (196, 213), (197, 205), (198, 204), (198, 199), (198, 207), (199, 201), (199, 207), (199, 221), (199, 208), (200, 201), (200, 222), (200, 211), (200, 235), (200, 238), (201, 208), (201, 211), (202, 203), (202, 214), (202, 232), (203, 206), (203, 214), (204, 206), (204, 207), (204, 220), (204, 226), (205, 213), (205, 218), (205, 224), (206, 219), (206, 220), (206, 214), (206, 230), (207, 221), (207, 226), (207, 231), (208, 211), (208, 225), (208, 221), (208, 243), (208, 247), (208, 248), (209, 212), (209, 217), (209, 239), (210, 216), (210, 228), (210, 234), (210, 236), (210, 229), (211, 225), (211, 235), (212, 223), (212, 222), (212, 239), (212, 244), (212, 249), (212, 252), (213, 224), (213, 229), (214, 230), (214, 232), (215, 216), (215, 217), (216, 217), (216, 227), (216, 228), (217, 227), (217, 233), (217, 239), (217, 240), (217, 252), (218, 224), (219, 220), (219, 230), (219, 237), (220, 226), (220, 237), (220, 250), (221, 231), (221, 243), (221, 255), (222, 238), (222, 244), (222, 249), (222, 257), (224, 229), (224, 241), (224, 251), (225, 235), (225, 248), (226, 231), (226, 250), (227, 233), (227, 228), (228, 234), (228, 233), (228, 245), (229, 236), (229, 241), (229, 260), (229, 262), (230, 237), (230, 246), (230, 232), (230, 242), (230, 254), (231, 250), (231, 255), (231, 243), (232, 242), (233, 240), (233, 245), (233, 234), (233, 258), (233, 259), (233, 265), (234, 236), (234, 245), (234, 262), (234, 266), (235, 238), (235, 248), (235, 256), (236, 262), (237, 246), (237, 250), (237, 263), (238, 256), (238, 257), (239, 252), (240, 252), (240, 265), (240, 258), (241, 251), (241, 260), (242, 253), (242, 254), (243, 247), (243, 255), (243, 261), (243, 269), (243, 264), (244, 249), (245, 259), (245, 266), (246, 254), (246, 267), (246, 253), (246, 263), (247, 248), (247, 256), (247, 261), (247, 264), (248, 256), (249, 257), (249, 252), (249, 271), (250, 255), (250, 263), (250, 268), (251, 260), (251, 274), (252, 265), (252, 271), (252, 277), (253, 254), (253, 267), (253, 275), (255, 268), (255, 269), (255, 273), (256, 257), (256, 264), (256, 282), (256, 287), (257, 271), (257, 282), (257, 283), (258, 259), (258, 265), (259, 266), (259, 265), (259, 272), (259, 279), (259, 280), (259, 284), (260, 262), (260, 270), (260, 274), (260, 278), (261, 264), (262, 266), (262, 270), (262, 272), (263, 267), (263, 268), (263, 281), (264, 269), (264, 276), (264, 287), (264, 291), (264, 298), (264, 301), (265, 279), (265, 277), (265, 294), (266, 272), (267, 275), (267, 281), (267, 286), (268, 273), (268, 281), (268, 289), (269, 273), (269, 276), (270, 272), (270, 278), (270, 285), (270, 288), (271, 277), (271, 283), (272, 280), (272, 288), (273, 276), (273, 289), (273, 290), (274, 278), (274, 292), (275, 286), (275, 296), (276, 290), (276, 297), (276, 298), (276, 301), (277, 283), (277, 294), (277, 299), (277, 311), (278, 285), (278, 292), (279, 284), (279, 294), (279, 295), (279, 302), (280, 284), (280, 288), (280, 306), (281, 286), (281, 289), (281, 300), (281, 309), (282, 287), (282, 293), (282, 283), (283, 293), (283, 310), (283, 311), (284, 302), (284, 306), (285, 288), (285, 292), (285, 307), (286, 296), (286, 303), (286, 309), (287, 293), (287, 291), (287, 305), (287, 301), (288, 306), (288, 307), (288, 312), (289, 290), (289, 300), (289, 304), (290, 297), (290, 304), (291, 301), (292, 307), (292, 308), (293, 305), (293, 310), (294, 295), (294, 299), (294, 311), (294, 313), (295, 302), (296, 303), (297, 304), (297, 301), (298, 301), (299, 311), (300, 309), (300, 304), (301, 305), (302, 306), (303, 309), (306, 312), (307, 312), (307, 308), (310, 311), (311, 313)]\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs_info[0].rag.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.28571428571429, 54.11764705882353, 110.56410256410257, 63.55]\n",
      "[[2, 0], [2, 3], [1, 0], [1, 3], [3, 0]]\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0])\n",
    "print(edge_indices[0])\n",
    "print(edges[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    edges[i] = np.expand_dims(edges[i], axis=-1).astype(np.float32)\n",
    "for i in range(len(labels)):\n",
    "    nodes[i] =np.expand_dims(nodes[i],axis=-1).astype(np.int)\n",
    "    \n",
    "labels_train, labels_test, nodes_train, nodes_test, edges_train, edges_test, edge_indices_train, edge_indices_test = train_test_split(labels, nodes, edges, edge_indices,  train_size=0.8, random_state=1)\n",
    "\n",
    "nodes_train = ragged_tensor_from_nested_numpy(nodes_train)\n",
    "edges_train = ragged_tensor_from_nested_numpy(edges_train)\n",
    "edge_indices_train = ragged_tensor_from_nested_numpy(edge_indices_train)\n",
    "\n",
    "nodes_test = ragged_tensor_from_nested_numpy(nodes_test)\n",
    "edges_test = ragged_tensor_from_nested_numpy(edges_test)\n",
    "edge_indices_test = ragged_tensor_from_nested_numpy(edge_indices_test)\n",
    "\n",
    "xtrain = nodes_train, edges_train, edge_indices_train\n",
    "xtest = nodes_test, edges_test, edge_indices_test\n",
    "ytrain = np.array(labels_train)\n",
    "ytest = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:kgcnn: Unknown model kwarg normalize_by_weights with value False\n",
      "INFO:kgcnn: Updated model kwargs:\n",
      "{'depth': 3,\n",
      " 'gcn_args': {'activation': 'relu',\n",
      "              'has_unconnected': True,\n",
      "              'is_sorted': False,\n",
      "              'normalize_by_weights': False,\n",
      "              'pooling_method': 'mean',\n",
      "              'units': 64,\n",
      "              'use_bias': True},\n",
      " 'input_embedding': {'edge': {'input_dim': 10, 'output_dim': 64},\n",
      "                     'node': {'input_dim': 55, 'output_dim': 64}},\n",
      " 'inputs': [{'dtype': 'float32',\n",
      "             'name': 'node_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'float32',\n",
      "             'name': 'edge_attributes',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 1)},\n",
      "            {'dtype': 'int64',\n",
      "             'name': 'edge_indices',\n",
      "             'ragged': True,\n",
      "             'shape': (None, 2)}],\n",
      " 'name': 'Unet',\n",
      " 'output_embedding': 'graph',\n",
      " 'output_mlp': {'activation': ['relu', 'relu', 'sigmoid'],\n",
      "                'units': [140, 70, 1],\n",
      "                'use_bias': [True, True, False]},\n",
      " 'verbose': 1}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "node_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 64)     128         node_attributes[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_attributes (InputLayer)    [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_indices (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn (GCN)                       (None, None, 64)     4160        dense[0][0]                      \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gcn_1 (GCN)                     (None, None, 64)     4160        gcn[0][0]                        \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gcn_2 (GCN)                     (None, None, 64)     4160        gcn_1[0][0]                      \n",
      "                                                                 edge_attributes[0][0]            \n",
      "                                                                 edge_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pooling_nodes (PoolingNodes)    (None, 64)           0           gcn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mlp (MLP)                       (None, 1)            19040       pooling_nodes[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,648\n",
      "Trainable params: 31,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3786/3786 - 9s - loss: 0.0769 - accuracy: 0.9852\n",
      "Epoch 2/150\n",
      "3786/3786 - 9s - loss: 0.0573 - accuracy: 0.9854\n",
      "Epoch 3/150\n",
      "3786/3786 - 9s - loss: 0.0520 - accuracy: 0.9854\n",
      "Epoch 4/150\n",
      "3786/3786 - 9s - loss: 0.0504 - accuracy: 0.9859\n",
      "Epoch 5/150\n",
      "3786/3786 - 9s - loss: 0.0493 - accuracy: 0.9862\n",
      "Epoch 6/150\n",
      "3786/3786 - 10s - loss: 0.0491 - accuracy: 0.9861\n",
      "Epoch 7/150\n",
      "3786/3786 - 10s - loss: 0.0486 - accuracy: 0.9859\n",
      "Epoch 8/150\n",
      "3786/3786 - 9s - loss: 0.0485 - accuracy: 0.9860\n",
      "Epoch 9/150\n",
      "3786/3786 - 9s - loss: 0.0482 - accuracy: 0.9865\n",
      "Epoch 10/150\n",
      "3786/3786 - 11s - loss: 0.0479 - accuracy: 0.9861 - val_loss: 0.0500 - val_accuracy: 0.9865\n",
      "Epoch 11/150\n",
      "3786/3786 - 9s - loss: 0.0481 - accuracy: 0.9866\n",
      "Epoch 12/150\n",
      "3786/3786 - 9s - loss: 0.0479 - accuracy: 0.9864\n",
      "Epoch 13/150\n",
      "3786/3786 - 9s - loss: 0.0473 - accuracy: 0.9863\n",
      "Epoch 14/150\n",
      "3786/3786 - 9s - loss: 0.0476 - accuracy: 0.9865\n",
      "Epoch 15/150\n",
      "3786/3786 - 9s - loss: 0.0474 - accuracy: 0.9867\n",
      "Epoch 16/150\n",
      "3786/3786 - 9s - loss: 0.0472 - accuracy: 0.9866\n",
      "Epoch 17/150\n",
      "3786/3786 - 9s - loss: 0.0476 - accuracy: 0.9865\n",
      "Epoch 18/150\n",
      "3786/3786 - 9s - loss: 0.0473 - accuracy: 0.9865\n",
      "Epoch 19/150\n",
      "3786/3786 - 9s - loss: 0.0466 - accuracy: 0.9868\n",
      "Epoch 20/150\n",
      "3786/3786 - 11s - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.0511 - val_accuracy: 0.9868\n",
      "Epoch 21/150\n",
      "3786/3786 - 9s - loss: 0.0467 - accuracy: 0.9869\n",
      "Epoch 22/150\n",
      "3786/3786 - 9s - loss: 0.0472 - accuracy: 0.9865\n",
      "Epoch 23/150\n",
      "3786/3786 - 9s - loss: 0.0466 - accuracy: 0.9868\n",
      "Epoch 24/150\n",
      "3786/3786 - 9s - loss: 0.0464 - accuracy: 0.9866\n",
      "Epoch 25/150\n",
      "3786/3786 - 9s - loss: 0.0470 - accuracy: 0.9868\n",
      "Epoch 26/150\n",
      "3786/3786 - 9s - loss: 0.0465 - accuracy: 0.9867\n",
      "Epoch 27/150\n",
      "3786/3786 - 10s - loss: 0.0467 - accuracy: 0.9867\n",
      "Epoch 28/150\n",
      "3786/3786 - 9s - loss: 0.0461 - accuracy: 0.9867\n",
      "Epoch 29/150\n",
      "3786/3786 - 9s - loss: 0.0469 - accuracy: 0.9866\n",
      "Epoch 30/150\n",
      "3786/3786 - 10s - loss: 0.0461 - accuracy: 0.9869 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 31/150\n",
      "3786/3786 - 9s - loss: 0.0463 - accuracy: 0.9869\n",
      "Epoch 32/150\n",
      "3786/3786 - 10s - loss: 0.0460 - accuracy: 0.9867\n",
      "Epoch 33/150\n",
      "3786/3786 - 9s - loss: 0.0463 - accuracy: 0.9869\n",
      "Epoch 34/150\n",
      "3786/3786 - 10s - loss: 0.0458 - accuracy: 0.9869\n",
      "Epoch 35/150\n",
      "3786/3786 - 9s - loss: 0.0461 - accuracy: 0.9869\n",
      "Epoch 36/150\n",
      "3786/3786 - 10s - loss: 0.0484 - accuracy: 0.9863\n",
      "Epoch 37/150\n",
      "3786/3786 - 10s - loss: 0.0461 - accuracy: 0.9868\n",
      "Epoch 38/150\n",
      "3786/3786 - 9s - loss: 0.0462 - accuracy: 0.9868\n",
      "Epoch 39/150\n",
      "3786/3786 - 9s - loss: 0.0458 - accuracy: 0.9867\n",
      "Epoch 40/150\n",
      "3786/3786 - 10s - loss: 0.0464 - accuracy: 0.9868 - val_loss: 0.0542 - val_accuracy: 0.9861\n",
      "Epoch 41/150\n",
      "3786/3786 - 9s - loss: 0.0458 - accuracy: 0.9869\n",
      "Epoch 42/150\n",
      "3786/3786 - 9s - loss: 0.0461 - accuracy: 0.9867\n",
      "Epoch 43/150\n",
      "3786/3786 - 9s - loss: 0.0463 - accuracy: 0.9869\n",
      "Epoch 44/150\n",
      "3786/3786 - 10s - loss: 0.0458 - accuracy: 0.9869\n",
      "Epoch 45/150\n",
      "3786/3786 - 9s - loss: 0.0459 - accuracy: 0.9867\n",
      "Epoch 46/150\n",
      "3786/3786 - 10s - loss: 0.0459 - accuracy: 0.9867\n",
      "Epoch 47/150\n",
      "3786/3786 - 10s - loss: 0.0469 - accuracy: 0.9871\n",
      "Epoch 48/150\n",
      "3786/3786 - 9s - loss: 0.0459 - accuracy: 0.9869\n",
      "Epoch 49/150\n",
      "3786/3786 - 9s - loss: 0.0457 - accuracy: 0.9870\n",
      "Epoch 50/150\n",
      "3786/3786 - 11s - loss: 0.0458 - accuracy: 0.9869 - val_loss: 0.0415 - val_accuracy: 0.9884\n",
      "Epoch 51/150\n",
      "3786/3786 - 9s - loss: 0.0457 - accuracy: 0.9868\n",
      "Epoch 52/150\n",
      "3786/3786 - 9s - loss: 0.0457 - accuracy: 0.9868\n",
      "Epoch 53/150\n",
      "3786/3786 - 9s - loss: 0.0466 - accuracy: 0.9867\n",
      "Epoch 54/150\n",
      "3786/3786 - 10s - loss: 0.0455 - accuracy: 0.9870\n",
      "Epoch 55/150\n",
      "3786/3786 - 9s - loss: 0.0457 - accuracy: 0.9868\n",
      "Epoch 56/150\n",
      "3786/3786 - 10s - loss: 0.0455 - accuracy: 0.9869\n",
      "Epoch 57/150\n",
      "3786/3786 - 9s - loss: 0.0475 - accuracy: 0.9866\n",
      "Epoch 58/150\n",
      "3786/3786 - 9s - loss: 0.0489 - accuracy: 0.9854\n",
      "Epoch 59/150\n",
      "3786/3786 - 9s - loss: 0.0465 - accuracy: 0.9859\n",
      "Epoch 60/150\n",
      "3786/3786 - 11s - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9884\n",
      "Epoch 61/150\n",
      "3786/3786 - 10s - loss: 0.0463 - accuracy: 0.9868\n",
      "Epoch 62/150\n",
      "3786/3786 - 11s - loss: 0.0457 - accuracy: 0.9869\n",
      "Epoch 63/150\n",
      "3786/3786 - 9s - loss: 0.0454 - accuracy: 0.9867\n",
      "Epoch 64/150\n",
      "3786/3786 - 9s - loss: 0.0455 - accuracy: 0.9869\n",
      "Epoch 65/150\n",
      "3786/3786 - 10s - loss: 0.0454 - accuracy: 0.9872\n",
      "Epoch 66/150\n",
      "3786/3786 - 9s - loss: 0.0456 - accuracy: 0.9870\n",
      "Epoch 67/150\n",
      "3786/3786 - 9s - loss: 0.0455 - accuracy: 0.9871\n",
      "Epoch 68/150\n",
      "3786/3786 - 9s - loss: 0.0456 - accuracy: 0.9869\n",
      "Epoch 69/150\n",
      "3786/3786 - 9s - loss: 0.0460 - accuracy: 0.9868\n",
      "Epoch 70/150\n",
      "3786/3786 - 10s - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.0429 - val_accuracy: 0.9884\n",
      "Epoch 71/150\n",
      "3786/3786 - 9s - loss: 0.0453 - accuracy: 0.9870\n",
      "Epoch 72/150\n",
      "3786/3786 - 9s - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 73/150\n",
      "3786/3786 - 9s - loss: 0.0451 - accuracy: 0.9871\n",
      "Epoch 74/150\n",
      "3786/3786 - 9s - loss: 0.0452 - accuracy: 0.9871\n",
      "Epoch 75/150\n",
      "3786/3786 - 9s - loss: 0.0452 - accuracy: 0.9872\n",
      "Epoch 76/150\n",
      "3786/3786 - 9s - loss: 0.0450 - accuracy: 0.9871\n",
      "Epoch 77/150\n",
      "3786/3786 - 9s - loss: 0.0454 - accuracy: 0.9871\n",
      "Epoch 78/150\n",
      "3786/3786 - 11s - loss: 0.0449 - accuracy: 0.9871\n",
      "Epoch 79/150\n",
      "3786/3786 - 9s - loss: 0.0457 - accuracy: 0.9869\n",
      "Epoch 80/150\n",
      "3786/3786 - 11s - loss: 0.0450 - accuracy: 0.9871 - val_loss: 0.0417 - val_accuracy: 0.9884\n",
      "Epoch 81/150\n",
      "3786/3786 - 10s - loss: 0.0460 - accuracy: 0.9871\n",
      "Epoch 82/150\n",
      "3786/3786 - 10s - loss: 0.0457 - accuracy: 0.9870\n",
      "Epoch 83/150\n",
      "3786/3786 - 9s - loss: 0.0452 - accuracy: 0.9870\n",
      "Epoch 84/150\n",
      "3786/3786 - 9s - loss: 0.0448 - accuracy: 0.9870\n",
      "Epoch 85/150\n",
      "3786/3786 - 10s - loss: 0.0454 - accuracy: 0.9870\n",
      "Epoch 86/150\n",
      "3786/3786 - 9s - loss: 0.0452 - accuracy: 0.9867\n",
      "Epoch 87/150\n",
      "3786/3786 - 10s - loss: 0.0456 - accuracy: 0.9872\n",
      "Epoch 88/150\n",
      "3786/3786 - 9s - loss: 0.0450 - accuracy: 0.9871\n",
      "Epoch 89/150\n",
      "3786/3786 - 9s - loss: 0.0450 - accuracy: 0.9871\n",
      "Epoch 90/150\n",
      "3786/3786 - 10s - loss: 0.0472 - accuracy: 0.9871 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
      "Epoch 91/150\n",
      "3786/3786 - 9s - loss: 0.0459 - accuracy: 0.9869\n",
      "Epoch 92/150\n",
      "3786/3786 - 10s - loss: 0.0456 - accuracy: 0.9870\n",
      "Epoch 93/150\n",
      "3786/3786 - 9s - loss: 0.0450 - accuracy: 0.9872\n",
      "Epoch 94/150\n",
      "3786/3786 - 9s - loss: 0.0451 - accuracy: 0.9871\n",
      "Epoch 95/150\n",
      "3786/3786 - 9s - loss: 0.0449 - accuracy: 0.9870\n",
      "Epoch 96/150\n",
      "3786/3786 - 9s - loss: 0.0451 - accuracy: 0.9870\n",
      "Epoch 97/150\n",
      "3786/3786 - 9s - loss: 0.0451 - accuracy: 0.9872\n",
      "Epoch 98/150\n",
      "3786/3786 - 9s - loss: 0.0449 - accuracy: 0.9872\n",
      "Epoch 99/150\n",
      "3786/3786 - 10s - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 100/150\n",
      "3786/3786 - 10s - loss: 0.0449 - accuracy: 0.9870 - val_loss: 0.0412 - val_accuracy: 0.9885\n",
      "Epoch 101/150\n",
      "3786/3786 - 9s - loss: 0.0446 - accuracy: 0.9874\n",
      "Epoch 102/150\n",
      "3786/3786 - 9s - loss: 0.0449 - accuracy: 0.9871\n",
      "Epoch 103/150\n",
      "3786/3786 - 9s - loss: 0.0465 - accuracy: 0.9872\n",
      "Epoch 104/150\n",
      "3786/3786 - 9s - loss: 0.0444 - accuracy: 0.9871\n",
      "Epoch 105/150\n",
      "3786/3786 - 9s - loss: 0.0447 - accuracy: 0.9872\n",
      "Epoch 106/150\n",
      "3786/3786 - 9s - loss: 0.0447 - accuracy: 0.9872\n",
      "Epoch 107/150\n",
      "3786/3786 - 9s - loss: 0.0441 - accuracy: 0.9874\n",
      "Epoch 108/150\n",
      "3786/3786 - 10s - loss: 0.0450 - accuracy: 0.9871\n",
      "Epoch 109/150\n",
      "3786/3786 - 9s - loss: 0.0484 - accuracy: 0.9873\n",
      "Epoch 110/150\n",
      "3786/3786 - 11s - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 111/150\n",
      "3786/3786 - 10s - loss: 0.0452 - accuracy: 0.9873\n",
      "Epoch 112/150\n",
      "3786/3786 - 9s - loss: 0.0443 - accuracy: 0.9874\n",
      "Epoch 113/150\n",
      "3786/3786 - 9s - loss: 0.0452 - accuracy: 0.9873\n",
      "Epoch 114/150\n",
      "3786/3786 - 9s - loss: 0.0450 - accuracy: 0.9873\n",
      "Epoch 115/150\n",
      "3786/3786 - 9s - loss: 0.0438 - accuracy: 0.9874\n",
      "Epoch 116/150\n",
      "3786/3786 - 9s - loss: 0.0438 - accuracy: 0.9871\n",
      "Epoch 117/150\n",
      "3786/3786 - 9s - loss: 0.0440 - accuracy: 0.9875\n",
      "Epoch 118/150\n",
      "3786/3786 - 9s - loss: 0.0438 - accuracy: 0.9873\n",
      "Epoch 119/150\n",
      "3786/3786 - 10s - loss: 0.0437 - accuracy: 0.9875\n",
      "Epoch 120/150\n",
      "3786/3786 - 12s - loss: 0.0438 - accuracy: 0.9874 - val_loss: 0.0412 - val_accuracy: 0.9886\n",
      "Epoch 121/150\n",
      "3786/3786 - 10s - loss: 0.0440 - accuracy: 0.9875\n",
      "Epoch 122/150\n",
      "3786/3786 - 9s - loss: 0.0435 - accuracy: 0.9876\n",
      "Epoch 123/150\n",
      "3786/3786 - 10s - loss: 0.0441 - accuracy: 0.9874\n",
      "Epoch 124/150\n",
      "3786/3786 - 9s - loss: 0.0439 - accuracy: 0.9874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "3786/3786 - 9s - loss: 0.0435 - accuracy: 0.9875\n",
      "Epoch 126/150\n",
      "3786/3786 - 9s - loss: 0.0462 - accuracy: 0.9875\n",
      "Epoch 127/150\n",
      "3786/3786 - 9s - loss: 0.0431 - accuracy: 0.9875\n",
      "Epoch 128/150\n",
      "3786/3786 - 10s - loss: 0.0431 - accuracy: 0.9874\n",
      "Epoch 129/150\n",
      "3786/3786 - 10s - loss: 0.0433 - accuracy: 0.9875\n",
      "Epoch 130/150\n",
      "3786/3786 - 10s - loss: 0.0433 - accuracy: 0.9876 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 131/150\n",
      "3786/3786 - 10s - loss: 0.0443 - accuracy: 0.9874\n",
      "Epoch 132/150\n",
      "3786/3786 - 10s - loss: 0.0429 - accuracy: 0.9876\n",
      "Epoch 133/150\n",
      "3786/3786 - 9s - loss: 0.0429 - accuracy: 0.9874\n",
      "Epoch 134/150\n",
      "3786/3786 - 10s - loss: 0.0431 - accuracy: 0.9875\n",
      "Epoch 135/150\n",
      "3786/3786 - 9s - loss: 0.0429 - accuracy: 0.9875\n",
      "Epoch 136/150\n",
      "3786/3786 - 9s - loss: 0.0429 - accuracy: 0.9876\n",
      "Epoch 137/150\n",
      "3786/3786 - 9s - loss: 0.0428 - accuracy: 0.9878\n",
      "Epoch 138/150\n",
      "3786/3786 - 9s - loss: 0.0426 - accuracy: 0.9876\n",
      "Epoch 139/150\n",
      "3786/3786 - 10s - loss: 0.0428 - accuracy: 0.9876\n",
      "Epoch 140/150\n",
      "3786/3786 - 11s - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 141/150\n",
      "3786/3786 - 9s - loss: 0.0429 - accuracy: 0.9876\n",
      "Epoch 142/150\n",
      "3786/3786 - 9s - loss: 0.0424 - accuracy: 0.9876\n",
      "Epoch 143/150\n",
      "3786/3786 - 9s - loss: 0.0428 - accuracy: 0.9877\n",
      "Epoch 144/150\n",
      "3786/3786 - 9s - loss: 0.0423 - accuracy: 0.9878\n",
      "Epoch 145/150\n",
      "3786/3786 - 9s - loss: 0.0422 - accuracy: 0.9876\n",
      "Epoch 146/150\n",
      "3786/3786 - 10s - loss: 0.0420 - accuracy: 0.9877\n",
      "Epoch 147/150\n",
      "3786/3786 - 9s - loss: 0.0425 - accuracy: 0.9878\n",
      "Epoch 148/150\n",
      "3786/3786 - 9s - loss: 0.0420 - accuracy: 0.9878\n",
      "Epoch 149/150\n",
      "3786/3786 - 9s - loss: 0.0419 - accuracy: 0.9878\n",
      "Epoch 150/150\n",
      "3786/3786 - 10s - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.0408 - val_accuracy: 0.9885\n",
      "Print Time for taining:  3442.868256972\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_model(\n",
    "    name = \"Unet\",\n",
    "    inputs = [{'shape': (None, 1), 'name': \"node_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "            {'shape': (None, 1), 'name': \"edge_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "            {'shape': (None, 2), 'name': \"edge_indices\", 'dtype': 'int64', 'ragged': True}],\n",
    "    input_embedding = {\"node\": {\"input_dim\": 55, \"output_dim\": 64},\n",
    "                       \"edge\": {\"input_dim\": 10, \"output_dim\": 64}},\n",
    "\n",
    "    output_embedding =  'graph',\n",
    "    output_mlp = {\"use_bias\": [True, True, False], \"units\": [140, 70, 1],\n",
    "                \"activation\": ['relu', 'relu', 'sigmoid']},\n",
    "    gcn_args = {\"units\": 64, \"use_bias\": True, \"activation\": 'relu', \"pooling_method\": 'mean', \n",
    "                \"normalize_by_weights\": False},\n",
    ")\n",
    "\n",
    "# Set learning rate and epochs\n",
    "learning_rate_start = 1e-3\n",
    "learning_rate_stop = 1e-4\n",
    "epo = 150\n",
    "epomin = 100\n",
    "epostep = 10\n",
    "\n",
    "# Compile model with optimizer and loss\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate_start)\n",
    "cbks = LinearLearningRateScheduler(learning_rate_start, learning_rate_stop, epomin, epo)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              weighted_metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Start and time training\n",
    "start = time.process_time()\n",
    "hist = model.fit(xtrain, ytrain,\n",
    "                 epochs=epo,\n",
    "                 batch_size=32,\n",
    "                 callbacks=[cbks],\n",
    "                 validation_freq=epostep,\n",
    "                 validation_data=(xtest, ytest),\n",
    "                 verbose=2\n",
    "                 )\n",
    "stop = time.process_time()\n",
    "print(\"Print Time for taining: \", stop - start)\n",
    "\n",
    "# Get loss from history\n",
    "trainlossall = np.array(hist.history['accuracy'])\n",
    "testlossall = np.array(hist.history['val_accuracy'])\n",
    "acc_valid = testlossall[-1]\n",
    "\n",
    "# Plot loss vs epochs\n",
    "plt.figure()\n",
    "plt.plot(np.arange(trainlossall.shape[0]), trainlossall, label='Training ACC', c='blue')\n",
    "plt.plot(np.arange(epostep, epo + epostep, epostep), testlossall, label='Test ACC', c='red')\n",
    "plt.scatter([trainlossall.shape[0]], [acc_valid], label=\"{0:0.4f} \".format(acc_valid), c='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Interaction Network Loss')\n",
    "plt.legend(loc='upper right', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.        0.9963907]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.83159018]\n",
      "[0.         1.         0.24255177]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.26900783]\n",
      "[0.         1.         0.24052164]\n",
      "[0.         1.         0.21462703]\n",
      "[1.         1.         0.55463922]\n",
      "[0.         1.         0.01093712]\n",
      "[1.         1.         0.69056833]\n",
      "[1.         1.         0.54109925]\n",
      "[1.        1.        0.6750797]\n",
      "[0.         1.         0.14153728]\n",
      "[0.         1.         0.36008441]\n",
      "[0.        1.        0.0544869]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.09656662]\n",
      "[0.         1.         0.01428521]\n",
      "[0.         1.         0.03504592]\n",
      "[0.         1.         0.00657487]\n",
      "[0.         1.         0.10983694]\n",
      "[1.         1.         0.67166758]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.38723648]\n",
      "[0.         1.         0.11512536]\n",
      "[0.         1.         0.26742119]\n",
      "[1.         1.         0.67405063]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.24890372]\n",
      "[1.         1.         0.77467239]\n",
      "[0.         1.         0.04853025]\n",
      "[1.        1.        0.8838886]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.53078467]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.58276284]\n",
      "[0.         1.         0.17587739]\n",
      "[0.         1.         0.23240289]\n",
      "[0.         1.         0.00226772]\n",
      "[0.         1.         0.38219947]\n",
      "[1.         1.         0.61229616]\n",
      "[1.         1.         0.80691898]\n",
      "[0.         1.         0.32968402]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.15107429]\n",
      "[0.         1.         0.03946087]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.81855583]\n",
      "[0.         1.         0.32776958]\n",
      "[0.         1.         0.03103948]\n",
      "[0.         1.         0.27149841]\n",
      "[1.         1.         0.83682716]\n",
      "[1.         1.         0.61827743]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.13523734]\n",
      "[0.         1.         0.03946087]\n",
      "[0.         1.         0.00546762]\n",
      "[0.         1.         0.10302848]\n",
      "[0.         1.         0.03103951]\n",
      "[1.       1.       0.821877]\n",
      "[0.         1.         0.05044693]\n",
      "[0.         1.         0.41725963]\n",
      "[0.         1.         0.49522781]\n",
      "[0.         1.         0.36094522]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.03203329]\n",
      "[0.         1.         0.06666183]\n",
      "[0.         1.         0.00496069]\n",
      "[0.         1.         0.01073423]\n",
      "[1.         1.         0.69678187]\n",
      "[0.         1.         0.08825856]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.19245416]\n",
      "[0.         1.         0.36463058]\n",
      "[1.        1.        0.9511441]\n",
      "[0.         1.         0.01249146]\n",
      "[1.         1.         0.57276821]\n",
      "[0.        1.        0.2441608]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.99915516]\n",
      "[1.         1.         0.86992598]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.01050439]\n",
      "[1.         1.         0.67809761]\n",
      "[0.         1.         0.04702747]\n",
      "[0.         1.         0.23821938]\n",
      "[1.         1.         0.73031509]\n",
      "[0.         1.         0.23850122]\n",
      "[0.         1.         0.08972603]\n",
      "[1.         1.         0.62263763]\n",
      "[1.         1.         0.68290555]\n",
      "[0.        1.        0.0300405]\n",
      "[0.         1.         0.00366864]\n",
      "[0.         1.         0.27442956]\n",
      "[1.         1.         0.89894676]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.78170174]\n",
      "[0.         1.         0.22073019]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.45181385]\n",
      "[1.         1.         0.74054503]\n",
      "[1.         1.         0.79096615]\n",
      "[0.         1.         0.11945096]\n",
      "[0.         1.         0.00856745]\n",
      "[0.         1.         0.14664468]\n",
      "[0.         1.         0.44755816]\n",
      "[0.         1.         0.18909702]\n",
      "[1.         1.         0.86763388]\n",
      "[0.         1.         0.00790784]\n",
      "[0.         1.         0.00315186]\n",
      "[1.         1.         0.76265299]\n",
      "[0.         1.         0.04393125]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.10983694]\n",
      "[1.         1.         0.77365351]\n",
      "[0.         1.         0.03504592]\n",
      "[0.         1.         0.03550622]\n",
      "[0.         1.         0.16548443]\n",
      "[1.         1.         0.89013898]\n",
      "[0.         1.         0.00101864]\n",
      "[1.         1.         0.76103306]\n",
      "[0.         1.         0.13773784]\n",
      "[0.         1.         0.14560086]\n",
      "[0.         1.         0.01775584]\n",
      "[0.         1.         0.42423508]\n",
      "[0.         1.         0.40929246]\n",
      "[1.         1.         0.99618649]\n",
      "[0.         1.         0.40377086]\n",
      "[1.         1.         0.76984286]\n",
      "[1.         1.         0.83159018]\n",
      "[0.         1.         0.00357321]\n",
      "[0.         1.         0.10983694]\n",
      "[1.         1.         0.70022076]\n",
      "[1.         1.         0.75735742]\n",
      "[0.         1.         0.03353027]\n",
      "[0.         1.         0.00703076]\n",
      "[0.         1.         0.01577935]\n",
      "[0.         1.         0.31645638]\n",
      "[0.         1.         0.38246483]\n",
      "[0.         1.         0.05312464]\n",
      "[1.         1.         0.52660257]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.01481512]\n",
      "[0.         1.         0.01439086]\n",
      "[0.         1.         0.03515348]\n",
      "[1.         1.         0.75198245]\n",
      "[0.         1.         0.10983694]\n",
      "[0.        1.        0.0394609]\n",
      "[0.         1.         0.05254522]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.00355408]\n",
      "[0.         1.         0.00769216]\n",
      "[0.        1.        0.0009498]\n",
      "[0.         1.         0.18561566]\n",
      "[0.         1.         0.03356838]\n",
      "[0.         1.         0.05719623]\n",
      "[0.         1.         0.03551286]\n",
      "[0.         1.         0.00536099]\n",
      "[0.         1.         0.04529765]\n",
      "[0.         1.         0.09432012]\n",
      "[1.        1.        0.8239305]\n",
      "[0.         1.         0.21506301]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.00457278]\n",
      "[0.         1.         0.03054813]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.25430477]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.16740733]\n",
      "[0.         1.         0.03234395]\n",
      "[1.         1.         0.73384511]\n",
      "[1.        1.        0.5933848]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.74588305]\n",
      "[0.         1.         0.25136155]\n",
      "[1.         1.         0.81389928]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.79931086]\n",
      "[0.         1.         0.23803306]\n",
      "[0.         1.         0.24979547]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.01375437]\n",
      "[0.         1.         0.03670707]\n",
      "[1.         1.         0.68912512]\n",
      "[0.         1.         0.03504592]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.03103948]\n",
      "[0.         1.         0.01008818]\n",
      "[0.         1.         0.22534087]\n",
      "[0.         1.         0.45947558]\n",
      "[0.         1.         0.47442871]\n",
      "[0.         1.         0.01974794]\n",
      "[0.         1.         0.00347355]\n",
      "[0.         1.         0.02843297]\n",
      "[0.         1.         0.03985608]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.35127684]\n",
      "[0.         1.         0.18455347]\n",
      "[1.         1.         0.75072944]\n",
      "[1.         1.         0.70607221]\n",
      "[0.        1.        0.0016394]\n",
      "[1.         1.         0.87837553]\n",
      "[0.         1.         0.03099477]\n",
      "[0.         1.         0.00979322]\n",
      "[1.         1.         0.65180612]\n",
      "[1.         1.         0.67046171]\n",
      "[0.         1.         0.11297399]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.88450605]\n",
      "[0.         1.         0.18660036]\n",
      "[1.         1.         0.79784608]\n",
      "[0.         1.         0.00345117]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.30403763]\n",
      "[1.         1.         0.66146106]\n",
      "[1.        1.        0.6650691]\n",
      "[1.         1.         0.77488053]\n",
      "[0.         1.         0.49267927]\n",
      "[0.         1.         0.22073019]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.03909025]\n",
      "[1.         1.         0.99979377]\n",
      "[0.         1.         0.00921816]\n",
      "[0.         1.         0.24866158]\n",
      "[0.         1.         0.01589772]\n",
      "[1.         1.         0.90426409]\n",
      "[1.         1.         0.66023862]\n",
      "[1.         1.         0.84251225]\n",
      "[0.         1.         0.20501024]\n",
      "[0.         1.         0.18558955]\n",
      "[0.        1.        0.0746575]\n",
      "[1.         1.         0.73232293]\n",
      "[0.         1.         0.00164545]\n",
      "[0.         1.         0.47241682]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.02479362]\n",
      "[0.         1.         0.08148175]\n",
      "[1.         1.         0.70179576]\n",
      "[1.         1.         0.51562786]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.90426415]\n",
      "[0.         1.         0.02397817]\n",
      "[1.         1.         0.64281827]\n",
      "[1.         1.         0.77365351]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.15658671]\n",
      "[1.         1.         0.64756268]\n",
      "[0.         1.         0.17739865]\n",
      "[1.         1.         0.99999535]\n",
      "[0.         1.         0.35904515]\n",
      "[0.        1.        0.0207611]\n",
      "[0.         1.         0.37772265]\n",
      "[0.         1.         0.18823916]\n",
      "[0.         1.         0.24877575]\n",
      "[0.         1.         0.16475719]\n",
      "[0.         1.         0.00781623]\n",
      "[0.         1.         0.01906326]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.66836101]\n",
      "[0.         1.         0.00622979]\n",
      "[1.         1.         0.89511806]\n",
      "[1.         1.         0.69777393]\n",
      "[0.         1.         0.01079431]\n",
      "[0.         1.         0.14082664]\n",
      "[0.         1.         0.02493522]\n",
      "[0.         1.         0.35520136]\n",
      "[0.        1.        0.2277807]\n",
      "[0.         1.         0.10983694]\n",
      "[1.         1.         0.61538309]\n",
      "[0.         1.         0.22695908]\n",
      "[0.         1.         0.02767989]\n",
      "[0.         1.         0.40558147]\n",
      "[0.         1.         0.00261897]\n",
      "[1.         1.         0.99972725]\n",
      "[0.         1.         0.07266814]\n",
      "[0.         1.         0.11736208]\n",
      "[0.         1.         0.12278336]\n",
      "[0.         1.         0.01870412]\n",
      "[1.         1.         0.99344981]\n",
      "[1.         1.         0.92260838]\n",
      "[0.         1.         0.08895522]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.22139955]\n",
      "[1.         1.         0.66041774]\n",
      "[1.         1.         0.57514077]\n",
      "[0.         1.         0.03946087]\n",
      "[0.         1.         0.05363321]\n",
      "[0.         1.         0.14770728]\n",
      "[0.         1.         0.26742119]\n",
      "[1.         1.         0.70665014]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.99963671]\n",
      "[1.         1.         0.59893346]\n",
      "[0.         1.         0.00052291]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.20854855]\n",
      "[0.         1.         0.01772466]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.21505448]\n",
      "[1.        1.        0.6467489]\n",
      "[0.         1.         0.04779169]\n",
      "[0.         1.         0.25779992]\n",
      "[0.         1.         0.00423062]\n",
      "[0.         1.         0.29974389]\n",
      "[0.         1.         0.33695048]\n",
      "[0.         1.         0.18537685]\n",
      "[1.         1.         0.60512853]\n",
      "[0.        1.        0.2823135]\n",
      "[0.         1.         0.00211948]\n",
      "[0.         1.         0.12547892]\n",
      "[0.         1.         0.34589595]\n",
      "[0.         1.         0.26742119]\n",
      "[0.         1.         0.17987221]\n",
      "[1.         1.         0.99989629]\n",
      "[0.         1.         0.01132175]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.04783842]\n",
      "[0.         1.         0.00160846]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.27118248]\n",
      "[1.         1.         0.94367301]\n",
      "[0.         1.         0.00001008]\n",
      "[1.         1.         0.95993626]\n",
      "[0.         1.         0.27726734]\n",
      "[0.        1.        0.0485712]\n",
      "[0.         1.         0.00967482]\n",
      "[0.         1.         0.00184196]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.00524569]\n",
      "[0.         1.         0.04529765]\n",
      "[0.         1.         0.07539707]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.88279414]\n",
      "[1.        1.        0.5352338]\n",
      "[1.         1.         0.57998091]\n",
      "[0.         1.         0.46420655]\n",
      "[0.         1.         0.12577677]\n",
      "[0.         1.         0.01692808]\n",
      "[0.         1.         0.02069464]\n",
      "[0.         1.         0.04700068]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.58596289]\n",
      "[1.         1.         0.61834002]\n",
      "[1.         1.         0.63769639]\n",
      "[1.         1.         0.85298419]\n",
      "[1.         1.         0.99999744]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.17979097]\n",
      "[0.         1.         0.24824736]\n",
      "[1.         1.         0.57068938]\n",
      "[0.         1.         0.27746555]\n",
      "[0.         1.         0.28533748]\n",
      "[0.         1.         0.38888457]\n",
      "[1.       1.       0.828987]\n",
      "[1.         1.         0.92858136]\n",
      "[0.         1.         0.04529765]\n",
      "[0.        1.        0.0524841]\n",
      "[0.         1.         0.13572639]\n",
      "[1.         1.         0.51759386]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.74802941]\n",
      "[0.         1.         0.24979541]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.69376725]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.14511606]\n",
      "[0.        1.        0.0207324]\n",
      "[0.         1.         0.05482858]\n",
      "[1.         1.         0.74034917]\n",
      "[1.        1.        0.9696452]\n",
      "[1.         1.         0.76092958]\n",
      "[0.         1.         0.26742119]\n",
      "[0.         1.         0.08233321]\n",
      "[1.         1.         0.59326059]\n",
      "[1.         1.         0.99988765]\n",
      "[0.         1.         0.00397053]\n",
      "[1.         1.         0.94753563]\n",
      "[1.         1.         0.65392905]\n",
      "[0.         1.         0.03946087]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.93061173]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.45595422]\n",
      "[0.         1.         0.03103951]\n",
      "[0.         1.         0.20308903]\n",
      "[1.         1.         0.68394244]\n",
      "[0.         1.         0.00252903]\n",
      "[0.         1.         0.04229268]\n",
      "[1.         1.         0.71898472]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.00081116]\n",
      "[1.         1.         0.69935608]\n",
      "[1.         1.         0.88614273]\n",
      "[0.         1.         0.10983694]\n",
      "[0.         1.         0.00914368]\n",
      "[1.        1.        0.6543026]\n",
      "[1.         1.         0.70022076]\n",
      "[1.         1.         0.58276284]\n",
      "[1.         1.         0.98431587]\n",
      "[0.         1.         0.04873857]\n",
      "[0.         1.         0.32968402]\n",
      "[1.         1.         0.93188453]\n",
      "[0.        1.        0.0032196]\n",
      "[0.         1.         0.03103951]\n",
      "[1.         1.         0.62727785]\n",
      "[0.         1.         0.16740733]\n",
      "[0.         1.         0.28308785]\n",
      "[1.         1.         0.85647064]\n",
      "[0.         1.         0.30336833]\n",
      "122/416\n",
      "294/416\n"
     ]
    }
   ],
   "source": [
    "probability = model.predict(xtest)\n",
    "predictions = np.round(probability)\n",
    "comparison = np.concatenate((predictions, ytest, probability), axis=1)\n",
    "# print(comparison)\n",
    "\n",
    "hole = 0\n",
    "true = 0\n",
    "false = 0\n",
    "for value in comparison:\n",
    "    if value[1] == 1.:\n",
    "        hole += 1\n",
    "        print(value)\n",
    "        if value[0] == 0.:\n",
    "            false +=1\n",
    "        else:\n",
    "            true +=1\n",
    "print(f\"{true}/{hole}\")\n",
    "print(f\"{false}/{hole}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object('saved_objects/rags', rags)\n",
    "save_object('saved_objects/neighbor_graphs', neighbor_graphs)\n",
    "save_object('saved_objects/labels', labels)\n",
    "save_object('saved_objects/nodes', nodes)\n",
    "save_object('saved_objects/edges', edges)\n",
    "save_object('saved_objects/edge_indices', edge_indices)\n",
    "model.save('/home/daniel/Praca inÅ¼ynierska/DetectingInflammationsInImagesOfSacroiliacJoint/saved_objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rags = load_object('saved_objects/rags')\n",
    "neighbor_graphs = load_object('saved_objects/neighbor_graphs')\n",
    "nodes = load_object('saved_objects/nodes')\n",
    "edges = load_object('saved_objects/edges')\n",
    "edge_indices = load_object('saved_objects/edge_indices')\n",
    "labels = load_object('saved_objects/labels')\n",
    "model = keras.models.load_model('/home/daniel/Praca inÅ¼ynierska/DetectingInflammationsInImagesOfSacroiliacJoint/saved_objects')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
