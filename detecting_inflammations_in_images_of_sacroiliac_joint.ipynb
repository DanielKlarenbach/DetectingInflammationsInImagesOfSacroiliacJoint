{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsage:\\n1. Directory with data sets must be placed in directory named \"input\"\\n2. Input directory must be in the same directory as the .ipynb file with this sript\\n3. Inside each data set directory there must be three directories named: images, labels and masks.\\n4. Filenames of labels and masks files must be the same as image filename.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Usage:\n",
    "1. Directory with data sets must be placed in directory named \"input\"\n",
    "2. Input directory must be in the same directory as the .ipynb file with this sript\n",
    "3. Inside each data set directory there must be three directories named: images, labels and masks.\n",
    "4. Filenames of labels and masks files must be the same as image filename.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.future.graph as skigraph\n",
    "import shutil\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from kgcnn.literature.GCN import make_model\n",
    "from kgcnn.utils.data import ragged_tensor_from_nested_numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from kgcnn.utils.learning import LinearLearningRateScheduler\n",
    "from PIL import Image, ImageOps\n",
    "import radiomics\n",
    "import numpy.ma as ma\n",
    "import nrrd\n",
    "import warnings\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script parameterss\n",
    "DATA_SET_DIR_NAME = \"data_set_2\"\n",
    "PYRADIOMICS_FEATURES = [\n",
    "    \"original_firstorder_Mean\",\n",
    "    \"original_firstorder_Variance\",\n",
    "    \"original_glcm_ClusterTendency\",\n",
    "    \"original_glcm_Correlation\",\n",
    "    \"original_ngtdm_Contrast\",\n",
    "    \"original_glrlm_RunEntropy\",\n",
    "    \"original_gldm_DependenceEntropy\",\n",
    "    \"original_gldm_SmallDependenceEmphasis\",\n",
    "    \"original_glrlm_GrayLevelNonUniformity\",\n",
    "    \"original_ngtdm_Busyness\",\n",
    "    \"original_glszm_ZoneEntropy\",\n",
    "    \"original_glszm_SizeZoneNonUniformity\"\n",
    "]\n",
    "\n",
    "# globals\n",
    "DATA_DIR_PATH = f\"./input/{DATA_SET_DIR_NAME}\"\n",
    "IMAGES_DIR_PATH = f\"{DATA_DIR_PATH}/images\"\n",
    "SUPERPIXELS_LABELS_DIR_PATH = f\"{DATA_DIR_PATH}/superpixels_labels\"\n",
    "MASKS_DIR_PATH = f\"{DATA_DIR_PATH}/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_segmented_images_from_predictions:\\n    predicted_images = {}\\n\\n    for (i, subgraph) in enumerate(subgraphs_test):\\n        if subgraph.rag.file_id not in predicted_images:\\n            predicted_images[subgraph.rag.file_id] = np.copy(subgraph.rag.superpixels_labels)\\n        predicted_images[subgraph.rag.file_id][ predicted_images[subgraph.rag.file_id] == subgraph.superpixel_label] = predictions[i] - 2\\n\\n    for key in predicted_images.keys():\\n        predicted_images[key][predicted_images[key] == -1] = 1\\n        predicted_images[key][predicted_images[key] == -2] = 0\\n        predicted_images[key]=predicted_images[key]*255\\n        im = Image.fromarray(predicted_images[key].astype(np.uint8))\\n        im.save(f\"predictions/{key}.png\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utils\n",
    "def save_object(filename, obj):\n",
    "    obj_file = open(filename, \"wb\")\n",
    "    pickle.dump(obj, obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "def load_object(filename):\n",
    "    obj_file = open(filename, \"rb\")\n",
    "    obj = pickle.load(obj_file)\n",
    "    obj_file.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, file_id, rag, image, superpixels_labels, mask):\n",
    "        self.file_id = file_id\n",
    "        self.rag = rag\n",
    "        self.image = image\n",
    "        self.superpixels_labels = superpixels_labels\n",
    "        self.mask = mask\n",
    "\n",
    "class Subgraph:\n",
    "    def __init__(self, rag, graph, middle_superpixel_label, label):\n",
    "        self.rag = rag\n",
    "        self.graph = graph\n",
    "        self.middle_superpixel_label = middle_superpixel_label\n",
    "        self.label = label\n",
    "        self.unnormalized_edge_indices = None\n",
    "        self.normalized_edge_indices = None\n",
    "        self.edges = None\n",
    "        self.nodes = None\n",
    "        \n",
    "def assign_labels(graph):\n",
    "    white_pixels_count = defaultdict(int)\n",
    "    total_pixels_count = defaultdict(int)\n",
    "    \n",
    "    for (i, row) in enumerate(graph.superpixels_labels):\n",
    "        for (j, superpixel_label) in enumerate(row):\n",
    "            total_pixels_count[superpixel_label] += 1\n",
    "            if graph.mask[i][j] == 1:\n",
    "                white_pixels_count[superpixel_label] += 1\n",
    "      \n",
    "    for node in graph.rag:\n",
    "        graph.rag.nodes[node]['label'] = 1.0 if white_pixels_count[node] / total_pixels_count[node] >= 0.65 else 0.0\n",
    "            \n",
    "            \n",
    "def assign_features(graph):\n",
    "    unique_superpixels_labels = np.unique(graph.superpixels_labels)\n",
    "    \n",
    "    for superpixel_label in unique_superpixels_labels:\n",
    "        superpixel_label_mask = (graph.superpixels_labels == superpixel_label).astype(int)\n",
    "        NRRD_DIRECTORY_PATH = \"./output/nrrd\"\n",
    "        os.makedirs(NRRD_DIRECTORY_PATH, exist_ok=True)\n",
    "        \n",
    "        nrrd.write(f\"{NRRD_DIRECTORY_PATH}/{superpixel_label}_image.nrrd\", graph.image)\n",
    "        nrrd.write(f\"{NRRD_DIRECTORY_PATH}/{superpixel_label}_superpixel_label_mask.nrrd\", superpixel_label_mask)\n",
    "        nrrd_image_path = os.path.join(NRRD_DIRECTORY_PATH, str(superpixel_label) + \"_image.nrrd\")\n",
    "        nrrd_superpixel_label_mask_path = os.path.join(NRRD_DIRECTORY_PATH, str(superpixel_label) + \"_superpixel_label_mask.nrrd\")\n",
    "        \n",
    "        extractor = radiomics.featureextractor.RadiomicsFeatureExtractor()\n",
    "        try:             \n",
    "            result = extractor.execute(nrrd_image_path, nrrd_superpixel_label_mask_path)\n",
    "        except Exception as exception:\n",
    "            os.makedirs(f\"./output/nrrd/failed/{graph.filed_id}\", exist_ok=True)\n",
    "            print(superpixel_label)\n",
    "            print(exception)\n",
    "            print(\"FAILED\")\n",
    "            nrrd.write(f\"{NRRD_DIRECTORY_PATH}/failed/{graph.filename}/{superpixel_label}_superpixel_label_mask.nrrd\", superpixel_label_mask)\n",
    "                \n",
    "        for feature in PYRADIOMICS_FEATURES:\n",
    "            graph.rag.nodes[superpixel_label][feature] = result[feature]\n",
    "    \n",
    "def process_images():\n",
    "    filenames = os.listdir(IMAGES_DIR_PATH)\n",
    "    graphs = list()\n",
    "    os.makedirs(\"./output/expected\", exist_ok=True)\n",
    "    os.makedirs(\"./output/generated\", exist_ok=True)\n",
    "    \n",
    "    for (file_count, filename) in enumerate(filenames, start=1):\n",
    "        print(f\"Processing files: {file_count}/{len(filenames)}\")\n",
    "        \n",
    "        file_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        try:\n",
    "            image = np.array(ImageOps.grayscale(Image.open(f\"{IMAGES_DIR_PATH}/{filename}\")))\n",
    "            mask = np.array(ImageOps.grayscale(Image.open(f\"{MASKS_DIR_PATH}/{file_id}.bmp\")))\n",
    "            superpixels_labels = np.fromfile(f\"{SUPERPIXELS_LABELS_DIR_PATH}/{file_id}.dat\", dtype=np.dtype((np.int32, image.shape)))[0]\n",
    "        except FileNotFoundError as error: \n",
    "            print(error)\n",
    "            \n",
    "        rag = skigraph.rag_mean_color(image, superpixels_labels)\n",
    "        graphs.append(Graph(file_id, rag, image, superpixels_labels, mask))\n",
    "        assign_labels(graphs[-1])\n",
    "        assign_features(graphs[-1])\n",
    "        \n",
    "        expected = Image.fromarray((mask*255).astype(np.uint8))\n",
    "        expected.save(f\"./output/expected/{file_id}.png\")\n",
    "        \n",
    "    print(\"All files have been processed\")\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "def split_into_subgraphs(graphs):\n",
    "    subgraphs = []\n",
    "    for graph in graphs:\n",
    "        for node in graph.rag.nodes:\n",
    "            nodes = [neighbor for neighbor in graph.rag.neighbors(node)] + [node]\n",
    "            rag = graph.rag.subgraph(nodes)\n",
    "            label = graph.rag.nodes[node]['label']\n",
    "            subgraphs.append(Subgraph(rag, graph, node, label))\n",
    "            \n",
    "    return subgraphs\n",
    "\n",
    "def normalize_edge_indices(edge_indices):\n",
    "    result = []\n",
    "    flat_list = []\n",
    "    for sublist in edge_indices:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "            \n",
    "    flat_list.sort()\n",
    "    flat_list = list(dict.fromkeys(flat_list))\n",
    "    change = {key:value for (value, key) in enumerate(flat_list)}\n",
    "    \n",
    "    for sublist in edge_indices:\n",
    "        temp = []\n",
    "        for item in sublist:\n",
    "            temp.append(change[item])\n",
    "        result.append(temp)    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def prepare_data(subgraphs):\n",
    "    nodes = []\n",
    "    edge_indices = []\n",
    "    edges = []\n",
    "    labels = []\n",
    "    \n",
    "    for subgraph in subgraphs:\n",
    "        node_features = []\n",
    "        \n",
    "        for node in subgraph.rag.nodes:\n",
    "            node_features.append([subgraph.rag.nodes[node][feature] for feature in PYRADIOMICS_FEATURES])\n",
    "            \n",
    "        nodes.append(node_features)\n",
    "        edges.append([[1.0] for edge in subgraph.rag.edges.data()])\n",
    "        unnormalized_edge_indices = [list(index) for index in subgraph.rag.edges]\n",
    "        edge_indices.append(normalize_edge_indices(unnormalized_edge_indices))\n",
    "        labels.append(subgraph.label)\n",
    "        \n",
    "        subgraph.nodes = nodes[-1]\n",
    "        subgraph.unnormalized_edge_indices = unnormalized_edge_indices\n",
    "        subgraph.normalized_edge_indices = edge_indices[-1]\n",
    "        subgraph.edges = edges[-1]\n",
    "\n",
    "    return nodes, edge_indices, edges, np.array(labels)\n",
    "\n",
    "'''\n",
    "def generate_segmented_images_from_predictions:\n",
    "    predicted_images = {}\n",
    "\n",
    "    for (i, subgraph) in enumerate(subgraphs_test):\n",
    "        if subgraph.rag.file_id not in predicted_images:\n",
    "            predicted_images[subgraph.rag.file_id] = np.copy(subgraph.rag.superpixels_labels)\n",
    "        predicted_images[subgraph.rag.file_id][ predicted_images[subgraph.rag.file_id] == subgraph.superpixel_label] = predictions[i] - 2\n",
    "\n",
    "    for key in predicted_images.keys():\n",
    "        predicted_images[key][predicted_images[key] == -1] = 1\n",
    "        predicted_images[key][predicted_images[key] == -2] = 0\n",
    "        predicted_images[key]=predicted_images[key]*255\n",
    "        im = Image.fromarray(predicted_images[key].astype(np.uint8))\n",
    "        im.save(f\"predictions/{key}.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 1/140\n",
      "Processing files: 2/140\n",
      "[Errno 2] No such file or directory: './input/data_set_2/superpixels_labels/7087195078.dat'\n",
      "Processing files: 3/140\n",
      "[Errno 2] No such file or directory: './input/data_set_2/superpixels_labels/6719056356.dat'\n",
      "Processing files: 4/140\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'filed_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d306ca634dbc>\u001b[0m in \u001b[0;36massign_features\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrrd_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrrd_superpixel_label_mask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/radiomics/featureextractor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, imageFilepath, maskFilepath, label, label_channel, voxelBased)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# Raises a ValueError if the ROI is invalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mboundingBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectedMask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageoperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/radiomics/imageoperations.py\u001b[0m in \u001b[0;36mcheckMask\u001b[0;34m(imageNode, maskNode, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mndims\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminDims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask has too few dimensions (number of dimensions %d, minimum required %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminDims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mask has too few dimensions (number of dimensions 1, minimum required 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8d77e19e6b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d306ca634dbc>\u001b[0m in \u001b[0;36mprocess_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuperpixels_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0massign_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0massign_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d306ca634dbc>\u001b[0m in \u001b[0;36massign_features\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrrd_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrrd_superpixel_label_mask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./output/nrrd/failed/{graph.filed_id}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperpixel_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'filed_id'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"radiomics\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "rags = process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rags_train, rags_test = train_test_split(rags, train_size=0.8, random_state=1)\n",
    "\n",
    "subgraphs_train = split_into_subgraphs(rags_train)\n",
    "subgraphs_test = split_into_subgraphs(rags_test)\n",
    "\n",
    "nodes_train, edge_indices_train, edges_train, labels_train =  prepare_data(subgraphs_train)\n",
    "nodes_test, edge_indices_test, edges_test, labels_test =  prepare_data(subgraphs_test)\n",
    "\n",
    "nodes_train = ragged_tensor_from_nested_numpy(nodes_train)\n",
    "edges_train = ragged_tensor_from_nested_numpy(edges_train)\n",
    "edge_indices_train = ragged_tensor_from_nested_numpy(edge_indices_train)\n",
    "\n",
    "nodes_test = ragged_tensor_from_nested_numpy(nodes_test)\n",
    "edges_test = ragged_tensor_from_nested_numpy(edges_test)\n",
    "edge_indices_test = ragged_tensor_from_nested_numpy(edge_indices_test)\n",
    "\n",
    "xtrain = nodes_train, edges_train, edge_indices_train\n",
    "xtest = nodes_test, edges_test, edge_indices_test\n",
    "ytrain = labels_train\n",
    "ytest = labels_test\n",
    "print([x.shape for x in xtrain])\n",
    "print([x.shape for x in xtest])\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(\n",
    "    name = \"GCN\",\n",
    "    inputs = [{'shape': (None, 12), 'name': \"node_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "            {'shape': (None, 1), 'name': \"edge_attributes\", 'dtype': 'float32', 'ragged': True},\n",
    "            {'shape': (None, 2), 'name': \"edge_indices\", 'dtype': 'int64', 'ragged': True}],\n",
    "    input_embedding = {\"node\": {\"input_dim\": 55, \"output_dim\": 64},\n",
    "                       \"edge\": {\"input_dim\": 10, \"output_dim\": 64}},\n",
    "    output_embedding =  'graph',\n",
    "    output_mlp = {\"use_bias\": [True, True, False], \"units\": [140, 70, 1],\n",
    "                \"activation\": ['relu', 'relu', 'sigmoid']},\n",
    "    gcn_args = {\"units\": 64, \"use_bias\": True, \"activation\": 'relu', \"pooling_method\": 'mean', \n",
    "                \"normalize_by_weights\": False},\n",
    "    depth = 1\n",
    ")\n",
    "\n",
    "# Set learning rate and epochs\n",
    "learning_rate_start = 1e-3\n",
    "learning_rate_stop = 1e-4\n",
    "epo = 150\n",
    "epomin = 100\n",
    "epostep = 10\n",
    "\n",
    "# Compile model with optimizer and loss\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate_start)\n",
    "cbks = LinearLearningRateScheduler(learning_rate_start, learning_rate_stop, epomin, epo)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              weighted_metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Start and time training\n",
    "start = time.process_time()\n",
    "hist = model.fit(xtrain, ytrain,\n",
    "                 epochs=epo,\n",
    "                 batch_size=32,\n",
    "                 callbacks=[cbks],\n",
    "                 validation_freq=epostep,\n",
    "                 validation_data=(xtest, ytest),\n",
    "                 verbose=2\n",
    "                 )\n",
    "stop = time.process_time()\n",
    "print(\"Print Time for taining: \", stop - start)\n",
    "\n",
    "# Get loss from history\n",
    "trainlossall = np.array(hist.history['accuracy'])\n",
    "testlossall = np.array(hist.history['val_accuracy'])\n",
    "acc_valid = testlossall[-1]\n",
    "\n",
    "# Plot loss vs epochs\n",
    "plt.figure()\n",
    "plt.plot(np.arange(trainlossall.shape[0]), trainlossall, label='Training ACC', c='blue')\n",
    "plt.plot(np.arange(epostep, epo + epostep, epostep), testlossall, label='Test ACC', c='red')\n",
    "plt.scatter([trainlossall.shape[0]], [acc_valid], label=\"{0:0.4f} \".format(acc_valid), c='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Interaction Network Loss')\n",
    "plt.legend(loc='upper right', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = model.predict(xtest)\n",
    "predictions = np.round(probability)\n",
    "print(predictions)\n",
    "print(ytest)\n",
    "comparison = np.concatenate((predictions, ytest, probability), axis=1)\n",
    "# print(comparison)\n",
    "\n",
    "hole = 0\n",
    "true = 0\n",
    "false = 0\n",
    "hole2 = 0\n",
    "true2 = 0\n",
    "false2 = 0\n",
    "for value in comparison:\n",
    "    if value[1] == 1.:\n",
    "        hole += 1\n",
    "        if value[0] == 0.:\n",
    "            false +=1\n",
    "        else:\n",
    "            true +=1\n",
    "    if value[1] == 0.:\n",
    "        hole2 += 1\n",
    "        if value[0] == 1.:\n",
    "            false2 +=1\n",
    "        else:\n",
    "            true2 +=1\n",
    "print(f\"{true}/{hole}\")\n",
    "print(f\"{false}/{hole}\")\n",
    "print(f\"{true2}/{hole2}\")\n",
    "print(f\"{false2}/{hole2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
